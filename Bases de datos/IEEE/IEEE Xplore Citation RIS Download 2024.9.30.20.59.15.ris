TY  - CHAP
TI  - About the Editors
T2  - Selected Topics in Intelligent Chips with Emerging Devices, Circuits and Systems
SP  - 235
EP  - 237
PY  - 2022
DO  - 
PB  - River Publishers
SN  - 9788770227643
UR  - http://ieeexplore.ieee.org.crai.referencistas.com/document/9933673
AB  - Memristors have provided a new direction of thinking for circuit designers to overcome the limits of scalability and for thinking of building systems beyond Moore&#x2019;s law. Over the last decade, there has been a significant number of innovations in using memristors for building neural networks through analog computing, in-memory computing, and stochastic computing approaches. The emergence of intelligent integrated circuits is inevitable for the future of integrated circuit applications. This book provides a collection of talks conducted as part of the IEEE Seasonal School on Circuits and System, having a focus on Intelligence in Chip: Tomorrow of Integrated Circuits. Technical topics discussed in the book include: &#x2022; Edge of Chaos Theory Explains Complex Phenomena in Memristor Circuits &#x2022; Analog Memristive Computing &#x2022; Designing energy efficient neo-cortex system with on-device learning &#x2022; Integrated sensors &#x2022; Challenges and recent advances in NVM based Neuromorphic Computing ICs &#x2022; In-memory Computing (for deep learning) &#x2022; Deep learning with Spiking Neural Networks &#x2022; Computational Intelligence for Designing Integrated Circuits and Systems &#x2022; Neurochip Design, Modeling, and Applications
ER  - 

TY  - CONF
TI  - Approximate computing: Challenges and opportunities
T2  - 2016 IEEE International Conference on Rebooting Computing (ICRC)
SP  - 1
EP  - 8
AU  - A. Agrawal
AU  - J. Choi
AU  - K. Gopalakrishnan
AU  - S. Gupta
AU  - R. Nair
AU  - J. Oh
AU  - D. A. Prener
AU  - S. Shukla
AU  - V. Srinivasan
AU  - Z. Sura
PY  - 2016
KW  - Approximate computing
KW  - Synchronization
KW  - Hardware
KW  - Computer architecture
KW  - Synthetic aperture radar
KW  - Training
KW  - Approximation algorithms
KW  - Approximate computing
KW  - perforation
KW  - reduced precision
KW  - relaxed synchronization
DO  - 10.1109/ICRC.2016.7738674
JO  - 2016 IEEE International Conference on Rebooting Computing (ICRC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2016 IEEE International Conference on Rebooting Computing (ICRC)
Y1  - 17-19 Oct. 2016
AB  - Approximate computing is gaining traction as a computing paradigm for data analytics and cognitive applications that aim to extract deep insight from vast quantities of data. In this paper, we demonstrate that multiple approximation techniques can be applied to applications in these domains and can be further combined together to compound their benefits. In assessing the potential of approximation in these applications, we took the liberty of changing multiple layers of the system stack: architecture, programming model, and algorithms. Across a set of applications spanning the domains of DSP, robotics, and machine learning, we show that hot loops in the applications can be perforated by an average of 50% with proportional reduction in execution time, while still producing acceptable quality of results. In addition, the width of the data used in the computation can be reduced to 10-16 bits from the currently common 32/64 bits with potential for significant performance and energy benefits. For parallel applications we reduced execution time by 50% using relaxed synchronization mechanisms. Finally, our results also demonstrate that benefits compounded when these techniques are applied concurrently. Our results across different applications demonstrate that approximate computing is a widely applicable paradigm with potential for compounded benefits from applying multiple techniques across the system stack. In order to exploit these benefits it is essential to re-think multiple layers of the system stack to embrace approximations ground-up and to design tightly integrated approximate accelerators. Doing so will enable moving the applications into a world in which the architecture, programming model, and even the algorithms used to implement the application are all fundamentally designed for approximate computing.
ER  - 

TY  - CONF
TI  - ANGELS for distributed analytics in IoT
T2  - 2014 IEEE World Forum on Internet of Things (WF-IoT)
SP  - 565
EP  - 570
AU  - A. Mukherjee
AU  - H. S. Paul
AU  - S. Dey
AU  - A. Banerjee
PY  - 2014
KW  - Internet
KW  - Smart phones
KW  - Logic gates
KW  - Mobile communication
KW  - Computer architecture
KW  - Servers
KW  - cyber-physical
KW  - ubiquitous systems
KW  - analytics
KW  - parallel execution
KW  - black-box
KW  - mobile grid
DO  - 10.1109/WF-IoT.2014.6803230
JO  - 2014 IEEE World Forum on Internet of Things (WF-IoT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2014 IEEE World Forum on Internet of Things (WF-IoT)
Y1  - 6-8 March 2014
AB  - The current global emphasis on “Internet of Things (IoT)” have highlighted the extreme importance of sensor-based intelligent and ubiquitous systems which are more commonly known as “cyber-physical systems.” The technology has the potential to create a network of smart devices and things to an extent that has never been envisaged before, far outnumbering the number of devices connected in the Internet as we know today. The sheer number of such connected ubiquitous devices is likely to give rise to a hitherto unforeseen volume of data of different types with a demand for execution of analytical algorithms over the data. On the success of these analytic processes will depend the actual “smartness” of the “Intelligent Infrastructures” which now form the crux of the IoT paradigm. We have seen the advent of cloud-based paradigms to analyse the data in a data-parallel fashion within large data centres which now form the basis of the “big-data” problem. But apart from the servers in the data centres, we potentially have a huge pool of compute resources if we think about the smart devices in and around our homes collectively, which remain relatively idle. In this paper, we present a proposal with some emulated experimental results where we claim that in an IoT framework, the smart devices such as mobile phones, home gateways etc. can be utilised for execution of dataparallel analytic jobs. This is effectively a work-in-progress and it is acknowledged that there will be further challenges for real devices. Future research will attempt to consider these challenges.
ER  - 

TY  - CONF
TI  - Processor Hardware Security Vulnerabilities and their Detection by Unique Program Execution Checking
T2  - 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE)
SP  - 994
EP  - 999
AU  - M. R. Fadiheh
AU  - D. Stoffel
AU  - C. Barrett
AU  - S. Mitra
AU  - W. Kunz
PY  - 2019
KW  - Security
KW  - Hardware
KW  - Microarchitecture
KW  - Hazards
KW  - Software
KW  - Pipelines
KW  - Timing
DO  - 10.23919/DATE.2019.8715004
JO  - 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE)
IS  - 
SN  - 1558-1101
VO  - 
VL  - 
JA  - 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE)
Y1  - 25-29 March 2019
AB  - Recent discovery of security attacks in advanced processors, known as Spectre and Meltdown, has resulted in high public alertness about security of hardware. The root cause of these attacks is information leakage across covert channels that reveal secret data without any explicit information flow between the secret and the attacker. Many sources believe that such covert channels are intrinsic to highly advanced processor architectures based on speculation and out-of-order execution, suggesting that such security risks can be avoided by staying away from high-end processors. This paper, however, shows that the problem is of wider scope: we present new classes of covert channel attacks which are possible in average-complexity processors with in-order pipelining, as they are mainstream in applications ranging from Internet-of-Things to Autonomous Systems. We present a new approach as a foundation for remedy against covert channels: while all previous attacks were found by clever thinking of human attackers, this paper presents a formal method called Unique Program Execution Checking which detects and locates vulnerabilities to covert channels systematically, including those to covert channels unknown so far.
ER  - 

TY  - CONF
TI  - Dynamo + Astro: An Integrated Approach for BPEL Monitoring
T2  - 2009 IEEE International Conference on Web Services
SP  - 230
EP  - 237
AU  - L. Baresi
AU  - S. Guinea
AU  - M. Pistore
AU  - M. Trainotti
PY  - 2009
KW  - Magnetohydrodynamic power generation
KW  - Monitoring
KW  - Proposals
KW  - Web services
KW  - Computer architecture
KW  - Software systems
KW  - Assembly
KW  - Distributed computing
KW  - Quality of service
KW  - Probes
DO  - 10.1109/ICWS.2009.67
JO  - 2009 IEEE International Conference on Web Services
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2009 IEEE International Conference on Web Services
Y1  - 6-10 July 2009
AB  - In the literature, there exist several approaches for monitoring the execution of BPEL processes. They concentrate on different properties, adopt different languages, work at different levels of abstraction, and assume different perspectives. Even if the field is rather new, we do not think that this diversity is a limitation of current solutions; rather it is intrinsic in the problem itself. We claim that, instead of working on the definition of the ultimate approach for BPEL monitoring, we should push a cooperative approach based on the integration of different solutions.In this paper, we present a first step in this direction, and describe a monitoring framework which is obtained by integrating two well-known approaches, namely Dynamo and Astro. This integration, which happens both for the language used for expressing the properties to be monitored, and for the architecture of the monitoring framework, allows to combine the advantages of the two approaches and to obtain a general, comprehensive solutions for BPEL monitoring.
ER  - 

TY  - JOUR
TI  - Mapping of Himalaya Leucogranites Based on ASTER and Sentinel-2A Datasets Using a Hybrid Method of Metric Learning and Random Forest
T2  - IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing
SP  - 1925
EP  - 1936
AU  - Z. Wang
AU  - R. Zuo
AU  - Y. Dong
PY  - 2020
KW  - Measurement
KW  - Remote sensing
KW  - Geology
KW  - Random forests
KW  - Belts
KW  - Spatial resolution
KW  - Metals
KW  - Himalaya leucogranites
KW  - lithological mapping
KW  - metric learning
KW  - random forest
KW  - remote sensing
DO  - 10.1109/JSTARS.2020.2989509
JO  - IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing
IS  - 
SN  - 2151-1535
VO  - 13
VL  - 13
JA  - IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing
Y1  - 2020
AB  - The widely distributed leucogranite belt in the Himalayan orogeny is expected to have excellent potential for developing rare metal mineralization. Finding a way to effectively map the spatial distribution of leucogranites would be a significant contribution to rare metal exploration. Research shows remote sensing technology has long been recognized the significance in geological works, which greatly promoted mineral exploration in a cost-effective manner, especially in the Himalayan orogenic belt with poor natural environment. However, several challenges still exist in relation to the limited spectral band and spatial resolution of remote sensing images, as well as the onerous data processing. In this context, this study sought to resolve these two issues by applying a hybrid approach that comprises image fusion, metric learning, and random forest methods. For the first challenge, multisource and multisensor remote sensing data were integrated to provide more comprehensive spatial texture characteristics and spectral information. To address the second challenge, this study used a hybrid method of metric learning and random forest to promote computing efficiency and classification accuracy. This process is illustrated through a case study of lithological mapping in Cuonadong dome, the northern part of the Himalayan orogeny belt. Seven target lithological units were effectively discriminated with an 85.75% overall accuracy. This provides an important scientific basis for further exploration for rare metal deposits in the Himalayan orogeny belt, and a way of thinking for detecting geological features under harsh natural conditions.
ER  - 

TY  - JOUR
TI  - Unleashing the Power of Participatory IoT with Blockchains for Increased Safety and Situation Awareness of Smart Cities
T2  - IEEE Network
SP  - 202
EP  - 209
AU  - B. Hamdaoui
AU  - M. Alkalbani
AU  - T. Znati
AU  - A. Rayes
PY  - 2020
KW  - Cloud computing
KW  - Internet of Things
KW  - Smart cities
KW  - Computer architecture
KW  - Blockchain
KW  - Real-time systems
DO  - 10.1109/MNET.001.1900253
JO  - IEEE Network
IS  - 2
SN  - 1558-156X
VO  - 34
VL  - 34
JA  - IEEE Network
Y1  - March/April 2020
AB  - IoT has emerged as an unprecedented paradigm with great potential for changing how people interact, think and live. It is making existing Internet services feasible in ways that were previously impossible, as well as paving the way for new situation- awareness applications suitable for smart cities, such as realtime video surveillance, traffic control, and emergency management. These applications will typically rely on large numbers of IoT devices to collect and collaboratively process streamed data to enable real-time decision making. In this article, we introduce the concept of Semantic Virtual Space (SVS), an abstraction for virtualized cloud-enabled IoT infrastructure that is commensurate with the goals and needs of these emerging smart city applications, and propose and discuss scalable architectures and mechanisms that enable and automate the deployment and management of multiple SVS instances on top of the cloud-enabled IoT infrastructure.
ER  - 

TY  - CONF
TI  - The DEEP Project - Pursuing Cluster-Computing in the Many-Core Era
T2  - 2013 42nd International Conference on Parallel Processing
SP  - 885
EP  - 892
AU  - N. Eicker
AU  - T. Lippert
AU  - T. Moschny
AU  - E. Suarez
PY  - 2013
KW  - Computer architecture
KW  - Program processors
KW  - Scalability
KW  - Hardware
KW  - Fabrics
KW  - Parallel processing
KW  - Programming
KW  - HPC
KW  - Computer Architecture
KW  - Exascale
DO  - 10.1109/ICPP.2013.105
JO  - 2013 42nd International Conference on Parallel Processing
IS  - 
SN  - 2332-5690
VO  - 
VL  - 
JA  - 2013 42nd International Conference on Parallel Processing
Y1  - 1-4 Oct. 2013
AB  - Homogeneous cluster architectures dominating high-performance computing (HPC) today are challenged, in particular when thinking about reaching Exascale by the end of the decade, by heterogeneous approaches utilizing accelerator elements. The DEEP (Dynamical Exascale Entry Platform) project aims for implementing a novel architecture for high-performance computing consisting of two components - a standard HPC Cluster and a cluster of many-core processors called Booster. In order to make the adaptation of application codes to this Cluster-Booster architecture as seamless as possible, DEEP provides a complete programming environment. It integrates the offloading functionality given by the MPI standard with an abstraction layer based on the task-based OmpSs programming paradigm. This paper presents the DEEP project with an emphasis on the DEEP programming environment.
ER  - 

TY  - JOUR
TI  - Non-Conforming Nitsche Interfaces for Edge Elements in Curl–Curl-Type Problems
T2  - IEEE Transactions on Magnetics
SP  - 1
EP  - 7
AU  - K. Roppert
AU  - S. Schoder
AU  - F. Toth
AU  - M. Kaltenbacher
PY  - 2020
KW  - Convergence
KW  - Approximation error
KW  - Method of moments
KW  - Magnetostatics
KW  - Eddy currents
KW  - Three-dimensional displays
KW  - Magnetic domains
KW  - Eddy current problem
KW  - magnetostatic
KW  - Nédélec elements
KW  - Nitsche method
KW  - non-conforming interface
DO  - 10.1109/TMAG.2020.2980477
JO  - IEEE Transactions on Magnetics
IS  - 5
SN  - 1941-0069
VO  - 56
VL  - 56
JA  - IEEE Transactions on Magnetics
Y1  - May 2020
AB  - In this article, a methodology to incorporate non-conforming interfaces between several conforming mesh regions is presented for Maxwell's curl-curl problem. The derivation starts from a general interior penalty discontinuous Galerkin formulation of the curl-curl problem and eliminates all interior jumps in the conforming parts but retains them across non-conforming interfaces. Therefore, it is possible to think of this Nitsche approach for interfaces as a specialization of discontinuous Galerkin on meshes, which are conforming nearly everywhere. The applicability of this approach is demonstrated in two numerical examples, including parameter jumps at the interface. A convergence study is performed for h-refinement, including the investigation of the penalization- (Nitsche-) parameter.
ER  - 

TY  - CONF
TI  - Trends in concurrent, multi-criteria and optimal design of mechatronic systems: A review
T2  - Proceedings of the 2014 International Conference on Innovative Design and Manufacturing (ICIDM)
SP  - 88
EP  - 93
AU  - A. Mohebbi
AU  - L. Baron
AU  - S. Achiche
AU  - L. Birglen
PY  - 2014
KW  - Mechatronics
KW  - Design methodology
KW  - Software
KW  - System analysis and design
KW  - Mathematical model
KW  - Solid modeling
KW  - Systematics
KW  - KEYWORDS
KW  - Mechatronics
KW  - Multicriteria
KW  - Multi-disciplinary
KW  - Concurrent Design
KW  - Integration
KW  - Optimization
DO  - 10.1109/IDAM.2014.6912676
JO  - Proceedings of the 2014 International Conference on Innovative Design and Manufacturing (ICIDM)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - Proceedings of the 2014 International Conference on Innovative Design and Manufacturing (ICIDM)
Y1  - 13-15 Aug. 2014
AB  - Due to the inherent complexity and the dynamic coupling between subsystems of mechatronic systems, a systematic and multicriteria design thinking methodology is crucial to replace the traditionally used sequential design approach. In this paper we discuss the various aspects of current approaches within mechatronic system design to point out the most important challenges. Accordingly, a review on the most recent work on design and optimization methods and tools is presented and briefly discussed. A framework for concurrent and integrated design of mechatronic system based on separation of realtime and non-realtime system behaviours is also introduced and developed methods based on this model are presented.
ER  - 

TY  - CONF
TI  - Quantum Computing Platforms: Assessing the Impact on Quality Attributes and SDLC Activities
T2  - 2021 IEEE 18th International Conference on Software Architecture (ICSA)
SP  - 80
EP  - 91
AU  - B. Sodhi
AU  - R. Kapur
PY  - 2021
KW  - Quantum algorithm
KW  - Software architecture
KW  - Scalability
KW  - Qubit
KW  - Buildings
KW  - Software algorithms
KW  - Computer architecture
KW  - Quantum Computing
KW  - Quantum Software Engineering
KW  - Software Development Life Cycle
KW  - Computing Platforms
DO  - 10.1109/ICSA51549.2021.00016
JO  - 2021 IEEE 18th International Conference on Software Architecture (ICSA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2021 IEEE 18th International Conference on Software Architecture (ICSA)
Y1  - 22-26 March 2021
AB  - Practical quantum computing is rapidly becoming a reality. To harness quantum computers’ real potential in software applications, one needs to have an in-depth understanding of all such characteristics of quantum computing platforms (QCPs), relevant from the Software Engineering (SE) perspective. Restrictions on copying, deletion, the transmission of qubit states, a hard dependency on quantum algorithms are few, out of many, examples of QCP characteristics that have significant implications for building quantum software.Thus, developing quantum software requires a paradigm shift in thinking by software engineers. This paper presents the key findings from the SE perspective, resulting from an in-depth examination of state-of-the-art QCPs available today. The main contributions that we present include i) Proposing a general architecture of the QCPs, ii) Proposing a programming model for developing quantum software, iii) Determining architecturally significant characteristics of QCPs, and iv) Determining the impact of these characteristics on various Quality Attributes (QAs) and Software Development Life Cycle (SDLC) activities.We show that the nature of QCPs makes them useful mainly in specialized application areas such as scientific computing. Except for performance and scalability, most of the other QAs (e.g., maintainability, testability, and reliability) are adversely affected by different characteristics of a QCP.
ER  - 

TY  - CONF
TI  - A Cloud Infrastructure for Collaborative Digital Public Services
T2  - 2011 IEEE Third International Conference on Cloud Computing Technology and Science
SP  - 340
EP  - 347
AU  - Y. Charalabidis
AU  - S. Koussouris
AU  - A. Ramfos
PY  - 2011
KW  - Technological innovation
KW  - Cloud computing
KW  - Service oriented architecture
KW  - Europe
KW  - Collaboration
KW  - Government
KW  - Cloud Computing
KW  - Public Services
KW  - Collaboration
KW  - Open Innovation
KW  - eGovernance
DO  - 10.1109/CloudCom.2011.53
JO  - 2011 IEEE Third International Conference on Cloud Computing Technology and Science
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2011 IEEE Third International Conference on Cloud Computing Technology and Science
Y1  - 29 Nov.-1 Dec. 2011
AB  - Looking back at the major developments of the previous years in the Internet and IT industry, it is more than certain that two of the most important innovations are cloud computing, which evidently takes processing power and IT provision to a whole new level, and Web2.0 service applications, that reveal the innovative thinking and development power of users, who in many cases are the architects of these applications. Despite this progress, focusing on the provision of public services reveals that until today little has been done in order to expose the real power of those two concepts. Cloud computing is in most cases regarded just as an alternative to having in premise infrastructures, while Web2.0 applications designed by third parties cannot be integrated in the public sector and are characterised as "promising initiatives that cannot go further". This paper targets the constantly increasing need for having more efficient and effective public sector services by trying to combine the benefits that derive by both the cloud computing and the open innovation concepts, and proposes a platform that could actually assist stakeholders to deploy their services towards meeting their needs, whether this refers to the exposure of public services over cloud infrastructures or to the creation of personalised composite public services.
ER  - 

TY  - CONF
TI  - Kaleido: An Efficient Out-of-core Graph Mining System on A Single Machine
T2  - 2020 IEEE 36th International Conference on Data Engineering (ICDE)
SP  - 673
EP  - 684
AU  - C. Zhao
AU  - Z. Zhang
AU  - P. Xu
AU  - T. Zheng
AU  - J. Guo
PY  - 2020
KW  - Data mining
KW  - Programming
KW  - Memory management
KW  - Patents
KW  - Arrays
KW  - Tensile stress
KW  - graph mining
KW  - exploration
KW  - isomorphism
KW  - out-of-core
DO  - 10.1109/ICDE48307.2020.00064
JO  - 2020 IEEE 36th International Conference on Data Engineering (ICDE)
IS  - 
SN  - 2375-026X
VO  - 
VL  - 
JA  - 2020 IEEE 36th International Conference on Data Engineering (ICDE)
Y1  - 20-24 April 2020
AB  - Graph mining is one of the most important categories of graph algorithms. However, exploring the subgraphs of an input graph produces a huge amount of intermediate data. The "think like a vertex" programming paradigm, pioneered by Pregel, cannot readily formulate mining problems, which is designed to produce graph computation problems like PageRank. Existing mining systems like Arabesque and RStream need large amounts of computing and memory resources. In this paper, we present Kaleido, an efficient single machine, out-of-core graph mining system which treats disks as an extension of memory. Kaleido treats intermediate data in graph mining tasks as a tensor and adopts a succinct data structure for the intermediate data. Kaleido implements half-memory-half-disk storage for storing large intermediate data, which treats the disk as an extension of the memory. Kaleido adopts a lightweight isomorphism checking strategy which uses an eigenvalue-based algorithm for small graphs and solves tree isomorphism for the other graphs. Comparing with two state-of-the-art mining systems, Arabesque and RStream, Kaleido outperforms them by a GeoMean 13.2× and 64.8× respectively.
ER  - 

TY  - JOUR
TI  - RL-DistPrivacy: Privacy-Aware Distributed Deep Inference for Low Latency IoT Systems
T2  - IEEE Transactions on Network Science and Engineering
SP  - 2066
EP  - 2083
AU  - E. Baccour
AU  - A. Erbad
AU  - A. Mohamed
AU  - M. Hamdi
AU  - M. Guizani
PY  - 2022
KW  - Task analysis
KW  - Collaboration
KW  - Deep learning
KW  - Servers
KW  - Privacy
KW  - Neural networks
KW  - Data models
KW  - IoT devices
KW  - resource constraints
KW  - sensitive data
KW  - black-box
KW  - distributed DNN
KW  - reinforcement learning
DO  - 10.1109/TNSE.2022.3165472
JO  - IEEE Transactions on Network Science and Engineering
IS  - 4
SN  - 2327-4697
VO  - 9
VL  - 9
JA  - IEEE Transactions on Network Science and Engineering
Y1  - 1 July-Aug. 2022
AB  - Although Deep Neural Networks (DNN) have become the backbone technology of several ubiquitous applications, their deployment in resource-constrained machines, e.g., Internet of Things (IoT) devices, is still challenging. To satisfy the resource requirements of such a paradigm, collaborative deep inference with IoT synergy was introduced. However, the distribution of DNN networks suffers from severe data leakage. Various threats have been presented, including black-box attacks, where malicious participants can recover arbitrary inputs fed into their devices. Although many countermeasures were designed to achieve privacy-preserving DNN, most of them result in additional computation and lower accuracy. In this paper, we present an approach that targets the security of collaborative deep inference via re-thinking the distribution strategy, without sacrificing the model performance. Particularly, we examine different DNN partitions that make the model susceptible to black-box threats and we derive the amount of data that should be allocated per device to hide proprieties of the original input. We formulate this methodology, as an optimization, where we establish a trade-off between the latency of co-inference and the privacy-level of data. Next, to relax the optimal solution, we shape our approach as a Reinforcement Learning (RL) design that supports heterogeneous devices as well as multiple DNNs/datasets.
ER  - 

TY  - CONF
TI  - Fuzzy rule interpolation based fuzzy signature structure in building condition evaluation
T2  - 2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)
SP  - 2214
EP  - 2221
AU  - G. I. Molnárka
AU  - S. Kovács
AU  - L. T. Kóczy
PY  - 2014
KW  - Buildings
KW  - Maintenance engineering
KW  - Interpolation
KW  - Vectors
KW  - Pragmatics
KW  - Radio frequency
KW  - Standards
DO  - 10.1109/FUZZ-IEEE.2014.6891883
JO  - 2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)
IS  - 
SN  - 1098-7584
VO  - 
VL  - 
JA  - 2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)
Y1  - 6-11 July 2014
AB  - The complexity of the residential house structures makes their condition evaluation difficult. Taking the human experts' thinking into consideration the linguistic approach seems reasonable, therefore the fuzzy set theory may provide a basis for creating an expert system. In practice, the assessment of some predefined attributes of building components may give a comprehensive value about the condition of the examined building on a relative scale. The data structure of building evaluation procedure makes clear that the fuzzy signature structure is helpful in analysis. The numerous building components that determine the character of the given building can turn to an unnecessarily large rule-base. The fuzzy rule interpolation and the corresponding sparse fuzzy rule-based knowledge representation could be a reasonably efficient structure for handling the building evaluation procedure. In this paper the fuzzy rule interpolation as a novel aggregation method in fuzzy signature structures is proposed. Its application is presented with a case study of roof structure evaluation of a classic urban-type residential house located in a historic district of Budapest, Hungary.
ER  - 

TY  - JOUR
TI  - Defining Cybernetics: Reflections on the Science of Governance
T2  - IEEE Systems, Man, and Cybernetics Magazine
SP  - 18
EP  - 26
AU  - Q. Zhao
AU  - J. Brine
AU  - D. P. Filev
PY  - 2015
KW  - Cybernetics
KW  - Ontologies
KW  - Governance
KW  - Internet
KW  - Control systems
DO  - 10.1109/MSMC.2015.2421325
JO  - IEEE Systems, Man, and Cybernetics Magazine
IS  - 2
SN  - 2333-942X
VO  - 1
VL  - 1
JA  - IEEE Systems, Man, and Cybernetics Magazine
Y1  - April 2015
AB  - In this article, we have reconsidered the meaning of cybernetics and provided a taxonomy that can be useful for us to understand various cybernetics more clearly. We have also investigated some fundamental properties of governable or self-governable distributed systems. In particular, we believe that ontology plays a key role for a distributed system to become governable or even self-governable. We think that automatic construction of a good ontology in a distributed system is an interesting topic for further study. In fact, constructing a good ontology for a mobile communication network, a social network, a traffic control network, and any network related to our daily lives is important to make the network governable, safe, and secure. For large-scale distributed systems (e.g., the Internet), certain self-governability is also indispensable for the network to be more reliable or dependable. Of course, full self-governability of these systems may not be expected from the point of view of human beings.
ER  - 

TY  - CONF
TI  - Software Services Engineering Manifesto - A Cross-Cutting Declaration
T2  - 2021 IEEE International Conference on Web Services (ICWS)
SP  - 703
EP  - 709
AU  - C. K. Chang
AU  - P. Ceravolo
AU  - R. N. Chang
AU  - S. Helal
AU  - Z. Jin
AU  - X. Liu
AU  - H. Ming
PY  - 2021
KW  - Industries
KW  - Ethics
KW  - Uncertainty
KW  - Web services
KW  - System dynamics
KW  - Systems operation
KW  - Service computing
KW  - agile
KW  - AI
KW  - context-aware
KW  - DevOps
KW  - IoT
KW  - microservice
KW  - ML
KW  - requirements engineering
KW  - services computing
KW  - situation-aware
KW  - software engineering
KW  - software services engineering
KW  - uncertainty
DO  - 10.1109/ICWS53863.2021.00014
JO  - 2021 IEEE International Conference on Web Services (ICWS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2021 IEEE International Conference on Web Services (ICWS)
Y1  - 5-10 Sept. 2021
AB  - As we have entered the Internet-of-Things (IoT) era, further blessed with rapid advances in several key technological areas including DevOps, AI/ML, 5G/6G/, neurocomputing, to name a few, it is imperative we think big and aim high. This new venture will require professionals in both software engineering and services computing to collaborate with an unprecedented intensity, and jointly develop the new interdisciplinary field hereby named Software Services Engineering (SSE). In SSE, the ever-deepening system dynamics emerging from both environments and humans in varying contexts are imposing steep challenges to both researchers and practitioners. Humans, both developers and the vast number of end users, are embedded ever closer to IoT environments, and are being afforded ample opportunities to continuously inject inputs during system development and after deployment. In fact, humans are increasingly playing the roles of both sensor and actuator. Traditional requirements engineering researchers are being lured more than ever into exploiting the IoT environments where human users are deeply embedded, to gather contextual information that inevitably introduces lots of ambiguity and uncertainty. Provisioning of highly adaptable and scalable microservices would be key to timely meeting ever-changing human desires and ever-evolving system requirements in the nimblest manner. As such, an ultra-agile and field-programmable development methodology and environment will be imperative to achieving such ultrafine grained microservices provisioning. Such ultra-agility and ultrafine granularity requirements imposed to the services industry obligate company executives to expect extreme manageability assurance to become the centroid of system operations and administration. The ultimate goal in pursuit of such a noble dream will be to provide genuinely individualized and trustworthy service, possibly enabled by AI, but it should be both explainable and ethical. Facing such grand challenges, this declaration samples a subset of burning issues in SSE through observations in seven themes, only meant to be starting points for the SSE community to further investigate. Through our declarations we also call for heightened attention to an assorted array of existing, barely emerging or non-existent services computing and software engineering methods for a concerted effort to research and explore.
ER  - 

TY  - CONF
TI  - Teaching the foundations of thermodynamics with PYro
T2  - 2016 IEEE Frontiers in Education Conference (FIE)
SP  - 1
EP  - 6
AU  - C. R. Martin
AU  - J. P. Moore
AU  - J. A. Ranalli
PY  - 2016
KW  - Software
KW  - Thermodynamics
KW  - Calculators
KW  - Education
KW  - Temperature
KW  - Chemicals
KW  - Documentation
DO  - 10.1109/FIE.2016.7757589
JO  - 2016 IEEE Frontiers in Education Conference (FIE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2016 IEEE Frontiers in Education Conference (FIE)
Y1  - 12-15 Oct. 2016
AB  - One of the key skills developed in foundational thermodynamics courses is obtaining property and state data for various substances of interest. Typically, students are instructed to perform this task through the use of tables or computer software. In this paper, we present and evaluate modules for teaching the foundations of thermodynamics using free open-source software intended to port to students' professional lives. The approach introduces the PYro thermodynamic property calculator. PYro is implemented in Python, which is free and available on most widely used platforms. PYro is clearly documented, and all data are readily traceable to reputable sources. Most of the data describe ideal gases from the NIST JANAF database, but there is also support for mixtures (such as air) and multiphase substances (such as steam). The interface design makes the software appropriate to most tasks in introductory and intermediate thermodynamics courses without requiring proficiency in the Python language. While the idea of using software to teach thermodynamics is far from new, commercial software usually comes at a substantial price and places the implementation burden on the instructor. On the other hand, educational software rarely transitions into students' professional lives. This paper proposes a model for productively separating the development of skills (like table look-ups) from knowledge and concepts. In addition to an introduction of the tool, this paper provides results of preliminary evaluation conducted within a thermodynamics classroom. The authors developed a learning module demonstrating the use of PYro to compute states for an ideal Brayton cycle. Students were tasked with performing parametric analysis on the cycle, by varying various limiting factors (e.g. combustor pressure, turbine inlet temperature). Students were asked to compare power produced and cycle efficiency computed under these conditions. At the end of the module, students were surveyed about the experience of working with the software. Evaluation is provided in the form of instructor and student feedback from a classroom implementation. We propose that this utilization of the tool demonstrates its ability to promote higher-level cognitive thinking in problem solving, removing the time intensive task of performing table look-ups and allowing them to focus on more holistic questions of cycle performance.
ER  - 

TY  - CONF
TI  - Systematic Review on Humanizing Machine Intelligence and Artificial Intelligence
T2  - 2023 Second International Conference on Electronics and Renewable Systems (ICEARS)
SP  - 1092
EP  - 1097
AU  - J. Abraham
AU  - G. J. Cherian
AU  - N. Jayapandian
PY  - 2023
KW  - Ethics
KW  - Renewable energy sources
KW  - Systematics
KW  - Law
KW  - Machine learning
KW  - Regulation
KW  - Behavioral sciences
KW  - Artificial Intelligence
KW  - Cognitive Intelligence
KW  - Machine Learning
KW  - Humanizing
KW  - Social Interactions;
DO  - 10.1109/ICEARS56392.2023.10084967
JO  - 2023 Second International Conference on Electronics and Renewable Systems (ICEARS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 Second International Conference on Electronics and Renewable Systems (ICEARS)
Y1  - 2-4 March 2023
AB  - In this era, Machine Learning is transforming human lives in a very different way. The need to give machines the power to make decisions or giving the moral compass is a big dilemma when humanity is more divided than it has ever been. There are two main ways in which law and AI interact. AI may be subject to legal restrictions and be employed in courtroom procedures. The world around us is being significantly and swiftly changed by AI in all of its manifestations. Public law includes important facets such as nondiscrimination law and labor law. In a manner similar to this when artificial intelligence (AI) is applied to tangible technology like robots. In certain cases, artificial intelligence (AI) might be hardly noticeable to customers but evident to those who built and are using it. The behavior research offers suggestions for how to build enduring and beneficial interactions between intelligent robots and people. The human improvement is main obstacles in the development and implementation of artificial intelligence. Best practices in this area are not governed by any one strategy that is generally acknowledged. Machine learning is about to revolutionize society as it is know it. It is crucial to give intelligent computers a moral compass now more than ever before because of how divided mankind is. Although machine learning has limitless potential, inappropriate usage might have detrimental long-term implications. It will think about how, for instance, earlier cultures built trust and improved social interactions via creative answers to many of the ethical issues that machine learning is posing now.
ER  - 

TY  - CONF
TI  - Digital Twin-Empowered Resource Allocation for 6G-Enabled Massive IoT
T2  - 2023 IEEE International Conference on Communications Workshops (ICC Workshops)
SP  - 727
EP  - 732
AU  - E. Bozkaya
AU  - B. Canberk
AU  - S. Schmidt
PY  - 2023
KW  - 6G mobile communication
KW  - Conferences
KW  - Wireless networks
KW  - Authentication
KW  - Computer architecture
KW  - Benchmark testing
KW  - Digital twins
DO  - 10.1109/ICCWorkshops57953.2023.10283649
JO  - 2023 IEEE International Conference on Communications Workshops (ICC Workshops)
IS  - 
SN  - 2694-2941
VO  - 
VL  - 
JA  - 2023 IEEE International Conference on Communications Workshops (ICC Workshops)
Y1  - 28 May-1 June 2023
AB  - 6G technology is expected to lead to an unpredictable increase of Internet of Things (IoT) devices. The need for maintaining continuous connectivity of these devices has in turn led to re-thinking of the traditional design of wireless networks. In particular, the integration of 6G and Digital Twin (DT) is expected to reshape the network management as it offers powerful features in design, development and optimization processes. DT is a digital representation of physical entities, which are designed around a two-way information flow. Therefore, this technology not only collects data, and employs intelligent learning methods by performing complex computations, but it also can send feedback to improve system performance for 6G-enabled massive IoT. However, deploying such a technology requires addressing complex challenges such as limited resources, seamless connectivity and lack of trust between end users and network edge. To address these challenges, we formulate the resource allocation problem including edge computation and service migration in 6G-enabled massive IoT. The contributions are threefold: First, our DT-empowered architecture is proposed that uses the real-time and historical data from end users to find the best allocation at a user. Second, it studies the impact of trust relationship between computing entities to prevent the unauthorized accesses and provides an authentication procedure. Third, it describes a Multi-Agent Reinforcement Learning (MARL) algorithm that consists of cooperative agents and aims to find the best resource allocation strategy by minimizing task processing latency. We validate the proposed DT-empowered architecture to show the reduced processing latency compared to traditional benchmark methods.
ER  - 

TY  - CONF
TI  - A cache-aware approach to domain decomposition for stencil-based codes
T2  - 2016 International Conference on High Performance Computing & Simulation (HPCS)
SP  - 875
EP  - 885
AU  - G. Saxena
AU  - P. K. Jimack
AU  - M. A. Walkley
PY  - 2016
KW  - Optimization
KW  - Jacobian matrices
KW  - Topology
KW  - Program processors
KW  - Load modeling
KW  - Mathematical model
KW  - Computer architecture
KW  - PDEs
KW  - Domain Decomposition
KW  - Stencil
KW  - Quasi-cache-directed
KW  - Cache-oblivious
DO  - 10.1109/HPCSim.2016.7568426
JO  - 2016 International Conference on High Performance Computing & Simulation (HPCS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2016 International Conference on High Performance Computing & Simulation (HPCS)
Y1  - 18-22 July 2016
AB  - Partial Differential Equations (PDEs) lie at the heart of numerous scientific simulations depicting physical phenomena. The parallelization of such simulations introduces additional performance penalties in the form of local and global synchronization among cooperating processes. Domain decomposition partitions the largest shareable data structures into sub-domains and attempts to achieve perfect load balance and minimal communication. Up to now research efforts to optimize spatial and temporal cache reuse for stencil-based PDE discretizations (e.g. finite difference and finite element) have considered sub-domain operations after the domain decomposition has been determined. We derive a cache-oblivious heuristic that minimizes cache misses at the sub-domain level through a quasi-cache-directed analysis to predict families of high performance domain decompositions in structured 3-D grids. To the best of our knowledge this is the first work to optimize domain decompositions by analyzing cache misses - thus connecting single core parameters (i.e. cache-misses) to true multicore parameters (i.e. domain decomposition). We analyze the trade-offs in decreasing cache-misses through such decompositions and increasing the dynamic bandwidth-per-core. The limitation of our work is that currently, it is applicable only to structured 3-D grids with cuts parallel to the Cartesian Axes. We emphasize and conclude that there is an imperative need to re-think domain decompositions in this constantly evolving multi-core era.
ER  - 

TY  - CONF
TI  - On fast retrieval of relational experiences
T2  - 2017 American Control Conference (ACC)
SP  - 3206
EP  - 3211
AU  - W. Gong
AU  - Y. -C. Ho
PY  - 2017
KW  - Resonant frequency
KW  - Transient analysis
KW  - Resonators
KW  - Intelligent systems
KW  - Signal processing
KW  - Computers
KW  - Neurons
DO  - 10.23919/ACC.2017.7963441
JO  - 2017 American Control Conference (ACC)
IS  - 
SN  - 2378-5861
VO  - 
VL  - 
JA  - 2017 American Control Conference (ACC)
Y1  - 24-26 May 2017
AB  - Various intelligent systems are needed for cyber-physical systems. Such intelligent systems need to learn from the human intelligence about concept abstraction and analogical thinking in order to resolve complex issues using past experiences. The algorithms for abstraction and analogies are based on quick memory recall with clever information coding and processing. The quick and accurate memory recall is based on the fact that the memory mostly records the relations among the constituents of the stimulating signals, rather than the constituents themselves. Relational memories can be stored in the form of networks of neuron clusters capable of resonating to particular signal sequences. However, similarity testing for such network representations is difficult. We suggest that linear dynamic systems that relate the system matrix and the output time function can be used as a conversion mechanism between the network matrix and the temporal representations of the signals. This leads to algorithms for relational similarity testing and concept abstraction. Transient behavior based selection rules in ordinal optimization is important in achieving quickness in our development.
ER  - 

TY  - JOUR
TI  - A Survey on Technologies Which Make Bitcoin Greener or More Justified
T2  - IEEE Access
SP  - 74792
EP  - 74814
AU  - H. T. Heinonen
AU  - A. Semenov
AU  - J. Veijalainen
AU  - T. Hämäläinen
PY  - 2022
KW  - Bitcoin
KW  - Blockchains
KW  - Green products
KW  - Energy consumption
KW  - Air pollution
KW  - Peer-to-peer computing
KW  - Grid computing
KW  - Blockchain
KW  - DLT
KW  - cryptocurrency
KW  - bitcoin
KW  - green technology
KW  - sustainability
KW  - unconventional computing
KW  - climate change
DO  - 10.1109/ACCESS.2022.3190891
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 10
VL  - 10
JA  - IEEE Access
Y1  - 2022
AB  - According to recent estimates, one bitcoin transaction consumes as much energy as 1.5 million Visa transactions. Why is bitcoin using so much energy? Most of the energy is used during the bitcoin mining process, which serves at least two significant purposes: a) distributing new cryptocurrency coins to the cryptoeconomy and b) securing the Bitcoin blockchain ledger. In reality, the comparison of bitcoin transactions to Visa transactions is not that simple. The amount of transactions in the Bitcoin network is not directly connected to the amount of bitcoin mining power nor the energy consumption of those mining devices; for example, it is possible to multiply the number of bitcoin transactions per second without increasing the mining power and the energy consumption. Bitcoin is not only “digital money for hackers”. It has very promising future potential as a global reserve currency and a method to make the World Wide Web (WWW) immune to cyberattacks such as the Distributed Denial-of-Service attacks. This survey approached cryptocurrencies’ various technological and environmental issues from many different perspectives. To make various cryptocurrencies, including bitcoin (BTC) and ether (ETH), greener and more justified, what technological solutions do we have? We found that cryptocurrency mining might be cleaner than is generally expected. There is also a plan to make a vast renewable energy source available by combining Ocean Thermal Energy Conversion and Bitcoin mining. There are plans to use unconventional computing methods (quantum computing, reversible computing, ternary computing, optical computing, analog computing) to solve some of the issues regarding the vast energy consumption of conventional computing (including cryptocurrency mining). We think using spare computing cycles for grid computing efforts is justified. For example, there are billions of smartphones in the world. Many smartphones are being recharged every day. If this daily recharging period of twenty to sixty minutes would be used for grid computing, for example, finding new cures to cancer, it would probably be a significant breakthrough for medical research simulations. We call on the cryptocurrency communities to research and develop grid computing and unconventional computing methods for the most significant cryptocurrencies: bitcoin (BTC)and ether (ETH).
ER  - 

TY  - CONF
TI  - Analog Computing in Memory (CIM) Technique for General Matrix Multiplication (GEMM) to Support Deep Neural Network (DNN) and Cosine Similarity Search Computing using 3D AND-type NOR Flash Devices
T2  - 2022 International Electron Devices Meeting (IEDM)
SP  - 33.3.1
EP  - 33.3.4
AU  - M. -L. Wei
AU  - H. -T. Lue
AU  - S. -Y. Ho
AU  - Y. -P. Lin
AU  - T. -H. Hsu
AU  - C. -C. Hsieh
AU  - Y. -C. Li
AU  - T. -H. Yeh
AU  - S. -H. Chen
AU  - Y. -H. Jhu
AU  - H. -P. Li
AU  - H. -W. Hu
AU  - C. -H. Hung
AU  - K. -C. Wang
AU  - C. -Y. Lu
PY  - 2022
KW  - Performance evaluation
KW  - Three-dimensional displays
KW  - Software algorithms
KW  - Neural networks
KW  - Memory architecture
KW  - Random access memory
KW  - Common Information Model (computing)
DO  - 10.1109/IEDM45625.2022.10019495
JO  - 2022 International Electron Devices Meeting (IEDM)
IS  - 
SN  - 2156-017X
VO  - 
VL  - 
JA  - 2022 International Electron Devices Meeting (IEDM)
Y1  - 3-7 Dec. 2022
AB  - The massively increasing data in computing world inspires the R&D of novel memory-centric computing architectures and devices. In this work, we propose a novel analog CIM technique for GEMM using 3D NOR Flash devices to support general-purpose matrix multiplication. Our analysis indicates that it’s very robust to use “billions” of memory cells with modest 4-level and large-spacing analog Icell to produce good accuracy and reliability, contrary to the past thinking to pursue many levels in each memory cell that inevitably suffers accuracy loss. We estimate that a 2.7Gb 3D NOR GEMM can provide a high-performance (frame/sec>300) image recognition inference of ResNet-50 on ImageNet dataset, using a simple flexible controller chip with 1MB SRAM without the need of massive ALU and external DRAM. The accuracy can maintain ~85% for Cifar-10 (by VGG7), and ~90% for ImageNet Top-5 (by ResNet-50) under good device control. This 3D NOR GEMM enjoys much lower system cost and flexibility than a complicated SOC. We also propose an operation and design method of “Cosine Similarity” computing using the 3D NOR. We can use a ternary similarity search algorithm with positive and negative inputs and weights to perform high-dimension feature vector (such as 512 for face recognition with FaceNet on VGGFace2 dataset) similarity computing in a high-parallelism CIM design (512 WL inputs, 1024 BL’s, at Tread=100ns). High-accuracy search (~97.8%, almost identical to 98% of software computing) and high internal search bandwidth (~5Tb/s per chip) are achieved. This in-Flash search accelerator is potential to enable new hardware-aware search algorithms in big data retrieval applications.
ER  - 

TY  - CONF
TI  - COFFEE: A Context-Free Protocol for Stimulating Data Forwarding in Wireless Ad Hoc Networks
T2  - 2009 6th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks
SP  - 1
EP  - 9
AU  - C. Song
AU  - Q. Zhang
PY  - 2009
KW  - Wireless application protocol
KW  - Mobile ad hoc networks
KW  - Peer to peer computing
KW  - Ad hoc networks
KW  - Bandwidth
KW  - Batteries
KW  - Communications Society
KW  - Context
KW  - Performance analysis
KW  - Routing
DO  - 10.1109/SAHCN.2009.5168916
JO  - 2009 6th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks
IS  - 
SN  - 2155-5494
VO  - 
VL  - 
JA  - 2009 6th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks
Y1  - 22-26 June 2009
AB  - Reputation based and credit-exchange based approaches have been studied extensively to enforce cooperation among non-cooperative nodes in wireless ad hoc networks. Most of the existing solutions are fundamentally context-based ones, which need to accurately identify selfish behaviors, securely maintain the context, and appropriately punish the selfish nodes. These requirements are extremely difficult to satisfy if not impossible. From a completely new angle, this paper proposes a context-free protocol, COFFEE, to enforce cooperation among selfish nodes, which has the ability to transmit a packet over the path successfully without the dependency on the information of other packets' transmission. Considering that every node in the network is rational, during the packet forwarding stage, if the intermediate nodes can not clearly tell whether the packet is destined to them or not, they can not simply drop the packet. Thus, in our proposed COFFEE protocol, through introducing several techniques, for any packet received by any node, the node thinks the packet could be destined to it and forwards the packet to find out the answer. Detailed analysis and performance evaluation have been conducted to demonstrate the effectiveness of the proposed protocol.
ER  - 

TY  - CONF
TI  - Remote and deep attestations to mitigate threats in Cloud Mash-Up services
T2  - 2013 World Congress on Computer and Information Technology (WCCIT)
SP  - 1
EP  - 6
AU  - A. Celesti
AU  - M. Fazio
AU  - M. Villari
AU  - A. Puliafito
AU  - D. Mulfari
PY  - 2013
KW  - Principal component analysis
KW  - Software
KW  - Servers
KW  - Hardware
KW  - Virtual machine monitors
KW  - Malware
KW  - Cloud Computing
KW  - Trusted Computing
KW  - Deep Attestation
KW  - Virtual Machine
KW  - PaaS
KW  - Federation
DO  - 10.1109/WCCIT.2013.6618763
JO  - 2013 World Congress on Computer and Information Technology (WCCIT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2013 World Congress on Computer and Information Technology (WCCIT)
Y1  - 22-24 June 2013
AB  - Cloud computing is an emerging technology able to offer a plethora of new advanced services. Cloud operators can use and combine such services in order to build new Mash-up Cloud platform and applications. However, security issues have strongly limited the large-scale adoption of Cloud computing, especially in business environments and similar application scenarios, where sensitive date need to be protected. At the same time the Trusted Computing technology is bringing a new way of thinking about security of systems. This paper deals with the importance to leverage the Trusted Computing for encouraging the development of secure distributed Mash-up Cloud services. We show how the Remote and Deep Attestation protocols make secure both the physical hosts and the virtual machines in a Cloud infrastructure, providing a solid framework for the deployment of federated environments.
ER  - 

TY  - JOUR
TI  - Validation of Current O-RAN Technologies and Insights on the Future Evolution
T2  - IEEE Journal on Selected Areas in Communications
SP  - 487
EP  - 505
AU  - Y. Huang
AU  - Q. Sun
AU  - N. Li
AU  - Z. Chen
AU  - J. Huang
AU  - H. Ding
AU  - C. -L. Ⅰ
PY  - 2024
KW  - Computer architecture
KW  - Hardware
KW  - 5G mobile communication
KW  - Synchronization
KW  - Cloud computing
KW  - Testing
KW  - Microprocessors
KW  - O-RAN
KW  - cloudification
KW  - RAN intelligent controller
KW  - prototype
KW  - field trial
DO  - 10.1109/JSAC.2023.3336180
JO  - IEEE Journal on Selected Areas in Communications
IS  - 2
SN  - 1558-0008
VO  - 42
VL  - 42
JA  - IEEE Journal on Selected Areas in Communications
Y1  - Feb. 2024
AB  - Entering the 5G era, the mobile network operators (MNO) are facing greater challenges in providing services cost effectively than any other previous generations. The potential solutions to this are lying on the emerging trend of deep convergence of information technology (IT), communication technology (CT) and data technology (DT). In particular, the O-RAN technology, the representation of such ICDT convergence and proposed by the O-RAN ALLIANCE in 2018, is transforming Radio Access Networks towards a new paradigm featuring openness, cloudification and intelligence. O-RAN has gained huge attention from both industry and academia since its inception. In this paper, we presented the recent endeavors from China Mobile, including our deployment scenarios, various test results from open fronthaul, cloud platform to the intelligent controller. Our rich and comprehensive tests have demonstrated the viability and superiority of current O-RAN technologies. Furthermore, we also provide our deep thinking on the O-RAN future evolution in order to better serve the emerging applications such as Metaverse, cloud extended-reality (XR), extensive enterprise private 5G verticals and so on.
ER  - 

TY  - CONF
TI  - Cache-aware task scheduling for maximizing control performance
T2  - 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)
SP  - 694
EP  - 699
AU  - W. Chang
AU  - D. Roy
AU  - X. S. Hu
AU  - S. Chakraborty
PY  - 2018
KW  - Schedules
KW  - Task analysis
KW  - Sensors
KW  - Optimal scheduling
KW  - Control systems
KW  - Delays
KW  - Feedback control
DO  - 10.23919/DATE.2018.8342098
JO  - 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)
IS  - 
SN  - 1558-1101
VO  - 
VL  - 
JA  - 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)
Y1  - 19-23 March 2018
AB  - Embedded control applications are widely implemented on small, low-cost and resource-constrained microcontrollers, e.g., in the automotive domain. Conventionally, control algorithms are designed using model-based approaches, without considering the details of the implementation platform. This leads to inefficient utilization of the resources. With the emergence of the cyber-physical system (CPS)-oriented thinking, there has lately been a strong interest in co-design of control algorithms and their implementation platforms. Some recent efforts have shown that a schedule on multiple applications with more on-chip cache reuse is able to improve the control performance. However, it has not been studied how the control performance can be maximized for a given schedule and how an optimal schedule can be computed. In this work, we propose a two-stage framework to compute the schedule maximizing the overall control performance of all the applications. First, a holistic controller design taking all the sampling periods and sensing-to-actuation delays in a schedule into account is presented, aiming to maximize the overall control performance. Second, a hybrid search algorithm for discrete decision space is reported to efficiently compute an optimal schedule. Experimental results on a case study with multiple automotive applications show that a significant improvement of 10-20% in control performance can be achieved by the proposed cache-aware scheduling approach.
ER  - 

TY  - CONF
TI  - A Research Of Drawing And Application Of Distribution Diagram Of Yunnan Ice Region Based On The Typical Ice Model Of Low Latitude Plateau Area
T2  - 2018 International Conference on Power System Technology (POWERCON)
SP  - 3440
EP  - 3447
AU  - F. L. G. bin
AU  - Z. F. rong
AU  - L. Gang
AU  - Y. Hong
AU  - Q. G. chao
AU  - S. Liangchi
AU  - Y. En
AU  - L. Xiang
PY  - 2018
KW  - Analytical models
KW  - Power transmission lines
KW  - Statistical analysis
KW  - Atmospheric modeling
KW  - Surfaces
KW  - Predictive models
KW  - Ice
KW  - Ice covering model
KW  - Yunnan region
KW  - Characteristics of ice
KW  - Distribution characteristics
KW  - The practical application
DO  - 10.1109/POWERCON.2018.8601794
JO  - 2018 International Conference on Power System Technology (POWERCON)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2018 International Conference on Power System Technology (POWERCON)
Y1  - 6-8 Nov. 2018
AB  - The international study of ice model mainly from the perspective of meteorology fluid mechanics, thermodynamics transmission line conductor and insulator ice mechanism research study of ice prediction model has been developed from Lenhard Kuoiwa simple conceptual model development experience model to Makkonen complex concept model and glaze rime hybrid numerical calculation model of freeze. Yunnan province is located in China's southwest, rolling within the territory of mountains, rivers, topography is complex, three-dimensional climate significantly, in climate resource is rich, meteorological disaster is frequent, influenced by monsoon climate, the prevalence of micro topography and microclimate characteristics; Yunnan line ice distribution characteristics of eastern Yunnan, Yunnan north southeast Yunnan wire ice mainly for glaze rime and mixed freezing, and northwest Yunnan is mainly for adhesion wet snow Is one of the areas hit hardest by the ice. Ice distribution can reflect the grid of ice in the area of distribution, further guidance inspect heavy ice monitoring and transmission lines deicing ice design application, reduce line ice disaster accident economic loss caused by ice, improve power grid ice resistance ability and the power supply reliability,This paper comprehensive analysis the Yunnan plateau region, the transmission lines ice distribution factors such as geographic conditions, climate type and on-the-spot investigation to collect typical data grid severe ice disaster in 2008, 1983, in ice model research results at home and abroad for reference, combining with the actual situation of Yunnan in northeast Yunnan, the corresponding ice model is constructed, This paper proposes a new model of ice coating in Yunnan province, which is suitable for studying the new ice model in Yunnan province. Detected in the weather station data for statistical analysis, using the computer on hd electronic topographic map, inductive areas of Yunnan power grid ice distribution, and taken as the basis of the division of ice, ice zoning map of different return period. Through in the new 500Kv DE Maoxian gold officer lines before the field site engineering feasibility study stage, according to the project line to choose the line path, in the ”Yunnan power grid ice distribution” to the first line of the path optimization and avoid ice marked lines need to focus on the path to the investigation of the ice area, fully do sufficient preparation before departure, greatly reduced the time of field reconnaissance, time reduced by about 1/3 of the original, but also improve the working efficiency and the quality of the project. Because Yunnan province special landform, geography, weather, climate, micro topography, and micro climate is numerous, Draught place, pass, canyons, air duct, windward area can cause tiny terrain conductor ice serious increase in local area, these areas of ice thickness can't, according to a broader range of meteorological data to determine when ice districts so the two ”micro” edit, finally get reasonable ice figure. Field test comparison test with many times, think theory model calculated results and the results have some discrepancy, but after altitude elevation and atmospheric circulation, the correction ”micro” two conditions, the result basically reflects the east and northeast Yunnan, Yunnan mountainous terrain upheaval and three-dimensional climate characteristics, the theory research of ice model is more reasonable. Through typical ice model, put forward a preliminary mastered the typical transmission line low latitude plateau area in Yunnan the formation law of ice, ice in Yunnan region distribution simultaneously provide basic data and model support, increased the application of ”practicality”. But transmission lines ice cover is a and the complex of the atmospheric physical processes, at the same time and the topography distribution and climate change have bigger relationship, must continue to carry out the statistical analysis of the actual ice, perfecting the model calculation model and the distribution of its ice.
ER  - 

TY  - CONF
TI  - Comparative analysis of signal processing in brain computer interface
T2  - 2009 4th IEEE Conference on Industrial Electronics and Applications
SP  - 580
EP  - 585
AU  - Ruiting Yang
AU  - D. A. Gray
AU  - B. W. Ng
AU  - Mingyi He
PY  - 2009
KW  - Signal analysis
KW  - Signal processing
KW  - Brain computer interfaces
KW  - Electroencephalography
KW  - Rhythm
KW  - Signal processing algorithms
KW  - Feature extraction
KW  - Frequency
KW  - Pattern recognition
KW  - Humans
KW  - Electroencephalography (EEG)
KW  - brain computer interface
KW  - feature
KW  - classifier
DO  - 10.1109/ICIEA.2009.5138215
JO  - 2009 4th IEEE Conference on Industrial Electronics and Applications
IS  - 
SN  - 2158-2297
VO  - 
VL  - 
JA  - 2009 4th IEEE Conference on Industrial Electronics and Applications
Y1  - 25-27 May 2009
AB  - Brain computer interface (BCI) systems utilise Electroencephalography (EEG) to translate specific human thinking activities into control commands. An essential part of any BCI is a pattern recognition system. In this paper, a number of different features and classifiers are compared in terms of classification accuracy and computation time. Two typical features are studied: autoregressive (AR) and spectrum components along with three different classifiers; the K-nearest neighbor, linear discriminant analysis (LDA) and Bayesian statistical classifiers. The results showed that all classifiers achieved very high accuracies and short computation times.
ER  - 

TY  - JOUR
TI  - Argus: Interactive a priori Power Analysis
T2  - IEEE Transactions on Visualization and Computer Graphics
SP  - 432
EP  - 442
AU  - X. Wang
AU  - A. Eiselmayer
AU  - W. E. Mackay
AU  - K. Hornbaek
AU  - C. Wacharamanotham
PY  - 2021
KW  - Fatigue
KW  - Tools
KW  - Human computer interaction
KW  - Statistics
KW  - Sociology
KW  - Task analysis
KW  - History
KW  - Experiment design
KW  - power analysis
KW  - simulation
DO  - 10.1109/TVCG.2020.3028894
JO  - IEEE Transactions on Visualization and Computer Graphics
IS  - 2
SN  - 1941-0506
VO  - 27
VL  - 27
JA  - IEEE Transactions on Visualization and Computer Graphics
Y1  - Feb. 2021
AB  - A key challenge HCl researchers face when designing a controlled experiment is choosing the appropriate number of participants, or sample size. A priori power analysis examines the relationships among multiple parameters, including the complexity associated with human participants, e.g., order and fatigue effects, to calculate the statistical power of a given experiment design. We created Argus, a tool that supports interactive exploration of statistical power: Researchers specify experiment design scenarios with varying confounds and effect sizes. Argus then simulates data and visualizes statistical power across these scenarios, which lets researchers interactively weigh various trade-offs and make informed decisions about sample size. We describe the design and implementation of Argus, a usage scenario designing a visualization experiment, and a think-aloud study.
ER  - 

TY  - CONF
TI  - Paradigm Shift From Monolithic to Microservices
T2  - 2023 IEEE International Conference on Recent Advances in Systems Science and Engineering (RASSE)
SP  - 1
EP  - 7
AU  - D. Saxena
AU  - B. Bhowmik
PY  - 2023
KW  - Technological innovation
KW  - Software architecture
KW  - Shape
KW  - Scalability
KW  - Microservice architectures
KW  - Time to market
KW  - Computer architecture
KW  - Monolithic Architecture
KW  - Service Oriented Architecture
KW  - Microservice Architecture
KW  - Deployment
KW  - Scalability
DO  - 10.1109/RASSE60029.2023.10363466
JO  - 2023 IEEE International Conference on Recent Advances in Systems Science and Engineering (RASSE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 IEEE International Conference on Recent Advances in Systems Science and Engineering (RASSE)
Y1  - 8-11 Nov. 2023
AB  - Microservices have been making waves among forward-thinking application development organizations. In the realm of software development, software architecture holds paramount importance because it serves as a guiding force to shape the entire life cycle of a software system. Software architecture is a foundation for complex digital components built upon a software system. Within this domain, two prevalent paradigms, monolithic and service-oriented architecture (SOA), stand distinct. While monolithic simplifies development using its integrated structure, SOA reduces complexity through modular services. However, both paradigms suffer severe scalability, development cycle, and flexibility challenges. Subsequently, microservice architecture as a modern paradigm emerges to overcome these challenges. This paper presents an in-depth analysis of the paradigm shift from monolithic to microservice architecture. It begins with exploring the monolithic and SOA conceptual landscape and their pros and cons. After that, we delve into the microservice platform, including its basic architecture and implementation stages. Furthermore, we provide the trend of the paradigm shift that highlights the recent developments in the field and identifies the research challenges associated with it. Thus, the paper brings multiple research dimensions for the researchers and lets the software and application development teams improve resilience and expedite their time to market.
ER  - 

TY  - CONF
TI  - Cybernetics: Where shall we go?
T2  - 2013 IEEE International Conference on Cybernetics (CYBCO)
SP  - 25
EP  - 31
AU  - D. P. Filev
AU  - Q. Zhao
AU  - J. Brine
PY  - 2013
KW  - Cybernetics
KW  - Neurons
KW  - Animals
KW  - Ontologies
KW  - Vehicles
KW  - Organizations
KW  - Cybernetics
KW  - governance
KW  - self-governance
KW  - artificial intelligence
KW  - awareness
KW  - search
KW  - evolution
DO  - 10.1109/CYBConf.2013.6617433
JO  - 2013 IEEE International Conference on Cybernetics (CYBCO)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2013 IEEE International Conference on Cybernetics (CYBCO)
Y1  - 13-15 June 2013
AB  - Cybernetics, as defined by Plato and later by Ampère is the science of governance. In the 1940s, Wiener used cybernetics as an umbrella term to refer to control and communication in both the animal and the machine. In the following decades, the term has been defined in various ways by different researchers, and because of this, cybernetics has been perceived rather negatively as a “nomad science”. Consequently, few people understand the true meaning of cybernetics. For the appropriate development of our field of research, we think it is necessary to re-consider the meaning and the scope of cybernetics, so that we can have a relatively clear mission in our research. In this paper, we try to provide a kind of governance message that might also be very weak, but nevertheless may be helpful for the cybernetics community to become cybernetic itself.
ER  - 

TY  - JOUR
TI  - Toward a computing workload classifier
T2  - IBM Journal of Research and Development
SP  - 19:1
EP  - 19:12
AU  - T. Rojahn
AU  - R. Lebsack
AU  - C. Pavlovski
PY  - 2014
KW  - Computers
KW  - Internet
KW  - Ubiquitous computing
KW  - Information technology
KW  - Technology forecastig
KW  - Mobile communication
KW  - Business
KW  - Market research
DO  - 10.1147/JRD.2014.2352491
JO  - IBM Journal of Research and Development
IS  - 5/6
SN  - 0018-8646
VO  - 58
VL  - 58
JA  - IBM Journal of Research and Development
Y1  - Sept.-Nov. 2014
AB  - Midrange and mainframe computers have a history for supporting critical business systems. As businesses have adapted to technological changes, including the emergence of the Internet and the ubiquitous connectivity offered by mobile devices, these computers have evolved to support these trends. The availability of further server and deployment options such as x86 servers, virtualization, and cloud platforms have also presented compelling alternatives for some enterprises and their business applications. The emergence of these alternatives has challenged organizations to develop sound processes when deciding where to deploy IT applications. IT applications and supporting tools are generally referred to as workloads, and their placement is often based upon budgetary constraints rather than on a combined assessment of the qualities of service aspects such as service level, performance, security, and cost. We present an approach toward a workload classifier for several compute technologies that may assist system engineers and designers in their initial decisions of where to place particular workloads. This paper is not meant to be the final word in classifying workloads, but rather a step toward classification and to stimulate debate and thinking on the subject.
ER  - 

TY  - CONF
TI  - Visual signal representation for fast and robust object recognition
T2  - 2019 18th European Control Conference (ECC)
SP  - 3231
EP  - 3236
AU  - W. Gong
AU  - P. Kelly
AU  - C. Hollot
PY  - 2019
DO  - 10.23919/ECC.2019.8795793
JO  - 2019 18th European Control Conference (ECC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2019 18th European Control Conference (ECC)
Y1  - 25-28 June 2019
AB  - Internal signal representation is critical for accurate perception, memory, and rapid recall in natural intelligence. In this paper we consider a model for cognitive computation that has as its base an algorithm for converting spatial signals into temporal representations. The model is motivated by vision functions but is supported by applications to concept abstraction and analogical thinking, as well as experimental comparison with the pixel intensity representation of visual images. In fact our method has demonstrated ability to defend against a well-known adversarial attack on the MNIST digits recognition. Ordinal optimization is important in achieving quickness of the algorithm.
ER  - 

TY  - JOUR
TI  - Brain–Computer Interface for Shared Controls of Unmanned Aerial Vehicles
T2  - IEEE Transactions on Aerospace and Electronic Systems
SP  - 3860
EP  - 3871
AU  - Z. Bi
AU  - A. Mikkola
AU  - A. W. H. Ip
AU  - K. L. Yung
AU  - C. Luo
PY  - 2024
KW  - Autonomous aerial vehicles
KW  - Reliability
KW  - Robots
KW  - Brain-computer interfaces
KW  - Accidents
KW  - Machine intelligence
KW  - Uncertainty
DO  - 10.1109/TAES.2024.3368402
JO  - IEEE Transactions on Aerospace and Electronic Systems
IS  - 4
SN  - 1557-9603
VO  - 60
VL  - 60
JA  - IEEE Transactions on Aerospace and Electronic Systems
Y1  - Aug. 2024
AB  - To control an intelligent system in an unstructured environment, it is desirable to synergize human and machine intelligence to deal with changes and uncertainty cost-effectively. A shared control takes advantage of human and computer strengths in decision-making support, and this helps to improve the adaptability, agility, reliability, responsiveness, and resilience of the system. Since the decision spaces for human thinking and machine intelligence are quite different, challenges occur to fuse human intelligence and machine intelligence effectively. A brain–computer interface (BCI) can bridge human and machine intelligence; however, traditional BCIs are unidirectional that support interaction in one of two scenarios: first, human or machine takes effect at different control layers, and second, either human or machine takes effect at a time. There is an emerging need to close the loop of BCI-based control to alleviate the adverse effects of a machine's error or a human's mistake. In this article, available technologies for acquisition, processing, and mining of brain signals are reviewed, the needs of integrating human's capability to control unmanned aerial vehicles (UAV) are elaborated, and research challenges in advancing BCI for a shared human and machine control are discussed at the aspects of data acquisition, mapping of human's and machine's decision spaces, and the fusion of human's and machine's intelligence in automated controls. To address unsolved problems in the aforementioned aspects, we proposed a new platform of using BCI for human–machine interactions and three innovations are, first, an advanced BCI to acquire multimodal brain signals and extract features related to the intentions of motion and the quantified human's affection, second, an arbitrating mechanism in system control to determine the weight of human's decisions based on quantified human's affection, and finally, a decision support system that is capable of fusing human's and machine's decisions from different decision spaces seamlessly in controlling a UAV for real-time performance in application.
ER  - 

TY  - CONF
TI  - An overview of Hierarchical Temporal Memory: A new neocortex algorithm
T2  - 2012 Proceedings of International Conference on Modelling, Identification and Control
SP  - 1004
EP  - 1010
AU  - X. Chen
AU  - W. Wang
AU  - W. Li
PY  - 2012
KW  - Humans
KW  - Prediction algorithms
KW  - Bayesian methods
KW  - Image recognition
KW  - Artificial intelligence
KW  - Pattern recognition
KW  - Biological system modeling
KW  - hierarchical Bayesian network
KW  - spatial-temporal
KW  - memory-prediction
KW  - temporal sequence
KW  - pattern recognition
DO  - 
JO  - 2012 Proceedings of International Conference on Modelling, Identification and Control
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2012 Proceedings of International Conference on Modelling, Identification and Control
Y1  - 24-26 June 2012
AB  - The overview presents the development and application of Hierarchical Temporal Memory (HTM). HTM is a new machine learning method which was proposed by Jeff Hawkins in 2005. It is a biologically inspired cognitive method based on the principle of how human brain works. The method invites hierarchical structure and proposes a memory-prediction framework, thus making it able to predict what will happen in the near future. This overview mainly introduces the developing process of HTM, as well as its principle, characteristics, advantages and applications in vision, image processing and robots movement, some potential applications by using HTM, such as thinking process, are also put forward.
ER  - 

TY  - CONF
TI  - Methodology for the hardware/software co-design of dataflow programs
T2  - 2011 IEEE Workshop on Signal Processing Systems (SiPS)
SP  - 174
EP  - 179
AU  - G. Roquier
AU  - R. Thavot
AU  - M. Mattavelli
PY  - 2011
KW  - Hardware
KW  - Software
KW  - Field programmable gate arrays
KW  - Decoding
KW  - Multicore processing
KW  - Transform coding
KW  - dataflow programming
KW  - hardware/software co-design
KW  - reconfigurable hardware
KW  - multi-core processor
DO  - 10.1109/SiPS.2011.6088970
JO  - 2011 IEEE Workshop on Signal Processing Systems (SiPS)
IS  - 
SN  - 2162-3570
VO  - 
VL  - 
JA  - 2011 IEEE Workshop on Signal Processing Systems (SiPS)
Y1  - 4-7 Oct. 2011
AB  - New generations of multi-core processors and reconfigurable hardware platforms are expected to provide a dramatic increase of processing capabilities. However, one obstacle for exploiting all the promises of such new platforms is the legacy of current applications and the development methodologies used, which is deeply rooted in a sequential way of thinking. A paradigm shift is necessary at all levels of application development to yield portable and efficient implementations, capable of exploiting the full potential of such platforms. Dataflow programming is an alternative approach that address the problem of providing portable and scalable parallel applications. Dataflow programming is able to explicitly expose the intrinsic parallelism of applications. This paper presents a hardware/software co-design methodology that starting from a unique dataflow program enables, by the direct synthesis of both hardware (HDL) and software components (C/C++), to map a signal processing application onto heterogeneous systems architectures composed by reconfigurable hardware and multi-core processors. Experimental results based on the implementation of the MPEG-4 Simple Profile decoder onto an heterogeneous platform are also provided to show the capabilities and flexibility of the approach.
ER  - 

TY  - JOUR
TI  - Lady Lovelace’s Objection: The Turing–Hartree Disputes Over the Meaning of Digital Computers, 1946–1951
T2  - IEEE Annals of the History of Computing
SP  - 6
EP  - 18
AU  - B. Gonçalves
PY  - 2024
KW  - History
KW  - Computers
KW  - Valves
KW  - Machinery
KW  - Digital computers
KW  - Presses
KW  - Physics
DO  - 10.1109/MAHC.2023.3326607
JO  - IEEE Annals of the History of Computing
IS  - 1
SN  - 1934-1547
VO  - 46
VL  - 46
JA  - IEEE Annals of the History of Computing
Y1  - Jan.-March 2024
AB  - Can machines think? Or can they do “whatever we know how to order” them to perform? Should machines be liberated from slavery and given “fair play” to “compete with men in all purely intellectual fields”? Or should this be associated with a fashion that decries “human reason” and a path that “leads straight to Nazism”? In the postwar years, these questions were debated by Alan Turing and Douglas Hartree, who differed in their interpretations of the digital computer as a new piece of science and technology. Hartree emphasized its unprecedented calculation speed and envisioned applications in physics, logistics, energy, and warfare. Turing, who envisioned applications in biology and cognition, emphasized its potential to outperform humans intellectually, including capabilities considered distinctly human, which Hartree downplayed by mobilizing the notes of Ada Lovelace. This article examines the Turing–Hartree disputes and draws a parallel between their positions and their perspectives on postwar Britain.
ER  - 

TY  - CONF
TI  - Key technniques of distributed geospatial information operations
T2  - 2010 18th International Conference on Geoinformatics
SP  - 1
EP  - 6
AU  - L. Wu
AU  - Z. Chen
AU  - L. Ma
AU  - L. Wan
PY  - 2010
KW  - Spatial databases
KW  - Distributed databases
KW  - Geographic Information Systems
KW  - Servers
KW  - Dynamic scheduling
KW  - Software
KW  - distributed computing framework
KW  - spatial data partition
KW  - computing load balancing
KW  - GIS
DO  - 10.1109/GEOINFORMATICS.2010.5567924
JO  - 2010 18th International Conference on Geoinformatics
IS  - 
SN  - 2161-0258
VO  - 
VL  - 
JA  - 2010 18th International Conference on Geoinformatics
Y1  - 18-20 June 2010
AB  - In order to improve spatial operations efficiency of massive data in distributed environment and to solve the interactive design problems of spatial analysis processing module designed to service agreement with the underlying database, spatial data models, map display and so on. For the status quo that there is no GIS software for a practical analysis of distributed computing, we have carried out in-depth study combined with the distributed characteristics of spatial data and information. The distributed geospatial information operation framework was designed in this paper. The basic characteristics of distributed computing are analyzed in this paper. The author of this paper discussed the distributed computing spatial information technology system form following aspects: apace computing task decomposition, distributed spatial data classification method, sharing data replication strategy, the data partitioning strategy based on the load and the caching mechanism of space computing framework, based on this framework, the author has developed the system for resolving the practical problems. In this paper, the proposed distributed computing framework suitable for distributed spatial analysis has solved the key technical problems of distributed spatial analysis computing framework. And it is accordant with "service-oriented" thinking, takes into account the heterogeneity of spatial data sources, and the distributed spatial computing among the different systems on different platforms. The dynamic load scheduling has improved the static data partitioning method, it avoids the load imbalance problem in the phase of static data partitioning. It solved the efficiency of large-scale spatial data operations in the complex distributed environment in practical applications. At last, based on the software, we do the distributed clipping computing environment test of the classic space experiments, a detailed result has given at the last of the article, it has shown that, the framework is designed novelty, and can reduce the spatial computing time in the distributed environments extremely.
ER  - 

TY  - CONF
TI  - Analyses and reflection of intelligent autonomous technology for Chinese manned deep space exploration
T2  - 2016 IEEE Chinese Guidance, Navigation and Control Conference (CGNCC)
SP  - 1033
EP  - 1038
AU  - K. Lu
AU  - Z. Qi
AU  - J. Liu
AU  - W. Bao
PY  - 2016
KW  - Space vehicles
KW  - Space exploration
KW  - Moon
KW  - Orbits
KW  - Reliability
KW  - Navigation
KW  - Earth
KW  - Intelligent autonomous technology
KW  - Chinese manned deep space exploration
KW  - Development situation
KW  - Technical requirement
KW  - Development trend
DO  - 10.1109/CGNCC.2016.7828929
JO  - 2016 IEEE Chinese Guidance, Navigation and Control Conference (CGNCC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2016 IEEE Chinese Guidance, Navigation and Control Conference (CGNCC)
Y1  - 12-14 Aug. 2016
AB  - Chinese manned deep space exploration (CMDSE) will make outstanding contributions to the progress of human civilization, and make human beings understand the origin, evolution and status of the universe in a wider and deeper level. Intelligent autonomous technology, which has the ability of automatic acquisition and application of knowledge, thinking and reasoning, problem solving and automatic learning, will provide broader prospects for the development of CMDSE activities. This paper will introduce briefly the development of CMDSE and analyze the problems and challenges encountered in this missions, and summarize the requirements for intelligent autonomous technology from rocket launching, flighting into orbit, flight on orbit, celestial landing to successful return to earth. Secondly, intelligent autonomous technology will be discussed in some important fields including high reliability, low cost, adapting of different uncertainties and unknown environment disturbances, emergency handling and obtaining maximum scientific return. In addition, the prospects for the future development of CMDSE mission and the progress of intelligent autonomous technology will be discussed. Finally, in view of CMDSE mission, a system architecture which is based on intelligent sensing, intelligent computing, intelligent control, intelligent material, intelligent communication and other intelligent techniques will be presented, and the future development of those technologies will be also proposed.
ER  - 

TY  - CONF
TI  - A Study of Cloud Based Solution for Data Analytics in Healthcare
T2  - 2023 6th International Conference on Information Systems and Computer Networks (ISCON)
SP  - 1
EP  - 6
AU  - U. Gupta
AU  - R. Sharma
PY  - 2023
KW  - Industries
KW  - Cloud computing
KW  - Analytical models
KW  - Data analysis
KW  - Costs
KW  - Memory
KW  - Medical services
KW  - Big Data
KW  - Healthcare
KW  - Cloud Computing
KW  - Data Analytics
KW  - Hadoop
DO  - 10.1109/ISCON57294.2023.10112083
JO  - 2023 6th International Conference on Information Systems and Computer Networks (ISCON)
IS  - 
SN  - 2832-143X
VO  - 
VL  - 
JA  - 2023 6th International Conference on Information Systems and Computer Networks (ISCON)
Y1  - 3-4 March 2023
AB  - The healthcare industry generates vast amounts of data that are crucial for improving patient outcomes and advancing medical research. However, traditional on premise solutions for data storage and analysis can become inadequate to handle the increasing volume, variety and velocity of healthcare data. The study aims to investigate the potential benefits and challenges of using cloud-based solutions for data analytics in healthcare. This paper reports about latest development and detailed role of using Artificial intelligence and capabilities of cloud Computing in health care sector/industry to foster innovative thinking, optimum wellbeing of the patient, focused medicinal support. This paper discusses various applications, algorithms and future of big data analytics with a focus on architecture, application and applicability of big data analytics using Hadoop and Cloud Computing in healthcare industry such as monitoring, prediction, performance, management etc including intensive care unit. many cloud platforms, like MMAP, are working in this field to provide a fast, reliable cost effective, efficient, and patient centric and solution to community health issues with capability of forecasting the health impact of various diseases on community for a given region or nation. Cloud computing framework, along with Artificial intelligence and Hadoop, aids healthcare management in completing analytical computations to identify logical, pertinent, and factual trends essential to strategize and enhanced readiness in event of catastrophes by facilitating data exchange among all stake holders.
ER  - 

TY  - CONF
TI  - A reverse engineering approach to teach biology students mathematical complexity in ecology: Interdisciplinary teaching connects mathematical literacy and outdoor practice
T2  - 2014 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)
SP  - 141
EP  - 147
AU  - P. Silapachote
AU  - A. Srisuphab
AU  - S. Srikosamatara
PY  - 2014
KW  - Decision support systems
KW  - Handheld computers
KW  - Education
KW  - Conferences
KW  - Sociology
KW  - Statistics
KW  - Estimation
KW  - interdisciplinary co-teaching
KW  - active and cooperative learning
KW  - mathematical literacy
KW  - computer simulations
DO  - 10.1109/TALE.2014.7062605
JO  - 2014 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2014 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)
Y1  - 8-10 Dec. 2014
AB  - Mathematics has long held a prominent spot in common core competencies. Rapid advances in information and communication technology literacy have gained it recognition as an essential skill in the 21st century. Mastering both is a challenge, as is teaching them. Integration with other disciplines, addressing STEM education, makes this even more challenging. Tackling this dilemma, we adapt cooperative learning and co-teaching schemes. Hands-on class activities effectively convey an understanding of a complex model without equations. Computer simulations promote visual comprehensions for highly dynamic systems. In our course, general ecology for biologists, mathematical complexity is a crucial element required for transitioning from the real world to the world of numbers pertaining both linear and non-linear relationships. We designed indoor activities to initiate analytical thinking and to extend appreciations of outdoor experiences to abstract reasoning in numerical terms and computer models. Our approach fulfills the objectives of guiding biology students to construct scenarios reflecting complex interactions among organisms in the natural world. They overcame their primarily negative mindset, feeling intimidated by mathematics and uncomfortably unfamiliar with computer technology. To evaluate our teaching method, students were asked to qualitatively write an after action evaluation. They expressed enjoyment in their learning. Though struggling at times, the experience was very rewarding and worthwhile. Students came to a realization of the importance of mathematics and information literacy skills, while drawing appreciation and awareness from outdoor experiences. Besides, we quantitatively analyzed students' performance, which effectively serves as a guideline for adjusting our course contents for the next offering of this subject.
ER  - 

TY  - JOUR
TI  - Computer Scientists as Modern Hypnotists: Placing a Trance on Societal Norms
T2  - IEEE Technology and Society Magazine
SP  - 78
EP  - 87
AU  - B. Patterson
AU  - N. Sakellariou
PY  - 2019
KW  - Handheld computers
KW  - Cyberspace
KW  - Digital systems
KW  - Twitter
KW  - Facebook
KW  - Social networking (online)
KW  - Decision making
KW  - Social implications of technology
DO  - 10.1109/MTS.2019.2913074
JO  - IEEE Technology and Society Magazine
IS  - 2
SN  - 1937-416X
VO  - 38
VL  - 38
JA  - IEEE Technology and Society Magazine
Y1  - June 2019
AB  - It is without question that the use of digital technology (DT) has pervaded everyday life. From video chatting with a family member in another country, to checking the weather on a handheld computer, technology has provided society with many benefits. Social media, like Facebook (FB), Twitter, and LinkedIn, have seemingly brought the world closer, but at what cost? In this article, we show that the mass use of technology, more specifically social media, have led to the conscious will of users to be hijacked by platforms in order to increase their user-base and capital. We do this by first evaluating the impact of technology on one's conscious will, the feeling that one's actions are caused by oneself. After finding that technology makes users feel as though their actions are more consciously willed, and people naturally want to feel consciously willed, the next logical step is to analyze how modern tech companies use this to their advantage. Looking at features from popular social media, we describe how these features artificially increase the feeling of users' actions being consciously willed, regardless of if the users are actually consciously willing their actions. Finally, we discuss ways in which individuals can reclaim control over their conscious will, and how to reduce this commodification of will at a company level. The ability of a company to control the decision-making metrics of their users should strike one as troubling; whereas the power of a company to hypnotize its users into thinking that they are using the platform because they want to, and not because the company wants them to, is quite concerning.
ER  - 

TY  - CONF
TI  - Design of Two Morphing Robot Surfaces and Results from a User Study On What People Want and Expect of Them, Towards a "Robot-Room"
T2  - 2024 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 11239
EP  - 11244
AU  - N. Kumar
AU  - H. -M. Chao
AU  - B. D. Da Silva Tassari
AU  - E. Sabinson
AU  - I. D. Walker
AU  - K. E. Green
PY  - 2024
KW  - Productivity
KW  - Prototypes
KW  - Human-robot interaction
KW  - Iterative methods
KW  - Artificial intelligence
KW  - Robots
KW  - Robot surfaces
KW  - User studies
DO  - 10.1109/ICRA57147.2024.10611246
JO  - 2024 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2024 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 13-17 May 2024
AB  - We propose, examine prototypes of, and collect user input on morphing robotic surfaces, "robot-room" elements that, individually or in combination, change the functionality of the rooms we live in, directly controlled by the room’s occupants engaging with it. Robot-rooms represent an advance in human-robot interaction whereby human interaction is within a machine that physically envelops us. We discuss the motivation for such robot-rooms, present initial work aimed at their physical realization, and report on a user study of 80 participants to learn what people might want of and expect from robot rooms, the results of which will inform both the iterative design of the robot room and the thinking of our community as it grapples with how we want to live with (and "in") robots.
ER  - 

TY  - JOUR
TI  - SecuCar: Data Loss Prevention for Cloud Assisted VSS Based on Public Auditing Technique
T2  - IEEE Transactions on Vehicular Technology
SP  - 14815
EP  - 14827
AU  - S. Li
AU  - H. Zhong
AU  - L. Wang
AU  - J. Cui
AU  - J. Han
AU  - Z. Ying
AU  - G. Yang
PY  - 2023
KW  - Vehicular ad hoc networks
KW  - Servers
KW  - Security
KW  - Cloud computing
KW  - Data privacy
KW  - Industries
KW  - Clouds
KW  - VANET
KW  - cloud security
KW  - cryptographic protocol
KW  - public auditing
KW  - integrity checking
DO  - 10.1109/TVT.2023.3281728
JO  - IEEE Transactions on Vehicular Technology
IS  - 11
SN  - 1939-9359
VO  - 72
VL  - 72
JA  - IEEE Transactions on Vehicular Technology
Y1  - Nov. 2023
AB  - Intelligent and networked vehicle is a popular developing trend in future. However, Data Loss Prevention (DLP) is an import problem need to be solved. Especially, in the Vehicle Sharing System (VSS), the data authority is hard to be guaranteed based on the current technology. VSS provides the users with a convenient way to access vehicles nearby. However, the driving data security which can be used to record the driving conditions cannot be guaranteed by either cloud server or the vehicle. The camera in the cab is also not accepted because it will leak the user's privacy. This article solves this problem based on the cryptography with the public auditing technology. We design a multi-signature scheme so that the OBU and the PDA equipment of the vehicle renter can jointly sign a signature as a meta data for the driving information and upload it to the cloud server together with the raw data. In the event of a dispute, such as a vehicle accident, anyone can conduct an integrity checking with batch jobs on the stored data in the cloud server, so that the cloud and the vehicle renter cannot deny these information. We think that our scheme can be used to prevent some obvious data modification in cloud or as a part of the reference for accident identification. We also use the provable security technology to prove that our protocol is secure, and we realize its core algorithms. The experimental result shows that our scheme is efficient.
ER  - 

TY  - CONF
TI  - Using a polymorphic VLIW processor to improve schedulability and performance for mixed-criticality systems
T2  - 2017 IEEE 23rd International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)
SP  - 1
EP  - 9
AU  - J. Hoozemans
AU  - J. van Straten
AU  - S. Wong
PY  - 2017
KW  - Dynamic scheduling
KW  - Schedules
KW  - VLIW
KW  - Context
KW  - Real-time systems
KW  - Multicore processing
KW  - Timing
DO  - 10.1109/RTCSA.2017.8046315
JO  - 2017 IEEE 23rd International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)
IS  - 
SN  - 2325-1301
VO  - 
VL  - 
JA  - 2017 IEEE 23rd International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)
Y1  - 16-18 Aug. 2017
AB  - As embedded systems are faced with ever more demanding workloads and more tasks are being consolidated onto a smaller number of microcontrollers, system designers are faced with opposing requirements of increasing performance while retaining real-time analyzability. For example, one can think of the following performance-enhancing techniques: caches, branch prediction, out-of-order (OoO) superscalar processing, simultaneous multi-threading (SMT). Clearly, there is a need for a platform that can deliver high performance for non-critical tasks and full analyzability and predictability for critical tasks (mixed-criticality systems). In this paper, we demonstrate how a polymorphic VLIW processor can satisfy these seemingly contradicting goals by allowing a schedule to dynamically, i.e., at run-time, distribute the computing resources to one or multiple threads. The core provides full performance isolation between threads and can keep multiple task contexts in hardware (virtual processors, similar to SMT) between which it can switch with minimal penalty (a pipeline flush). In this work, we show that this dynamic platform can improve performance over current predictable processors (by a factor of 5 on average using the highest performing configuration), and provides schedulability that is on par with an earlier study that explored the concept of creating a dynamic processor based on a superscalar architecture. Furthermore, we measured a 15% improvement in schedulability over a heterogeneous multi-core platform with an equal number of datapaths. Finally, our VHDL design and tools (including compiler, simulator, libraries etc.) are available for download for the academic community.
ER  - 

TY  - CONF
TI  - A Literature Review: Usability Aspects of Ubiquitous Computing
T2  - 2016 International Conference on Platform Technology and Service (PlatCon)
SP  - 1
EP  - 6
AU  - S. Yagmur
PY  - 2016
KW  - Usability
KW  - Ubiquitous computing
KW  - Human computer interaction
KW  - Mobile communication
KW  - Conferences
DO  - 10.1109/PlatCon.2016.7456775
JO  - 2016 International Conference on Platform Technology and Service (PlatCon)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2016 International Conference on Platform Technology and Service (PlatCon)
Y1  - 15-17 Feb. 2016
AB  - We live in a digital world which controls our physical environment. The increasing use of wireless network supports these digital devices to use mostly people. People prefer mobile devices such as smart phones and tablets to personal computers or laptops. This brings that accessing to information and services is available any time and everywhere. This can be called ubiquitous computing. There is a high demand of pervasive computing applications and they have grown in the last years. However, a large group of people do not engage with these developments. This attracted the researchers to think this problem and they link it with usability of systems. In this study we reviewed 37 the articles which published on usability of ubiquitous computing. Within the scope of this study, the first stage is defining ubiquitous and usability. In the second stage, this paper organizes and classifies the literature on the area in order to facilitate future research. The review covers 37 peer-reviewed journal articles from 18 journals published between 2000 and 2014. The resulting framework summarizes the progress in usability studies on pervasive computing environments research and provides future research directions.
ER  - 

TY  - CONF
TI  - Research on Automatic Recognition Technology of Print Robot in Human-Computer Interaction
T2  - 2023 International Conference on Integrated Intelligence and Communication Systems (ICIICS)
SP  - 1
EP  - 5
AU  - Y. Liu
AU  - Q. Gong
AU  - C. Ji
PY  - 2023
KW  - Human computer interaction
KW  - Printing
KW  - Virtual reality
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Recording
KW  - System analysis and design
KW  - Computer
KW  - Human-Automatic Recognition
KW  - Interaction
KW  - Print
KW  - Robot
DO  - 10.1109/ICIICS59993.2023.10421076
JO  - 2023 International Conference on Integrated Intelligence and Communication Systems (ICIICS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 International Conference on Integrated Intelligence and Communication Systems (ICIICS)
Y1  - 24-25 Nov. 2023
AB  - In the digital era, the interaction between people and machines is constantly changing the way of interaction between people and between people and society, making people feel the unprecedented development of science and technology. In order to systematically study the influence of human-computer interaction on automatic recognition technology of print robot, the influence of human-computer interaction on human thinking mode, behavior mode and experience demand is analyzed. Secondly, from the perspective of media and its interaction, it describes the impact of human-computer interaction on machine recognition methods from four aspects: expanding the range of spatial information through multisource data, and improving the sensory experience through multi-channel interaction. Finally, under the background of new information technology, new interaction mode, intelligent feedback and new emotional factors, the dynamic response process is improved through real-time recording and feedback. The interaction between machines can create more opportunities for the automatic recognition technology of printing robots, and expand the research direction and the development of new designs.
ER  - 

TY  - CONF
TI  - Sketch an ICT-based Data Management Scheme for liberalizing electricity market
T2  - 2013 Eleventh International Conference on ICT and Knowledge Engineering
SP  - 1
EP  - 6
AU  - Y. -T. Chen
AU  - B. -Y. Su
PY  - 2013
KW  - Load forecasting
KW  - Electricity
KW  - Power markets
KW  - Energy management
KW  - Load modeling
KW  - Predictive models
KW  - electricity trading
KW  - energy management
KW  - load forecasting
KW  - ICT
KW  - environmental sustainability
DO  - 10.1109/ICTKE.2013.6756269
JO  - 2013 Eleventh International Conference on ICT and Knowledge Engineering
IS  - 
SN  - 2157-099X
VO  - 
VL  - 
JA  - 2013 Eleventh International Conference on ICT and Knowledge Engineering
Y1  - 20-22 Nov. 2013
AB  - Electricity has been the most important energy resource for daily applications. With the trends of continuously increasing of electricity cost and imperative need of CO2 emission reductions, forward-thinking governments are taking great importance of optimization on electricity trading for national economic and environmental developments. Although conventional electricity trading approaches such as electricity pool, bilateral market, and so on have been applied in many countries, these methods are lack of the attention to emerging renewable energy options. Based on the above, this paper presents a Data Management Scheme for Electricity Trading (DaMaSET), especially adding the role of Micro-gird. With the support of ICT-enabled load forecasting model, the proposed DaMaSET is capable of shaping an information processing module for electricity-oriented Energy Management System, addressing a valuable research direction in terms of advancing electricity trading, and further indicating a systematic perspective on energy-related environmental sustainability.
ER  - 

TY  - CONF
TI  - FAST-Based Production Monitoring Information System for Extra-High Voltage Power Line Towers
T2  - 2022 IEEE Creative Communication and Innovative Technology (ICCIT)
SP  - 1
EP  - 8
AU  - S. Sutrisna
AU  - G. Maulani
AU  - M. R. Anwar
AU  - T. Nurtino
AU  - B. Bhima
PY  - 2022
KW  - Poles and towers
KW  - Production
KW  - High-voltage techniques
KW  - Manuals
KW  - Voltage
KW  - Iron
KW  - Steel
KW  - Information System
KW  - Production Monitoring
KW  - FAST Method
DO  - 10.1109/ICCIT55355.2022.10118630
JO  - 2022 IEEE Creative Communication and Innovative Technology (ICCIT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 IEEE Creative Communication and Innovative Technology (ICCIT)
Y1  - 22-23 Nov. 2022
AB  - The role of computers is indispensable in various aspects of life, especially in the Production Monitoring information system which increases work productivity. PT Citra Banjar Abadi is a company that produces iron and steel electric towers for the needs of making High Voltage Power Line Towers, where this research takes place. The problem that occurs at this time is that the steel production monitoring information system is not optimal because it still uses a manual system so that there are often problems, one of which is the problem of production progress that cannot be monitored properly so that the completion of production is not on time. The purpose of this study is to provide solutions to problems that occur using the FAST (Framework Analytical System Thinking) method. The result of this research is to produce a steel production monitoring information system for the Tower Extra High Voltage Power Line for PT Citra Banjar Abadi, Indonesia.
ER  - 

TY  - JOUR
TI  - Prototypical Concept Representation
T2  - IEEE Transactions on Knowledge and Data Engineering
SP  - 7357
EP  - 7370
AU  - X. Wang
AU  - J. Liang
AU  - Y. Xiao
AU  - W. Wang
PY  - 2023
KW  - Prototypes
KW  - Task analysis
KW  - Taxonomy
KW  - Semantics
KW  - Context modeling
KW  - Cognition
KW  - Representation learning
KW  - Concept learning
KW  - distributed representations
KW  - knowledge graphs
KW  - machine learning
DO  - 10.1109/TKDE.2022.3180886
JO  - IEEE Transactions on Knowledge and Data Engineering
IS  - 7
SN  - 1558-2191
VO  - 35
VL  - 35
JA  - IEEE Transactions on Knowledge and Data Engineering
Y1  - 1 July 2023
AB  - Concepts are building blocks of human thinking. For machines, concept understanding has also been increasingly important, which makes concept representation a fundamental problem in artificial intelligence. While many concepts have their instances, the massive amount of information carried by instances has long been ignored in current concept representation, which limits the usage of these concepts in applications. In this paper, inspired by prototype theory in cognitive science, we propose prototypical concept representation for machines, which represents each concept with a distributed prototype derived from representations of its instances. For prototypical representation learning, we further introduce a novel model named Prototypical Siamese Network (PSN). PSN is trained under the supervision of isA determination, one of the most important concept-related applications. Results of extensive experiments demonstrate that, our method achieves state-of-the-art performance, thus validating the effectiveness of prototypical concept representation.
ER  - 

TY  - CONF
TI  - A Review of Gaps between Web 4.0 and Web 3.0 Intelligent Network Infrastructure
T2  - 2023 IEEE 9th World Forum on Internet of Things (WF-IoT)
SP  - 1
EP  - 6
AU  - Z. Zhou
AU  - Z. Li
AU  - X. Zhang
AU  - Y. Sun
AU  - H. Xu
PY  - 2023
KW  - Semantic Web
KW  - Reviews
KW  - Force
KW  - Ecosystems
KW  - Semantics
KW  - World Wide Web
KW  - Software
KW  - Routing protocols
KW  - Web sites
KW  - Artificial intelligence
KW  - Web 4.0
KW  - Web 3.0
KW  - Blockchain
KW  - Intelligence
KW  - AI
KW  - Semantic network
KW  - VR
KW  - AR
KW  - Computing Force Network
DO  - 10.1109/WF-IoT58464.2023.10539509
JO  - 2023 IEEE 9th World Forum on Internet of Things (WF-IoT)
IS  - 
SN  - 2768-1734
VO  - 
VL  - 
JA  - 2023 IEEE 9th World Forum on Internet of Things (WF-IoT)
Y1  - 12-27 Oct. 2023
AB  - World Wide Web is speeding up its pace into an intelligent and decentralized ecosystem, as seen in the campaign of Web 3.0 and forthcoming Web 4.0. Marked by the Europe Commission's latest mention of Web 4.0, a race towards strategic Web 4.0 success has started. Web 4.0 is committed to bringing the next technological transition with an open, secure, trustworthy fairness and digital ecosystem for individuals and businesses in private and public sectors. Despite overlapping scopes and objectives of Web 3.0 and Web 4.0 from academic and industrial perspectives, there are distinct and definitive features and gaps for the next generation of WWW. In this review, a brief introduction to WWW development unravels the entangled but consistent requirement of a more vivid web experience, enhancing human-centric experience in both societal and technical aspects. Moreover, the review brings a decentralized intelligence prospect of view on native AI entities for Web 4.0, envisioning sustainable, autonomous and decentralized AI services for the entire Web 4.0 environment, powering a self-sustainable Decentralized Physical and Software Infrastructure for Computing Force Network, Semantic Network, Virtual/Mixed Reality, and Privacy-preserving content presumption. The review aims to reveal that Web 4.0 offers native intelligence with focused thinking on utilizing decentralized physical infrastructure, in addition to sole requirements on decentralization, bridging the gap between Web 4.0 and Web 3.0 advances with the latest future-shaping blockchain-enabled computing and network routing protocols.
ER  - 

TY  - CONF
TI  - An Innovative Way to Teach Computer Programming for Middle and High Schools Students in Summer Camps
T2  - 2023 IEEE Frontiers in Education Conference (FIE)
SP  - 1
EP  - 9
AU  - S. Andrei
AU  - S. Wang
PY  - 2023
KW  - Printing
KW  - Java
KW  - Computer languages
KW  - Casting
KW  - Career development
KW  - Engineering profession
KW  - Stars
KW  - Computing
KW  - Scratch and Java programming languages
KW  - Summer Camp
DO  - 10.1109/FIE58773.2023.10342945
JO  - 2023 IEEE Frontiers in Education Conference (FIE)
IS  - 
SN  - 2377-634X
VO  - 
VL  - 
JA  - 2023 IEEE Frontiers in Education Conference (FIE)
Y1  - 18-21 Oct. 2023
AB  - This Innovative Practice Full Paper presents our design of teaching computer programming for middle and high school students during an one-week Summer camp for the past five years, with an interruption in the Summer of 2020 due to the Covid-19 pandemic. Many researchers believe that good Summer camps can improve many students' educational and career development outcomes. Teachers and administrators are increasingly promoting Summer camp opportunities for introducing programming skills to middle and high school students. The motivation of our program is to offer hands-on projects for middle and high school students to increase their interests and knowledge in computing to meet the growing demand. Like some Summer coding camps, we picked Scratch as the programming language (designed and offered for free by the Massachusetts Institute of Technology) for the students to learn important mathematical and computer programming concepts. In addition, the students learn how to think and reason creatively, reason systematically, and work collaboratively, while also having fun during the one-week Summer camp. For the students already familiar with Scratch, the instructor exposed students to basic concepts of Java programming language, such as Java virtual machine, computer memory, data representation, primitive data types, casting, arithmetic, and relational operators, as well as the assignment, selection and printing statements. This article presents our findings from Summer camps organized in 2018 and 2022. Our conclusion is that all students showed a better understanding of programming concepts and confidence in computing. In the upcoming paper sections, we will describe details about how we made one-week camps to be unique compared to other similar camps. One element of our own approach is to teach in an effective and innovative using an interactive teaching approach. For example, when we designed the lecture notes, we imagine that we are students taking for the first time a computer programming course. In addition, we designed simple programming exercises for the students to solve immediately. The instructors and Teaching Assistants promptly checked the solution and award the students with stars for completing the work. This environment was very well received because it was viewed as a student collegiate competition instead of a race against time. Besides learning about computer programming, we adopted during Summer camps several strategies like those enumerated earlier to enrich our camps, as well as social events, career and professional development, and academic exposure. Our findings indicate that these additional activities proved to be beneficial to our students attending the Summer camps.
ER  - 

TY  - CONF
TI  - A Comparative Analysis of the Environmental and Structural Performance of PET Bottle Designs in Sri Lanka
T2  - 2021 Moratuwa Engineering Research Conference (MERCon)
SP  - 214
EP  - 219
AU  - S. U. M. Jagoda
AU  - J. R. Gamage
AU  - H. Karunathilake
PY  - 2021
KW  - Industries
KW  - Polyethylene
KW  - Supply chains
KW  - Production
KW  - Recycling
KW  - Finite element analysis
KW  - Bottling
KW  - PET bottle design
KW  - Life cycle analysis
KW  - Environmental impact
KW  - Methodological Framework
DO  - 10.1109/MERCon52712.2021.9525802
JO  - 2021 Moratuwa Engineering Research Conference (MERCon)
IS  - 
SN  - 2691-364X
VO  - 
VL  - 
JA  - 2021 Moratuwa Engineering Research Conference (MERCon)
Y1  - 27-29 July 2021
AB  - Polyethylene Terephthalate (PET) has become the most commonly used material in the global beverage bottling industry. PET bottle production has increased by over seven times within the last three decades. However, the use of PET has a considerably detrimental effect on the environment, and many studies have been carried out on curbing this damage. Reducing the amount of material used, design for recycling, repurposing, and reusing are possible approaches for mitigating the negative environmental impacts of the PET bottle industry. The local PET bottle market has a range of products to cater the various customer requirements. To obtain a holistic vision of the actual impacts of this industry, life cycle thinking becomes necessary. The objective of this study is to present a methodological framework for comparing the environmental performance and structural performance of PET bottle designs, using case studies from the Sri Lankan market. A life cycle assessment and a finite element analysis were carried out to evaluate the overall environmental impacts of the PET supply chain and the structural performance of PET bottles. The outcomes of the study are used to provide recommendations on the short and long-term strategies to increase the eco-friendliness of the PET bottle industry.
ER  - 

TY  - CONF
TI  - Data Mining Methods for Internet of Things: A Survey
T2  - 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)
SP  - 2610
EP  - 2618
AU  - A. Saxena
AU  - R. Taluja
AU  - M. Sararswat
AU  - N. Shalini
AU  - O. Krishna
AU  - P. Kumar
PY  - 2023
KW  - Text mining
KW  - Surveys
KW  - Databases
KW  - Education
KW  - Data mining
KW  - Internet of Things
KW  - Expert systems
KW  - Database
KW  - Data Mining
KW  - Data Mining Techniques
KW  - Database Management Systems
KW  - Data Mining Processes
DO  - 10.1109/IC3I59117.2023.10397668
JO  - 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)
IS  - 
SN  - 
VO  - 6
VL  - 6
JA  - 2023 6th International Conference on Contemporary Computing and Informatics (IC3I)
Y1  - 14-16 Sept. 2023
AB  - It is fascinating to think about all the many ways in which information, intellect, and knowledge may be used in human existence. Because of the lightning-fast pace at which technology is advancing, it is now essential to amass a large quantity of data in order to forecast and investigate potential developments in the field of artificial intelligence. In order to identify new information inside databases, it is necessary to apply strategies and procedures taken from a variety of information systems specializations. The practice of data mining entails not only the finding of new information but also the extraction of information that may be put to beneficial use. In recent years, considerable advances have been made in decision-making abilities in a variety of contexts, including expert systems, artificial agent networks, and machine intelligence. These businesses include companies in the fields of commerce, education, architecture, and building construction, among others. The approach that was taken in this piece was derived from an analysis of the data mining strategies and developments that have seen the greatest amount of adoption across a variety of business sectors over the course of the last five years. These patterns and modes of operation were investigated. Throughout the course of this enquiry, the processes and patterns described above were scrutinized. The use of text mining as a tool for database analysis, the enhancement of worker productivity in the industrial sector, and the application of data mining for instructional practices are only a few instances of what has been learnt in the area of education. One other illustration of this would be the use of text mining as a technique for image recognition. It was also found in the fields of trade and industry.
ER  - 

TY  - JOUR
TI  - Extended JSSL for Multi-Feature Face Recognition via Intra-Class Variant Dictionary
T2  - IEEE Access
SP  - 91807
EP  - 91819
AU  - G. Lin
AU  - Q. Zhang
AU  - S. Zhou
AU  - X. Jiang
AU  - H. Wu
AU  - H. You
AU  - Z. Li
AU  - P. He
AU  - H. Li
PY  - 2021
KW  - Face recognition
KW  - Feature extraction
KW  - Training
KW  - Testing
KW  - Dictionaries
KW  - Data mining
KW  - Collaboration
KW  - Sparse representation
KW  - image classification
KW  - multi-feature
KW  - face recognition
DO  - 10.1109/ACCESS.2021.3089836
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 9
VL  - 9
JA  - IEEE Access
Y1  - 2021
AB  - This paper focuses on how to represent the testing face images for multi-feature face recognition. The choice of feature is critical for face recognition. The different features of the sample contribute differently to face recognition. The joint similar and specific learning (JSSL) has been effectively applied in multi-feature face recognition. In the JSSL, although the representation coefficient is divided into the similar coefficient and the specific coefficient, there is the disadvantage that the training images cannot represent the testing images well, because there are probable expressions, illuminations and disguises in the testing images. We think that the intra-class variations of one person can be linearly represented by those of other people. In order to solve well the disadvantage of JSSL, in the paper, we extend JSSL and propose the extended joint similar and specific learning (EJSSL) for multi-feature face recognition. EJSSL constructs the intra-class variant dictionary to represent the probable variation between the training images and the testing images. EJSSL uses the training images and the intra-class variant dictionary to effectively represent the testing images. The proposed EJSSL method is perfectly experimented on some available face databases, and its performance is superior to many current face recognition methods.
ER  - 

TY  - CONF
TI  - Redefining the Performance Management using Emotional Artificial Intelligence
T2  - 2023 International Conference on Applied Intelligence and Sustainable Computing (ICAISC)
SP  - 1
EP  - 8
AU  - P. Govindasamy
AU  - R. S. Ganesh
AU  - R. Ramesh
PY  - 2023
KW  - Productivity
KW  - Human intelligence
KW  - Employment
KW  - Buildings
KW  - Collaboration
KW  - Organizations
KW  - Artificial intelligence
KW  - Artificial Intelligence
KW  - Performance Management.
DO  - 10.1109/ICAISC58445.2023.10200202
JO  - 2023 International Conference on Applied Intelligence and Sustainable Computing (ICAISC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 International Conference on Applied Intelligence and Sustainable Computing (ICAISC)
Y1  - 16-17 June 2023
AB  - Over the last two decades, the relevant literature has focused a lot on the human intelligence of (EI) and the machine intelligence of AI. The present research integrates these two schools of thinking and examines how employee retention and productivity are impacted by mental agility and artificial intelligence. How successfully individuals execute tasks during their internal and external services contacts with clients and colleagues, respectively. These interactions may take place either internally or outside and are categorized as either internal or external. The research demonstrates that emotive artificial intelligence has a major effect on both the performance of employees and their retention rates.
ER  - 

TY  - CONF
TI  - A dramaturgical exploration of engineering judgment processes in undergraduate student writing
T2  - 2021 IEEE Frontiers in Education Conference (FIE)
SP  - 1
EP  - 9
AU  - R. Francis
AU  - R. Riedner
AU  - M. Paretti
PY  - 2021
KW  - Navigation
KW  - Conferences
KW  - Writing
KW  - Complexity theory
KW  - Task analysis
KW  - Interviews
KW  - Engineering students
KW  - engineering judgment
KW  - engineering identity
KW  - thematic analysis
KW  - dramaturgical analysis
DO  - 10.1109/FIE49875.2021.9637349
JO  - 2021 IEEE Frontiers in Education Conference (FIE)
IS  - 
SN  - 2377-634X
VO  - 
VL  - 
JA  - 2021 IEEE Frontiers in Education Conference (FIE)
Y1  - 13-16 Oct. 2021
AB  - The objective of this full paper is to explore the interplay between engineering judgment and communication practices involved in completing an undergraduate systems engineering senior project. We view engineering judgment as an embodied process that emerges through discourse as individuals position themselves relative to both other individuals and disciplinary norms in a range of contexts. It happens, broadly, through a series of tasks and thinking processes through which students choose and formulate problems, make assumptions, select data, and adopt roles in relation to disciplinary norms in different contexts. We explore this conceptualization of engineering judgment using thematic and dramaturgical analysis of a single case. The data collected are a semi-structured 90-minute interview collected with one systems engineering senior after completion of their senior project and graduation from their degree program. These data are first coded using a thematic analysis approach, then re-analyzed using a dramaturgical approach. Our findings raise important issues about the blend of communication demands faced by practicing engineers that potentially impact the socialization of engineering students. Different communication demands require students to use different ways to navigate complexity. The varied communication forms also prompt students to view themselves as professionals with the capacity to judge and act from a position of professional authority that vary with the situational context.
ER  - 

TY  - CONF
TI  - Cyborg Intelligence-Current study and challenges
T2  - 2023 5th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)
SP  - 930
EP  - 935
AU  - R. Singh
AU  - J. Padma
AU  - J. Singh
PY  - 2023
KW  - Legged locomotion
KW  - Program processors
KW  - Human-machine systems
KW  - Humanoid robots
KW  - Software
KW  - Biology
KW  - Artificial intelligence
KW  - Cyborg intelligence
KW  - Rat cyborgs spatial cognition
KW  - Bio robotics Cyborgology
DO  - 10.1109/ICAC3N60023.2023.10541749
JO  - 2023 5th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 5th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)
Y1  - 15-16 Dec. 2023
AB  - Cyborg Intelligence is a major component in replacing lost body part functions in the twenty-first century by incorporating cyborg technology; a human body will be able to function even if it loses one or more of its functioning parts, such as its arms or legs, which would significantly benefit society. The study of cyborgs and the creation of humanoid robots from them Cyborgs, as the title implies, are hybrids of humans and robots. The study examines cyborg technology that is cybernetic. An artificial intelligence is referred to as a cyborg in this context. Artificial intelligence, sometimes referred to as machine intelligence, is the ability of a computer to create software and act and think like a human. Cybernetics is a branch of science that focuses on the fundamentals of communication and control in both machines and biological things. The discussion of how cybernetics and artificial intelligence interact will be the main focus of this article. Additionally, this article will assess cyborg technology in the real world, examining its benefits and drawbacks as well as the ways in which cyborgs and robots are different. Cyborgs are conceivable in today’s world. A cyborg is a humanoid robot or, more accurately, a hybrid of humans and robots. Robots are mechanical humans that depend on the intellect offered by people. With the use of artificial intelligence, cyborgs may now create their own algorithms. The fusion of logic and technology is a key aspect in the creation of a cyborg.
ER  - 

TY  - CONF
TI  - A Fuzzy Statistical Perspective for Empirical Evaluation of EEG Classification Models for Epileptic Seizures
T2  - 2022 International Conference on Emerging Smart Computing and Informatics (ESCI)
SP  - 1
EP  - 6
AU  - R. Suryawanshi
AU  - S. Vanjale
AU  - M. Vanjale
PY  - 2022
KW  - Support vector machines
KW  - Transfer learning
KW  - Signal processing algorithms
KW  - Brain modeling
KW  - Feature extraction
KW  - Electroencephalography
KW  - Real-time systems
KW  - EEG
KW  - classification
KW  - deep learning
KW  - convolutional
KW  - neural
KW  - network
KW  - epileptic & non-epileptic seizure
DO  - 10.1109/ESCI53509.2022.9758337
JO  - 2022 International Conference on Emerging Smart Computing and Informatics (ESCI)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 International Conference on Emerging Smart Computing and Informatics (ESCI)
Y1  - 9-11 March 2022
AB  - Electroencephalography (EEG) signals are a combination of complex pattern sequences, which are periodic in nature. These pattern sequences include a gamma waves that indicates deep thinking behaviour, a beta wave sequence that indicates busy and active mind status, an alpha wave segment which indicates reflective and restful behaviour, a theta wave which is an indicative of drowsiness, and a delta wave which indicates sleeping & dreaming conditions. Features like frequency changes, amplitude changes, pattern changes, etc. are used to identify chronic, ischemic and other diseases related to the brain. In order to classify these wave patterns into brain diseases like epilepsy, a series of high complexity signal processing operations are needed to be executed in tandem. These operations include signal pre-processing, feature extraction, feature selection, classification into epileptic & non-epileptic seizure and post-processing. A large variety of algorithms are developed by researchers for each of these operations. Performance of these algorithms varies largely w.r.t. the number of leads used for EEG capture, filtering efficiency, feature extraction & selection efficiency, and classifier efficiency. Thus, it becomes ambiguous for researchers and system designers to select the best possible algorithm set for their application. In order to reduce the ambiguity, this text provides a comprehensive comparison of a wide variety of epileptic & non-epileptic seizure classification system models. These models are statistically compared on the basis of overall accuracy, delay of decision making, precision, recall, f-measure and field of application. It is observed that convolutional neural network (CNN) based models outperform other models in terms of general-purpose performance, while specialized CNN models must be used for application specific deployments.
ER  - 

TY  - CONF
TI  - Research on Path Planning of Mobile Robot Based on A* Algorithm
T2  - 2024 International Conference on Intelligent Computing and Robotics (ICICR)
SP  - 189
EP  - 194
AU  - C. Duan
AU  - P. Zhang
PY  - 2024
KW  - Smoothing methods
KW  - Service robots
KW  - Trajectory planning
KW  - Heuristic algorithms
KW  - Power system stability
KW  - Stability analysis
KW  - Real-time systems
KW  - Mobile robot
KW  - Path planning
KW  - A * algorithm
KW  - Grid method
KW  - MATLAB
DO  - 10.1109/ICICR61203.2024.00042
JO  - 2024 International Conference on Intelligent Computing and Robotics (ICICR)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2024 International Conference on Intelligent Computing and Robotics (ICICR)
Y1  - 12-14 April 2024
AB  - Mobile robots are widely used in industrial, medical, agricultural and other scenarios. The core technology is path planning. The existing methods have limited ability to deal with complex environment, low search efficiency, unsmooth path, easy to trap local optimum, and lack of real-time performance. Intelligent algorithm is a better method to solve this problem. Because the A * algorithm has strong search ability, clear algorithm thinking, and can be constrained to the global optimal path, it has the advantages of high efficiency, stability and optimality. Therefore, a motion trajectory planning method based on A * algorithm is proposed for mobile robots. Firstly, this paper analyzes several commonly used mobile robot path planning algorithms, and selects the A * algorithm as the object of this study. Secondly, the working principle, advantages and disadvantages of the A * algorithm are introduced in detail, as well as the design modules of the A * algorithm. Then, the problem of motion trajectory planning for mobile robots is analyzed and a solution is proposed. Aiming at the problems of low planning efficiency, turning path, sharp and unsmooth path, the efficiency and stability of A * algorithm are optimized by adding heuristic algorithm, corner optimization and path smoothing. Finally, the working environment of the mobile robot is established by using the grid method, and the path planning simulation experiment is carried out on the MATLAB platform. The experimental results show that the method of path planning using A * algorithm is effective and has a wide application prospect.
ER  - 

TY  - CONF
TI  - Smart transition management to smarten energy systems in a deeply uncertain world
T2  - 2011 Proceedings of PICMET '11: Technology Management in the Energy Smart World (PICMET)
SP  - 1
EP  - 9
AU  - E. Pruyt
PY  - 2011
KW  - Robustness
DO  - 
JO  - 2011 Proceedings of PICMET '11: Technology Management in the Energy Smart World (PICMET)
IS  - 
SN  - 2159-5100
VO  - 
VL  - 
JA  - 2011 Proceedings of PICMET '11: Technology Management in the Energy Smart World (PICMET)
Y1  - 31 July-4 Aug. 2011
AB  - Enormous future investments are needed to replace old energy systems/technologies, and prepare them for future needs. Moreover, smarter technologies/systems are needed. And in this ever more complex, interconnected, and uncertain world, smarter policymaking in the energy field is certainly needed too. After all, current energy policymaking still mainly ignores (dynamic) complexity and (deep) uncertainty. This paper illustrates two model-based approaches for supporting policymaking for complex and uncertain issues as well as their combination. First, Exploratory System Dynamics Modeling and Analysis allows exploring and analyzing millions of plausible (uncertain) dynamic system behaviors and testing the robustness of policies. This approach is illustrated by means of a System Dynamics simulation model related to energy grid investments. Second, Experiential Model-Based Gaming allows policymakers to experience dynamic complexity and deep uncertainty, and helps them feel the need to embrace both in policymaking. Before having experienced different plausible futures, almost all high-level managers and highly-educated students that played such experiential games applied inappropriate strategies in most plausible futures played, and hence failed in the face of uncertainty. Failing repeatedly actually prepared them for thinking outside their old/reactive/predictive modes in subsequent bounce-casting sessions. Exploratory System Dynamics Modeling and Analysis and Experiential Model-Based Gaming may also be mutually beneficial: most subjects only acknowledge the need to take uncertainty and dynamic complexity seriously into account after having participated in experience-oriented gaming sessions.
ER  - 

TY  - CONF
TI  - Crop Recommendation Using Machine Learning
T2  - 2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)
SP  - 1
EP  - 6
AU  - V. S. Priya
AU  - B. V. Ramana
AU  - A. S. Kumar
AU  - A. Tanvireddy
AU  - A. Jasta
PY  - 2023
KW  - Support vector machines
KW  - Scalability
KW  - Forestry
KW  - Prediction algorithms
KW  - Robustness
KW  - Decision trees
KW  - Climate change
KW  - Agriculture
KW  - Crop Prediction
KW  - Data Mining
KW  - Random Forest Algorithm
KW  - Crop yield
DO  - 10.1109/RMKMATE59243.2023.10369475
JO  - 2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)
Y1  - 1-2 Nov. 2023
AB  - In current decades India has knowing a significant decline in land crop depiction generally due to the damaging belongings of feeling change accurate prognosis of crop yield before harvest is essential for laborers and policymakers to make conversant resolutions concerning marketing and depository this project aims to evolve an common prediction method original that allows farmers to estimate crop result before education bureaucracy will feature a user-friendly netting-located graphical interface and engage a machine intelligence invention anticipated effects will be determined to laborers empowering ruling class to create appropriate resolutions based on the news miscellaneous methods and algorithms including the usual chance forest invention will be promoted to resolve essential variables such as weather environments heat dampness rainfall and liquid for land result forecasting furthermore dossier excavating a comprehensive approach to resolving dossier from multiple outlooks will be used to extract valuable judgments random thicket a strong directed machine learning treasure worthy operating classification and reversion tasks builds an ensemble of conclusion trees all along preparation and generates prophecies established the fad of classes classification or the mean prognosis reversion from individual shrubs by integrating these methods this project aims to specify an direct solution for thinking crop yield in India portion of food to address the challenges formal by climate change in the land area
ER  - 

TY  - CONF
TI  - Acceleration and Implementation of Database Aggregation Query Based on FPGA
T2  - 2023 China Automation Congress (CAC)
SP  - 817
EP  - 822
AU  - H. Zhang
AU  - D. Jia
AU  - L. Chen
AU  - X. Wang
AU  - S. Wang
AU  - R. Li
PY  - 2023
KW  - Databases
KW  - Query processing
KW  - Software algorithms
KW  - Collaboration
KW  - Computer architecture
KW  - Relational databases
KW  - Parallel processing
KW  - database
KW  - FPGA
KW  - heterogeneous acceleration
KW  - aggregation
KW  - hash grouping
KW  - aggregation function
DO  - 10.1109/CAC59555.2023.10452115
JO  - 2023 China Automation Congress (CAC)
IS  - 
SN  - 2688-0938
VO  - 
VL  - 
JA  - 2023 China Automation Congress (CAC)
Y1  - 17-19 Nov. 2023
AB  - Database is an important carrier to meet information overall management. With the continuous development of global information construction in recent years, the types and quantities of information stored in databases are increasing. Implementing high-speed query response to massive database storage resources through hardware-level optimization design has become an important research direction in related fields. Aiming at the key problems such as low efficiency and high delay existing in the process of performing aggregation operation in the current mainstream database, this paper thorough analysis the principles and key steps of database execution of aggregation queries, and a new FPGA-based database aggregation query accelerator is designed using heterogeneous thinking. The accelerator is designed according to the actual application scenario of relational database aggregation query, and implements the aggregation grouping strategy based on hash algorithm and five commonly used aggregation functions through FPGA; In order to maximize processing efficiency and fully utilize the excellent parallel processing capabilities of FPGA, this study also optimizes the existing aggregation query architecture and proposes a decentralized multi-core collaborative aggregation query architecture to meet the needs of single time period and multithreaded queries. The aggregation query experiments on ZNBase, an open source database platform, show that the proposed database aggregation query accelerator based on FPGA is 21.71 times more efficient than the traditional software algorithm to realize the aggregation query scheme.
ER  - 

TY  - CONF
TI  - Remixing Minecraft to broaden participation in computing
T2  - 2016 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)
SP  - 1
EP  - 1
AU  - U. Acholonu
AU  - D. Amato
AU  - J. Dickinson
AU  - L. Smith
AU  - J. Engel
AU  - E. Walker
AU  - G. Grant
AU  - N. Pinkard
PY  - 2016
KW  - Organizations
KW  - Games
KW  - Urban areas
KW  - Media
KW  - Electronic mail
KW  - YouTube
KW  - Servers
DO  - 10.1109/RESPECT.2016.7836183
JO  - 2016 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2016 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)
Y1  - 11-13 Aug. 2016
AB  - Minecraft is one of the most popular games among youth today, experiencing sales over 100 million worldwide and channels on YouTube generating over 47 billion views. Our interest in the game environment is due to its innate computational mechanics that integrate logic, design, and scripting elements. Because of these traits, many organizations and schools are looking to incorporate Minecraft into their curriculum to support computational thinking and computational practices. However, there are challenges surrounding the distribution and availability of individuals who possess the technical and computational expertise needed to support these opportunities. In this poster we introduce the DYN Minecraft Server project. The project is designed to address barriers of entry for adults at schools and youth-serving organizations who want to provide computing-related learning opportunities to diverse youth. We worked with families, city organizations, mentors, and youth to modify the commercially available Minecraft to support adults who may have limited expertise in computing or Minecraft, yet wish to use the platform in order to teach computational content The modifications include the integration of an information network that promotes STEM learning opportunities that are available throughout the city. We discuss our design process, designed activities and interfaces, and feedback from youth, partners, and mentors using the system.
ER  - 

TY  - JOUR
TI  - Combining the Attention Network and Semantic Representation for Chinese Verb Metaphor Identification
T2  - IEEE Access
SP  - 137103
EP  - 137110
AU  - D. Zhang
AU  - H. Lin
AU  - X. Liu
AU  - H. Zhang
AU  - S. Zhang
PY  - 2019
KW  - Thesauri
KW  - Semantics
KW  - Task analysis
KW  - Deep learning
KW  - Computational modeling
KW  - Natural language processing
KW  - Attention network
KW  - metaphor identification
KW  - metaphor dataset
KW  - semantic representation
DO  - 10.1109/ACCESS.2019.2932136
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 7
VL  - 7
JA  - IEEE Access
Y1  - 2019
AB  - Metaphor is the central issue of language and thinking. Metaphor identification plays a significant preliminary role in the field of machine translation, reading comprehension, and automatic summarization, making it a focus of natural language processing. Recently, research into Chinese verb metaphor identification has become a widespread concern. The main problem is that the usage of semantic resources is relatively simple, and there is a lack of deep semantic support. Therefore, this paper proposes a word representation method suitable for metaphor classification tasks, which combines the traditional word vector with structural information from the Synonym Thesaurus, so that the word vector can contain the abstraction degree of the word in the metaphor. On this basis, we propose a verb metaphor attention network based on subject-predicate and verb-object relationships, which gives full consideration to the global syntactic information when we perform LSTM encoding and calculate the weight of each word. At the same time, it can facilitate the understanding of literalness and non-literalness. The experimental results show that the identification effect improves on the existing results, indicating that word representation combining semantic resources and attention network can improve the verb metaphor identification performance.
ER  - 

TY  - JOUR
TI  - Trident-LK Net: A Lightweight Trident Structure Network With Large Kernel for Muti-Scale Defect Detection
T2  - IEEE Access
SP  - 131073
EP  - 131080
AU  - S. Yang
AU  - X. Wang
AU  - X. Qian
AU  - Y. Yu
AU  - W. Jin
PY  - 2023
KW  - Feature extraction
KW  - Convolutional neural networks
KW  - Kernel
KW  - Computational modeling
KW  - Detectors
KW  - Data mining
KW  - Steel
KW  - Industrial engineering
KW  - Structural engineering
KW  - Convolutional neural network
KW  - defect detection
KW  - feature fusion
KW  - lightweight network
DO  - 10.1109/ACCESS.2023.3333918
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 11
VL  - 11
JA  - IEEE Access
Y1  - 2023
AB  - Identifying defects at different scales is a challenge in industrial defect detection. To solve this problem, many multi-scale feature fusion networks have been proposed to improve multi-scale target detection accuracy by fusing fine-grained information from shallow networks and semantic information from deep networks. This approach requires the introduction of extraÂ parameters. Thinking from another perspective, can the accuracy of multi-scale target detection be improved by fusing the feature information under different receptive fields? For this purpose, we designed a three-layer network structure called Trident-LK Net. our model uses convolutional kernels of different sizes (31, 25, 1) in the feature extraction phase and establishes cross-fusion connections. This omits the feature fusion part and greatly reduces the network parameters while obtaining a good detection accuracy. Finally we perform experiments on the neu-det dataset and the gc10 dataset to verify the feasibility of our idea. While keeping the number of parameters to a minimum, our model achieves competitive detection results on the neu-det dataset (76.9% mAP) and optimal on the gc10 dataset (63.55% mAP). Our code will be publicly available at https://github.com/syyang2022/Trident-LK-Net.
ER  - 

TY  - JOUR
TI  - Explainability as a Method for Learning From Computers
T2  - IEEE Access
SP  - 35853
EP  - 35865
AU  - M. Klimo
AU  - J. Kopčan
AU  - L. Králik
PY  - 2023
KW  - Feature extraction
KW  - Neural networks
KW  - Decision making
KW  - Data mining
KW  - Deep learning
KW  - Fuzzy logic
KW  - Computational modeling
KW  - Explainability
KW  - feature extraction
KW  - neural networks
KW  - machine learning
KW  - pattern classification
DO  - 10.1109/ACCESS.2023.3265582
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 11
VL  - 11
JA  - IEEE Access
Y1  - 2023
AB  - Humans have rich experience applying linear models and logical thinking, but only experts understand the behaviour of non-linear systems. However, the deep neural network (DNN) implementation of text non-linear systems outperforms optimal linear models. Therefore, the forward DNN (the pattern recognition system in this paper) attracts attention to the necessity of interpreting the results obtained by DNN. To preserve the high performance of DNN, we focus on a post-hoc explanation; this approach means building an explainable model for the decision obtained by the black box. To avoid the interpretation of a set of millions of non-linear functions, we divide DNN into two parts: the feature extractor and the classifier. Following that, we argue for a specific interpretation of each of them. While for classifiers, we have several suitable explainable models (and we decided on the fuzzy logical function), we believe that feature interpretation is a creative scientific activity corresponding to the usual research. The paper presents a tool to help researchers and users understand extracted features not necessarily known in the specific application domain. Explaining the new features offers a way to learn from computers.
ER  - 

TY  - JOUR
TI  - An Improved Lightweight YOLOv5 Algorithm for Detecting Railway Catenary Hanging String
T2  - IEEE Access
SP  - 114061
EP  - 114070
AU  - S. Zhang
AU  - Y. Chang
AU  - S. Wang
AU  - Y. Li
AU  - T. Gu
PY  - 2023
KW  - Feature extraction
KW  - Convolutional neural networks
KW  - Deep learning
KW  - Rail transportation
KW  - Training
KW  - Predictive models
KW  - Computational efficiency
KW  - YOLO
KW  - YOLOv5
KW  - lightweight network
KW  - image detection
KW  - railway
KW  - deep learning
DO  - 10.1109/ACCESS.2023.3322444
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 11
VL  - 11
JA  - IEEE Access
Y1  - 2023
AB  - Aiming at the problems of small target and low recognition accuracy of high-speed railway contact network hanging chord defects, this paper proposes a target detection algorithm for hanging chord defects based on YOLOv5. To enhance the original YOLOv5 algorithm, the MobielNetv3 module was used as the efficient and lightweight backbone feature extraction network. Depth-separable convolution was adopted instead of standard convolution, reducing the number of network parameters by  $2\times 10 ^{6}$  and increasing detection speed by 23%. Introducing BiFPN feature pyramid structure with fusion of different feature layers in neck network improves detection accuracy by 0.4%. Adding CBAM attention mechanism at the prediction end improves the feature extraction ability of the model for small target images, which further improves the detection accuracy by 0.5%. The loss function CIoU was improved to Focal EIoU in order to solve the problems of unbalanced sample datasets and vanishing IoU gradients during the training process. The experimental results exhibit that the improved algorithm achieves an average accuracy of 98.5% on the dataset, a 39% enchancment in model detection speed and a 28% reduction in model parameters, verifying that the algorithm has the advantages of high recognition accuracy and fast detection speed. It can effectively solve the technical difficulties in the detection of defects in the existing contact network suspension chords, and provides a new way of thinking for intelligent railway inspection.
ER  - 

TY  - JOUR
TI  - Securing Consumer Electronics Devices: A Blockchain-Based Access Management Approach Enhanced by Deep Learning Threat Modeling for IoT Ecosystems
T2  - IEEE Access
SP  - 110671
EP  - 110680
AU  - M. M. Asiri
AU  - H. Alfraihi
AU  - Y. Said
AU  - K. M. Othman
AU  - A. S. Salama
AU  - R. Marzouk
PY  - 2024
KW  - Biological system modeling
KW  - Safety
KW  - Consumer electronics
KW  - Internet of Things
KW  - Computational modeling
KW  - Threat modeling
KW  - Ecosystems
KW  - Blockchains
KW  - Deep learning
KW  - Search methods
KW  - Evidence theory
KW  - Blockchain
KW  - Internet of Things
KW  - deep learning
KW  - reptile search algorithm
KW  - deep belief network
DO  - 10.1109/ACCESS.2024.3441094
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 12
VL  - 12
JA  - IEEE Access
Y1  - 2024
AB  - Securing user electronics devices has become a significant concern in the digital period, and a forward-thinking solution covers the fusion of blockchain (BC) technology and deep learning (DL) methods. Blockchain improves device safety by transforming access management, storing credentials on a tamper-resistant ledger, mitigating the risk of unauthorized access and giving a robust defence against malevolent actors. Integrating DL into this framework also raises safety measures, as it permits devices to inspect and regulate to develop attacks distinctly. DL models accurately recognize intricate designs and anomalies, allowing the technique to distinguish and threaten possible attacks in real time. The fusion of BC and DL not only improves the reliability of user electronics but also establishes a dynamic and adaptive safety system, enhancing consumer confidence in the safety of their devices. Therefore, this study presents a BC-Based Access Management with DL Threat Modeling (BCAM-DLTM) technique for securing consumer electronics devices in the IoT ecosystems. The BCAM-DLTM technique mainly follows a two-phase procedure: access management and threat detection. Moreover, BC technology can be applied to the access management of consumer electronics devices. Besides, the BCAM-DLTM technique applies a deep belief networks (DBNs) model for proficiently identifying threats. To enhance the recognition results of the DBN model, the hyperparameter tuning procedure uses the reptile search algorithm (RSA). The experimental outcome study of the BCAM-DLTM approach employs the NSLKDD dataset. The comprehensive results of the BCAM-DLTM approach portrayed a superior accuracy outcome of 99.63% over existing models in terms of distinct metrics.
ER  - 

TY  - JOUR
TI  - Cognitive Dynamic System for Control and Cyber-Attack Detection in Smart Grid
T2  - IEEE Access
SP  - 78320
EP  - 78335
AU  - M. I. Oozeer
AU  - S. Haykin
PY  - 2019
KW  - State estimation
KW  - Transmission line measurements
KW  - Power measurement
KW  - Smart grids
KW  - Measurement uncertainty
KW  - Mathematical model
KW  - Voltage measurement
KW  - Bad data detection (BDD)
KW  - false data injection
KW  - cognitive dynamic systems
KW  - cognitive control
KW  - cumulative sum (CUSUM)
KW  - cyber-physical attack
KW  - cyber-physical systems
KW  - online estimation
KW  - smart grid
KW  - smart grid security
DO  - 10.1109/ACCESS.2019.2922410
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 7
VL  - 7
JA  - IEEE Access
Y1  - 2019
AB  - This paper introduces a new way of thinking that characterizes itself by uniting two entities, namely state estimation in the smart grid (SG) and cognitive dynamic system (CDS). False data injection (FDI) attacks are a family of new attacks that have been considered to be the most dangerous cyber-attack as it leads to cascaded bad decision making throughout the SG network, which can lead to severe repercussions. The conventional state estimation and bad data detection techniques, which have been applied to reduce observation errors and detect bad data in energy system state estimators, cannot detect FDI attacks. Here, we bring into play an objective-seeking system to act as the supervisor of the SG network. To this end, we propose to introduce a new metric for the SG: the entropic state. The entropic state has two purposes: 1) it provides an indication of the grid's health on a cycle-to-cycle basis and 2) it can be used to detect FDI attacks. Consequently, improving the entropic state is the goal of the supervisor. To achieve that objective, the supervisor dynamically optimizes the state estimation process by reconfiguring the weights of the sensors in the network. With optimality in mind, the CDS is the superior choice for the supervisory system. In this structure, the CDS interacts with the SG network, which is considered as the environment. Computer simulations are carried out on a 4-bus and the IEEE 14-bus systems to highlight the performance of the proposed approach in detecting both bad data and FDI attacks in the SG, respectively.
ER  - 

TY  - JOUR
TI  - Holochain: An Agent-Centric Distributed Hash Table Security in Smart IoT Applications
T2  - IEEE Access
SP  - 81205
EP  - 81223
AU  - S. Gaba
AU  - H. Khan
AU  - K. J. Almalki
AU  - A. Jabbari
AU  - I. Budhiraja
AU  - V. Kumar
AU  - A. Singh
AU  - K. K. Singh
AU  - S. S. Askar
AU  - M. Abouhawwash
PY  - 2023
KW  - Internet of Things
KW  - Blockchains
KW  - Decentralized applications
KW  - Distributed ledger
KW  - Security
KW  - Peer-to-peer computing
KW  - Array signal processing
KW  - Distributed ledger
KW  - Holochain
KW  - communication infrastructure
KW  - holo
KW  - ledger
KW  - process models
KW  - distributed ledger technology
KW  - agent centric technology
KW  - blockchain
DO  - 10.1109/ACCESS.2023.3300220
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 11
VL  - 11
JA  - IEEE Access
Y1  - 2023
AB  - The accomplishment of blockchain has increased the focus on the various applications for simplifying the confidentiality and transaction sanctuary using the decentralized architecture via consensus mechanisms between different internet of things (IoT) nodes in daily increasing societal areas. The growth of blockchain lasted to grow and used to do compare technologies. The major shortcomings of blockchain is the lack of scalability in modern application settings. Holochain technology vends itself as a “thinking” exterior to blocks, and it is a peer-to-peer disseminated ledger technology. It works contrarily compared to the blockchain, and it offers an exclusive value in the existing market. IoT devices are continuously used in distributed environments, in various smart applications. The peer-to-peer IoT networks, connected to smart agricultural systems are exposed to the security issues. Specifically, the personal data of agricultural land records need protection against unauthorized access and eradicate corruption in land transactions. The Blockchain offers a possible solution based on distributed ledger, but it has scalability issues due to high storage and processing requirements with growing network size. Also data is not locally stored in a Blockchain. This paper studies the conventions of holochain technology, its architecture and challenges, and critical mechanisms of holochain applications. We also analyze the numerous models utilized for the implementation of protected transactions. We discuss an agent centric framework with distributed hash table for secured applications.
ER  - 

TY  - JOUR
TI  - Two promising future developments of cryo-EM: capturing short-lived states and mapping a continuum of states of a macromolecule
T2  - Microscopy
SP  - 69
EP  - 79
AU  - B. Chen
AU  - J. Frank
PY  - 2016
KW  - classification
KW  - manifold embedding
KW  - microfluidics
KW  - ribosome
KW  - time-resolved imaging
KW  - translation
DO  - 10.1093/jmicro/dfv344
JO  - Microscopy
IS  - 1
SN  - 1477-9986
VO  - 65
VL  - 65
JA  - Microscopy
Y1  - Feb. 2016
AB  - The capabilities and application range of cryogenic electron microscopy (cryo-EM) method have expanded vastly in the last two years, thanks to the advances provided by direct detection devices and computational classification tools. We take this review as an opportunity to sketch out promising developments of cryo-EM in two important directions: (i) imaging of short-lived states (10–1000 ms) of biological molecules by using time-resolved cryo-EM, particularly the mixing-spraying method and (ii) recovering an entire continuum of coexisting states from the same sample by employing a computational technique called manifold embedding. It is tempting to think of combining these two methods, to elucidate the way the states of a molecular machine such as the ribosome branch and unfold. This idea awaits further developments of both methods, particularly by increasing the data yield of the time-resolved cryo-EM method and by developing the manifold embedding technique into a user-friendly workbench.
ER  - 

TY  - CONF
TI  - A decision-making approach for semi-decentralized rail transit control system
T2  - IET Doctoral Forum on Biomedical Engineering, Healthcare, Robotics and Artificial Intelligence 2018 (BRAIN 2018)
SP  - 1
EP  - 8
AU  - Y. Guo
AU  - C. Zhang
AU  - S. Lu
PY  - 2018
KW  - Medical services
KW  - Safety
KW  - Artificial intelligence
KW  - Rails
KW  - Optimization
KW  - Rail transportation
KW  - Biomedical engineering
KW  - MULTI-AGENT
KW  - RAIL TRANSIT
KW  - DECISION APPROACH
DO  - 10.1049/cp.2018.1732
JO  - IET Doctoral Forum on Biomedical Engineering, Healthcare, Robotics and Artificial Intelligence 2018 (BRAIN 2018)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - IET Doctoral Forum on Biomedical Engineering, Healthcare, Robotics and Artificial Intelligence 2018 (BRAIN 2018)
Y1  - 4-4 Nov. 2018
AB  - At present, the primary control system in the field of rail transit is in the form of centralised control, which is based on the communication of the ground side system and the on-board side system. A central controller will play the role of information flow centre and has to afford a lot of computational loads when it needs to manage a large number of trains simultaneously. It is believed that with the development of artificial intelligence algorithms, the control system could be built based on a semi-decentralised multi-agent system (MAS). This paper proposes an innovative MAS system to enhance the decision-making of the rail transit control system. This proposed MAS includes several agents, e.g., train agents, station agents, and a central agent. A train agent can exchange information with other agents directly and make decisions based on the collected data. A case study is carried out to build a preliminary MAS for a rail transit control in Suzhou Metro. Compared with the centralised control system, this MAS can reduce the computational pressure of the central controller and improve the information exchange efficiency. The proposed method is expected to advance the thinking of how to achieve fully automated train control in the future.
ER  - 

TY  - CONF
TI  - Hot Topic Day
T2  - 2021 IEEE Real-Time Systems Symposium (RTSS)
SP  - 17
EP  - 17
PY  - 2021
KW  - Complexity theory
KW  - Uncertainty
KW  - Tutorials
KW  - Technological innovation
KW  - Runtime
KW  - Robustness
KW  - Real-time systems
DO  - 10.1109/RTSS52674.2021.00009
JO  - 2021 IEEE Real-Time Systems Symposium (RTSS)
IS  - 
SN  - 2576-3172
VO  - 
VL  - 
JA  - 2021 IEEE Real-Time Systems Symposium (RTSS)
Y1  - 7-10 Dec 2021
AB  - Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. RTSS 2021 features the Hot Topics Day (HTD) that highlights emerging research topics related to realtime systems. The HTD features a combination of workshops, special sessions, and tutorials. Unfortunately the uncertainties due to COVID-19 affected the number of proposed events during the HTD. Still, the 2021 HTD will welcome the following very interesting special session "Self-Adaptive Safety- and Mission-critical CPS: Wishful Thinking or Absolute Necessity?" Due to the increasing performance demands of mission- and safety-critical Cyber Physical Systems (CPS), these systems exhibit a rapidly growing complexity, manifested by an increasing number of (distributed) computational cores and application components connected via complex networks. However, with the growing complexity and interconnectivity of these systems, the chances of hardware failures as well as disruptions due to cyber-attacks will also quickly increase. System adaptivity, for example in the form of dynamically remapping of application components to processing cores, represents a promising technique to handle this challenging scenario. In this session, we address the (consequences of the) idea of deploying runtime adaptivity to mission and safety-critical CPS, yielding dynamically morphing systems, to establish robustness against computational hurdles, component failures, and cyberattacks. This special session reports some of the research findings of the European Union's Horizon 2020 research and innovation project ADMORPH (http://admorph.eu/).
ER  - 

TY  - CONF
TI  - Coding Like a Data Miner: A Sandbox Approach to Computing-Based Data Science for High School Student Learning
T2  - 2023 IEEE Frontiers in Education Conference (FIE)
SP  - 1
EP  - 5
AU  - J. T. Walker
AU  - A. Barany
AU  - A. Acquah
AU  - S. M. Reza
AU  - A. Barrera
AU  - K. Del Rio Guzman
AU  - M. A. Johnson
PY  - 2023
KW  - Computer science
KW  - Smart textiles
KW  - Social networking (online)
KW  - Statistical analysis
KW  - Affordances
KW  - Soft sensors
KW  - Scholarships
KW  - Computer Science Education
KW  - Data Science Education
KW  - Constructionism
KW  - Curriculum Design
KW  - Computer Science Learning
DO  - 10.1109/FIE58773.2023.10343283
JO  - 2023 IEEE Frontiers in Education Conference (FIE)
IS  - 
SN  - 2377-634X
VO  - 
VL  - 
JA  - 2023 IEEE Frontiers in Education Conference (FIE)
Y1  - 18-21 Oct. 2023
AB  - Personal health tracking devices and internet-based digital platforms with the capacity to collect, aggregate, and store data at massive scales are examples of tools that have broadened priorities in computing to include data science. In response, there has been growing attention in research and practice emphasizing pre-college groups. This is partly because of the growing recognition-reflected in initiatives like CS4ALL, Code.org, Bootstrap: Data Science, Exploring Computer Science-that learning experiences before college are consequential in sustaining a robust pipeline of computer scientists and engineers. Despite these inroads, there is justifiable concern that existing efforts might not fully support learner development in the necessary conceptual, epistemological, and heuristic styles needed to productively parse and understand “big data.” This is because computing-based curricula that include data science often involve data curated by others (rather than learners directly), which results in simulated versions of practice instead of engagement that is realistically discursive and messy. This is further complicated by the persistent shortage of K-12 computer science teachers in general and even fewer who can design and implement curricula that support authentic engagement with data science. To address these issues, we leverage culturally relevant and constructionist perspectives in a sandbox (i.e., open-ended) science where tools like Scratch and electronic textiles (E-textiles) have had success expanding possibilities in computing to also include activities where learners can engage broadly along varied pursuits-and encounter challenges that spur computational thinking and problem-solving. The literature suggests that learning activities framed in this way encourage knowledge construction, practice literacies, and seriously impact learner attitudes, interest, and perceptions of growth in the field. This latter set of self-concept measures represents a few of many related key predictors of long-term field participation and persistence. In this work-in-progress scholarship of discovery research, we co-develop, with youth and educators, “Coding Like a Data Miner” (CLDM)-a sandbox approach to computing-based data science wherein learners access a social media platform, Twitter, to mine, analyze, and understand quantitative and qualitative data sources. In this preliminary work, we assess affordances in co-developing a curriculum that leverages sandbox approaches to data science. Ultimately (and what will be presented in our final submission), we aim to study learning outcomes when high school students' access, analyze and make sense of “big data” sets of their own. We collaborated with high school teachers in a West Texas/Paso Del Norte region where computer science educators are exceptionally scarce and where there is an urgent and persistent need to support underrepresented learner access to burgeoning areas of computing. Using mixed-methodological approaches (e.g., quantitative analysis of learner pre- and post-survey responses along with qualitative assessments of semi-structured interview data), we address the following research questions: (1) What affordances exist using co-design approaches to develop sandbox data science for pre-college learners? (2) Which computational concepts do students learn when carrying out CLDM activities, (3) Which computational practices do high school students enact when mining, processing, and analyzing big data sets in CLDM? (4) How do learner knowledge and perceptions about data science shift after participating in CLDM? We use contemporary perspectives in computing education, constructionism, and equity to discuss how open-ended sandbox approaches to computing-based data science support learner computational thinking, practice literacies, and field perceptions.
ER  - 

TY  - JOUR
TI  - Potential of quantum computing for drug discovery
T2  - IBM Journal of Research and Development
SP  - 6:1
EP  - 6:20
AU  - Y. Cao
AU  - J. Romero
AU  - A. Aspuru-Guzik
PY  - 2018
KW  - Quantum computing
KW  - Drugs
KW  - Proteins
KW  - Computers
KW  - Machine learning
KW  - Computational modeling
DO  - 10.1147/JRD.2018.2888987
JO  - IBM Journal of Research and Development
IS  - 6
SN  - 0018-8646
VO  - 62
VL  - 62
JA  - IBM Journal of Research and Development
Y1  - 1 Nov.-Dec. 2018
AB  - Quantum computing has rapidly advanced in recent years due to substantial development in both hardware and algorithms. These advances are carrying quantum computers closer to their impending commercial utility. Drug discovery is a promising area of application that will find a number of uses for these new machines. As a prominent example, quantum simulation will enable faster and more accurate characterizations of molecular systems than existing quantum chemistry methods. Furthermore, algorithmic developments in quantum machine learning offer interesting alternatives to classical machine learning techniques, which may also be useful for the biochemical efforts involved in early phases of drug discovery. Meanwhile, quantum hardware is scaling up rapidly into a regime where an exact simulation is difficult even using the world’s largest supercomputers. We review how these recent advances can shift the paradigm with which one thinks about drug discovery, focusing on both the promises and caveats associated with each development. In particular, we highlight how hybrid quantum-classical approaches to quantum simulation and quantum machine learning could yield substantial progress using noisy-intermediate scale quantum devices, whereas fault-tolerant, error-corrected quantum computers are still in their development phase.
ER  - 

TY  - JOUR
TI  - Resource Management at the Network Edge: A Deep Reinforcement Learning Approach
T2  - IEEE Network
SP  - 26
EP  - 33
AU  - D. Zeng
AU  - L. Gu
AU  - S. Pan
AU  - J. Cai
AU  - S. Guo
PY  - 2019
KW  - Resource management
KW  - Edge computing
KW  - Dynamic scheduling
KW  - Servers
KW  - Task analysis
KW  - Computational modeling
DO  - 10.1109/MNET.2019.1800386
JO  - IEEE Network
IS  - 3
SN  - 1558-156X
VO  - 33
VL  - 33
JA  - IEEE Network
Y1  - May/June 2019
AB  - With the advent of edge computing, it is highly recommended to extend some cloud services to the network edge such that the services can be provisioned in the proximity of end users, with better performance efficiency and cost efficiency. Compared to cloud computing, edge computing has high dynamics, and therefore the resources shall be correspondingly managed in an adaptive way. Traditional model-based resource management approaches are limited in practical application due to the involvement of some assumptions or prerequisites. We think it is desirable to introduce a model-free approach that can fit the network dynamics well without any prior knowledge. To this end, we introduce a model-free DRL approach to efficiently manage the resources at the network edge. Following the design principle of DRL, we design and implement a mobility- aware data processing service migration management agent. The experiments show that our agent can automatically learn the user mobility pattern and accordingly control the service migration among the edge servers to minimize the operational cost at runtime. Some potential future research challenges are also presented.
ER  - 

TY  - CONF
TI  - Fault Attacks on AES with Faulty Ciphertexts Only
T2  - 2013 Workshop on Fault Diagnosis and Tolerance in Cryptography
SP  - 108
EP  - 118
AU  - T. Fuhr
AU  - E. Jaulmes
AU  - V. Lomné
AU  - A. Thillard
PY  - 2013
KW  - Ciphers
KW  - Encryption
KW  - Mathematical model
KW  - Context
KW  - Computational modeling
KW  - Protocols
KW  - Fault Attacks
KW  - AES
DO  - 10.1109/FDTC.2013.18
JO  - 2013 Workshop on Fault Diagnosis and Tolerance in Cryptography
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2013 Workshop on Fault Diagnosis and Tolerance in Cryptography
Y1  - 20-20 Aug. 2013
AB  - Classical Fault Attacks often require the ability to encrypt twice the same plaintext, in order to get one or several pairs of correct and faulty cipher texts corresponding to the same message. This observation led some designers to think that a randomized mode of operation may be sufficient to protect block cipher encryption against this kind of threat. In this paper, we consider the case where the adversary neither chooses nor knows the input messages, and has only access to the faulty cipher texts. In this context, we are able to describe several attacks against AES-128 by using non uniform fault models. Our attacks target the last 4 rounds and allow to recover the correct key with practical time complexity, using a limited number of faulty cipher texts. This work highlights the need for dedicated fault attack countermeasures in secure embedded systems.
ER  - 

TY  - CONF
TI  - Review on Image Processing Based Adversarial Example Defenses in Computer Vision
T2  - 2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)
SP  - 94
EP  - 99
AU  - M. Qiu
AU  - H. Qiu
PY  - 2020
KW  - Deep learning
KW  - Computer vision
KW  - Image coding
KW  - Perturbation methods
KW  - Computational modeling
KW  - Conferences
KW  - Robustness
KW  - Deep learning
KW  - adversarial examples
KW  - image denoising
KW  - image compression
KW  - computer vision
DO  - 10.1109/BigDataSecurity-HPSC-IDS49724.2020.00027
JO  - 2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)
Y1  - 25-27 May 2020
AB  - Recent research works showed that deep neural networks are vulnerable to adversarial examples, which are usually maliciously created by carefully adding deliberate and imperceptible perturbations to examples. Several states of the art defense methods are proposed based on the existing image processing methods like image compression and image denoising. However, such approaches are not the final optimal solution for defense adversarial perturbations in DNN models. In this paper, we reviewed two main approaches to deploying image processing methods as a defense. By analyzing and discus!sing the remaining issues, we present two open questions for future research direction including the definition of adversarial perturbations and noises, the novel defense-aware threat model. A further research direction is also given by re-thinking the impacts of adversarial perturbations on all frequency bands.
ER  - 

TY  - CONF
TI  - Digital Twin for Smart Manufacturing: The Simulation Aspect
T2  - 2019 Winter Simulation Conference (WSC)
SP  - 2085
EP  - 2098
AU  - G. Shao
AU  - S. Jain
AU  - C. Laroque
AU  - L. H. Lee
AU  - P. Lendermann
AU  - O. Rose
PY  - 2019
KW  - Data models
KW  - Manufacturing
KW  - Analytical models
KW  - Biological system modeling
KW  - Computational modeling
KW  - Standards
KW  - Virtual manufacturing
DO  - 10.1109/WSC40007.2019.9004659
JO  - 2019 Winter Simulation Conference (WSC)
IS  - 
SN  - 1558-4305
VO  - 
VL  - 
JA  - 2019 Winter Simulation Conference (WSC)
Y1  - 8-11 Dec. 2019
AB  - The purpose of this panel is to discuss the state of the art in digital twin for manufacturing research and practice from the perspective of the simulation community. The panelists come from the US, Europe, and Asia representing academia, industry, and government. This paper begins with a short introduction to digital twins and then each panelist provides preliminary thoughts on concept, definitions, challenges, implementations, relevant standard activities, and future directions. Two panelists also report their digital twin projects and lessons learned. The panelists may have different viewpoints and may not totally agree with each other on some of the arguments, but the intention of the panel is not to unify researchers' thinking, but to list the research questions, initiate a deeper discussion, and try to help researchers in the simulation community with their future study topics on digital twins for manufacturing.
ER  - 

TY  - JOUR
TI  - DNA Data Storage and Hybrid Molecular–Electronic Computing
T2  - Proceedings of the IEEE
SP  - 63
EP  - 72
AU  - D. Carmean
AU  - L. Ceze
AU  - G. Seelig
AU  - K. Stewart
AU  - K. Strauss
AU  - M. Willsey
PY  - 2019
KW  - Molecular computing
KW  - Memory
KW  - Sequential analysis
KW  - Substrates
KW  - Computer architecture
KW  - Market research
KW  - Computational modeling
KW  - Data storage systems
KW  - Future computer architectures
KW  - molecular data storage and computing
DO  - 10.1109/JPROC.2018.2875386
JO  - Proceedings of the IEEE
IS  - 1
SN  - 1558-2256
VO  - 107
VL  - 107
JA  - Proceedings of the IEEE
Y1  - Jan. 2019
AB  - Moore's law may be slowing, but our ability to manipulate molecules is improving faster than ever. DNA could provide alternative substrates for computing and storage as existing ones approach physical limits. In this paper, we explore the implications of this trend in computer architecture. We present a computer systems perspective on molecular processing and storage, positing a hybrid molecular-electronic architecture that plays to the strengths of both domains. We cover the design and implementation of all stages of the pipeline: encoding, DNA synthesis, system integration with digital microfluidics, DNA sequencing (including emerging technologies such as nanopores), and decoding. We first draw on our experience designing a DNA-based archival storage system, which includes the largest demonstration to date of DNA digital data storage of over three billion nucleotides encoding over 400 MB of data. We then propose a more ambitious hybrid-electronic design that uses a molecular form of near-data processing for massive parallelism. We present a model that demonstrates the feasibility of these systems in the near future. We think the time is ripe to consider molecular storage seriously and explore system designs and architectural implications.
ER  - 

TY  - CONF
TI  - Binocular Mutual Learning for Improving Few-shot Classification
T2  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
SP  - 8382
EP  - 8391
AU  - Z. Zhou
AU  - X. Qiu
AU  - J. Xie
AU  - J. Wu
AU  - C. Zhang
PY  - 2021
KW  - Learning systems
KW  - Degradation
KW  - Computer vision
KW  - Computational modeling
KW  - Decision making
KW  - Focusing
KW  - Performance gain
KW  - Transfer/Low-shot/Semi/Unsupervised Learning
KW  - Recognition and classification
DO  - 10.1109/ICCV48922.2021.00829
JO  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
IS  - 
SN  - 2380-7504
VO  - 
VL  - 
JA  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
Y1  - 10-17 Oct. 2021
AB  - Most of the few-shot learning methods learn to transfer knowledge from datasets with abundant labeled data (i.e., the base set). From the perspective of class space on base set, existing methods either focus on utilizing all classes under a global view by normal pretraining, or pay more attention to adopt an episodic manner to train meta-tasks within few classes in a local view. However, the interaction of the two views is rarely explored. As the two views capture complementary information, we naturally think of the compatibility of them for achieving further performance gains. Inspired by the mutual learning paradigm and binocular parallax, we propose a unified framework, namely Binocular Mutual Learning (BML), which achieves the compatibility of the global view and the local view through both intraview and cross-view modeling. Concretely, the global view learns in the whole class space to capture rich inter-class relationships. Meanwhile, the local view learns in the local class space within each episode, focusing on matching positive pairs correctly. In addition, cross-view mutual interaction further promotes the collaborative learning and the implicit exploration of useful knowledge from each other. During meta-test, binocular embeddings are aggregated together to support decision-making, which greatly improve the accuracy of classification. Extensive experiments conducted on multiple benchmarks including cross-domain validation confirm the effectiveness of our method1.
ER  - 

TY  - CONF
TI  - Distribution System Analysis to support the Smart Grid
T2  - IEEE PES General Meeting
SP  - 1
EP  - 8
AU  - R. C. Dugan
AU  - R. F. Arritt
AU  - T. E. McDermott
AU  - S. M. Brahma
AU  - K. Schneider
PY  - 2010
KW  - Smart grids
KW  - Load modeling
KW  - Integrated circuit modeling
KW  - Analytical models
KW  - Computational modeling
KW  - Planning
KW  - Monitoring
KW  - Power Distribution System Analysis
KW  - Smart grid
DO  - 10.1109/PES.2010.5589539
JO  - IEEE PES General Meeting
IS  - 
SN  - 1944-9925
VO  - 
VL  - 
JA  - IEEE PES General Meeting
Y1  - 25-29 July 2010
AB  - The “Smart Grid” refers to various efforts to modernize the power grid through the application of intelligent devices. This paper describes current thinking by members of the Distribution System Analysis Subcommittee (DSA SC) on how distribution system analysis might evolve to support the Smart Grid. Various issues related to Smart Grid and distribution system analysis are identified. The essential characteristics of distribution system analysis tools to support these issues are discussed. Relevant activities of the DSA SC are described.
ER  - 

TY  - JOUR
TI  - PsyPhy: A Psychophysics Driven Evaluation Framework for Visual Recognition
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
SP  - 2280
EP  - 2286
AU  - B. RichardWebster
AU  - S. E. Anthony
AU  - W. J. Scheirer
PY  - 2019
KW  - Visualization
KW  - Computer vision
KW  - Computational modeling
KW  - Psychology
KW  - Task analysis
KW  - Machine learning
KW  - Observers
KW  - Object recognition
KW  - visual psychophysics
KW  - neuroscience
KW  - psychology
KW  - evaluation
KW  - deep learning
DO  - 10.1109/TPAMI.2018.2849989
JO  - IEEE Transactions on Pattern Analysis and Machine Intelligence
IS  - 9
SN  - 1939-3539
VO  - 41
VL  - 41
JA  - IEEE Transactions on Pattern Analysis and Machine Intelligence
Y1  - 1 Sept. 2019
AB  - By providing substantial amounts of data and standardized evaluation protocols, datasets in computer vision have helped fuel advances across all areas of visual recognition. But even in light of breakthrough results on recent benchmarks, it is still fair to ask if our recognition algorithms are doing as well as we think they are. The vision sciences at large make use of a very different evaluation regime known as Visual Psychophysics to study visual perception. Psychophysics is the quantitative examination of the relationships between controlled stimuli and the behavioral responses they elicit in experimental test subjects. Instead of using summary statistics to gauge performance, psychophysics directs us to construct item-response curves made up of individual stimulus responses to find perceptual thresholds, thus allowing one to identify the exact point at which a subject can no longer reliably recognize the stimulus class. In this article, we introduce a comprehensive evaluation framework for visual recognition models that is underpinned by this methodology. Over millions of procedurally rendered 3D scenes and 2D images, we compare the performance of well-known convolutional neural networks. Our results bring into question recent claims of human-like performance, and provide a path forward for correcting newly surfaced algorithmic deficiencies.
ER  - 

TY  - JOUR
TI  - vFog: A Vehicle-Assisted Computing Framework for Delay-Sensitive Applications in Smart Cities
T2  - IEEE Access
SP  - 34900
EP  - 34909
AU  - S. S. Shah
AU  - M. Ali
AU  - A. W. Malik
AU  - M. A. Khan
AU  - S. D. Ravana
PY  - 2019
KW  - Edge computing
KW  - Task analysis
KW  - Vehicular ad hoc networks
KW  - Processor scheduling
KW  - Smart cities
KW  - Servers
KW  - Computational modeling
KW  - Vehicular fog computing
KW  - tasks scheduling policy
KW  - edge devices
KW  - multi-vehicle relay
DO  - 10.1109/ACCESS.2019.2903302
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 7
VL  - 7
JA  - IEEE Access
Y1  - 2019
AB  - The inception of the smart cities concept provides a compelling platform to support innovative applications. It provides distinctive view of cities, where mobile devices, pedestrians, and electronic gadgets can communicate with each other to build an effective urban environment to further improve the living standards. Similarly, the role of the Internet of Things (IoT) and vehicular computing has emerged due to smart cities. This is further complemented by edge and fog computing architectures. The emerging concept of vehicular fog computing has enabled the platform to support delay-sensitive applications and to reduce the workload on the backend networks. Vehicular fog computing is a paradigm that touches the boundaries of thinking vehicles as an infrastructures-as-a-service. The use of vehicles to provide computation on-the-move poses various challenges. The vehicles with onboard computing equipment can facilitate delay-sensitive applications. These vehicles can act as an edge device to reduce the load from a backbone network. However, due to continuous mobility, it is difficult to use traditional frameworks to distribute the computation task among vehicles. In this paper, we propose a framework termed vFog. The vFog is designed to provide computing facilities from nearby fog vehicles. The framework utilizes the onboard computing facility of vehicles without the support of roadside units (RSUs). Moreover, the proposed framework handles churn behavior and supports multi-hop communication to improve the task delivery ratio. The proposed framework allows researchers to benchmark their own task distribution algorithms over the dynamic vehicular networks.
ER  - 

TY  - CONF
TI  - A Closer Look at Fourier Spectrum Discrepancies for CNN-generated Images Detection
T2  - 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
SP  - 7196
EP  - 7205
AU  - K. Chandrasegaran
AU  - N. -T. Tran
AU  - N. -M. Cheung
PY  - 2021
KW  - Computer vision
KW  - Systematics
KW  - Codes
KW  - Forensics
KW  - Computational modeling
KW  - Detectors
KW  - Computer architecture
DO  - 10.1109/CVPR46437.2021.00712
JO  - 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
IS  - 
SN  - 2575-7075
VO  - 
VL  - 
JA  - 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
Y1  - 20-25 June 2021
AB  - CNN-based generative modelling has evolved to produce synthetic images indistinguishable from real images in the RGB pixel space. Recent works have observed that CNN-generated images share a systematic shortcoming in replicating high frequency Fourier spectrum decay attributes. Furthermore, these works have successfully exploited this systematic shortcoming to detect CNN-generated images reporting up to 99% accuracy across multiple state-of-the-art GAN models.In this work, we investigate the validity of assertions claiming that CNN-generated images are unable to achieve high frequency spectral decay consistency. We meticulously construct a counterexample space of high frequency spectral decay consistent CNN-generated images emerging from our handcrafted experiments using DCGAN, LSGAN, WGAN-GP and StarGAN, where we empirically show that this frequency discrepancy can be avoided by a minor architecture change in the last upsampling operation. We subsequently use images from this counterexample space to successfully bypass the recently proposed forensics detector which leverages on high frequency Fourier spectrum decay attributes for CNN-generated image detection.Through this study, we show that high frequency Fourier spectrum decay discrepancies are not inherent characteristics for existing CNN-based generative models—contrary to the belief of some existing work—, and such features are not robust to perform synthetic image detection. Our results prompt re-thinking of using high frequency Fourier spectrum decay attributes for CNN-generated image detection. Code and models are available at https://keshik6.github.io/Fourier-Discrepancies-CNN-Detection/
ER  - 

TY  - CONF
TI  - Gables: A Roofline Model for Mobile SoCs
T2  - 2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)
SP  - 317
EP  - 330
AU  - M. Hill
AU  - V. Janapa Reddi
PY  - 2019
KW  - Computer architecture
KW  - Computational modeling
KW  - Smart phones
KW  - Bandwidth
KW  - Fabrics
KW  - Software
KW  - Hardware
KW  - Accelerator architectures
KW  - Mobile computing
KW  - System-on-Chip
KW  - Processor Architecture
DO  - 10.1109/HPCA.2019.00047
JO  - 2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)
IS  - 
SN  - 2378-203X
VO  - 
VL  - 
JA  - 2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)
Y1  - 16-20 Feb. 2019
AB  - Over a billion mobile consumer system-on-chip (SoC) chipsets ship each year. Of these, the mobile consumer market undoubtedly involving smartphones has a significant market share. Most modern smartphones comprise of advanced SoC architectures that are made up of multiple cores, GPS, and many different programmable and fixed-function accelerators connected via a complex hierarchy of interconnects with the goal of running a dozen or more critical software usecases under strict power, thermal and energy constraints. The steadily growing complexity of a modern SoC challenges hardware computer architects on how best to do early stage ideation. Late SoC design typically relies on detailed full-system simulation once the hardware is specified and accelerator software is written or ported. However, early-stage SoC design must often select accelerators before a single line of software is written. To help frame SoC thinking and guide early stage mobile SoC design, in this paper we contribute the Gables model that refines and retargets the Roofline model---designed originally for the performance and bandwidth limits of a multicore chip---to model each accelerator on a SoC, to apportion work concurrently among different accelerators (justified by our usecase analysis), and calculate a SoC performance upper bound. We evaluate the Gables model with an existing SoC and develop several extensions that allow Gables to inform early stage mobile SoC design.
ER  - 

TY  - CONF
TI  - Hybrid Machine Learning Technique for Personality Classification from Online Text using HEXACO Model
T2  - 2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
SP  - 253
EP  - 259
AU  - P. William
AU  - A. Badholia
AU  - B. Patel
AU  - M. Nigam
PY  - 2022
KW  - Text recognition
KW  - Social networking (online)
KW  - Computational modeling
KW  - Entrepreneurship
KW  - Machine learning
KW  - Benchmark testing
KW  - Data models
KW  - Personality recognition
KW  - Social Networks
KW  - HEXACO model
KW  - Individual Performance
KW  - Personality Traits
DO  - 10.1109/ICSCDS53736.2022.9760970
JO  - 2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
Y1  - 7-9 April 2022
AB  - Personality refers to a person's unique collection of traits that influence their habits, behaviors, attitudes, and thinking patterns. Text accessible on social networking sites may be used to automatically identify an individual's personality characteristics. In the trials, a publicly accessible benchmark dataset from Kaggle is utilized. The major problem with the previous study was the skewness of the dataset, which was reduced by using the Re-sampling method, essentially random over-sampling, which resulted in improved performance. Although the results produced by all classifiers across all personality characteristics are acceptable, the performance of the XGBoost classifier is exceptional, reaching more than 99 percent precision and accuracy for various qualities. Individual preferences, talents, social and human values, personality variations, and human will power must all be addressed while analyzing entrepreneurial activities, intents, and performance, especially with entrepreneurship playing such an important part in the contemporary dynamic. Using the HEXACO Personality Characteristics Model, this study demonstrates a link between personality traits and entrepreneurial success, indicating that personality traits have a significant and direct effect on entrepreneurial performance.
ER  - 

TY  - CONF
TI  - Real time simulation: A novel approach in engineering education
T2  - 2011 3rd International Conference on Electronics Computer Technology
SP  - 215
EP  - 219
AU  - P. M. Menghal
AU  - A. J. Laxmi
PY  - 2011
KW  - Real time systems
KW  - Computational modeling
KW  - Mathematical model
KW  - Motor drives
KW  - Power electronics
KW  - Education
KW  - Testing
KW  - Real Time Simulation
KW  - Real Time Lab(RT Lab)
KW  - Hardware in the Loop (HIL)
KW  - Real Time Workshop
KW  - Education Tools
DO  - 10.1109/ICECTECH.2011.5941592
JO  - 2011 3rd International Conference on Electronics Computer Technology
IS  - 
SN  - 
VO  - 1
VL  - 1
JA  - 2011 3rd International Conference on Electronics Computer Technology
Y1  - 8-10 April 2011
AB  - Today, with the advent of computers and various easily accessible software packages, computer aided teaching tools have become an essential part of both classroom lectures and laboratory experiments in any kind of education curriculum. Real Time Simulation tools, as a part of Electrical Machine Drives laboratory experiments, enhance lab experience by providing students with the opportunity to judge the performance of Electrical Machines in real time situations. This interactive learning environment, consisting of simulations, demonstrations and exercises, can fulfill the role of a bridge from passive learning to active engagement and thus stimulate deeper thinking; grounding a problem based-learning environment. The applications are also very important for relating theory to practice, so that the students can develop engineering judgment and understand how process behavior can be captured using real time simulations. Due to advancement of the software tools like MATLAB/SEVIULINK with its Real Time Workshop(RTW) and Real Time Windows Target (RTWT), real time simulators are used extensively in many engineering fields, such as industry, education and research institutions. As a consequence, inclusion of the real time simulation applications in academic curriculum provides great learning value to the students. A case is made to present overview of the Real Time Simulations of Electrical Machines Drives possibility of including these techniques in modern engineering educational curriculum. This paper will review the various real time simulation techniques such as Real Time Laboratory (RT Lab), Rapid Control Prototyping (RCP) and Hardware in the Loop (HIL), which can be used in a modern engineering education.
ER  - 

TY  - JOUR
TI  - Querying Similar Process Models Based on the Hungarian Algorithm
T2  - IEEE Transactions on Services Computing
SP  - 121
EP  - 135
AU  - B. Cao
AU  - J. Wang
AU  - J. Fan
AU  - J. Yin
AU  - T. Dong
PY  - 2017
KW  - Context
KW  - Computational modeling
KW  - Petri nets
KW  - Context modeling
KW  - Query processing
KW  - Companies
KW  - Process models
KW  - hungarian algorithm
KW  - structural similarity
KW  - query processing
KW  - petri net
DO  - 10.1109/TSC.2016.2597143
JO  - IEEE Transactions on Services Computing
IS  - 1
SN  - 1939-1374
VO  - 10
VL  - 10
JA  - IEEE Transactions on Services Computing
Y1  - 1 Jan.-Feb. 2017
AB  - The structural similarity between two process models is usually considered as the main measurement for ranking the process models for a given query model. Current process query methods are inefficient since too many expensive computations of the graph edit distance are involved. To address this issue, using Petri-net as the modeling method, this paper presents the Hungarian algorithm based similarity query method. Unlike previous work where the non-task nodes (i.e., place nodes in the Petri-net) were lightly studied or even ignored, we think these non-task nodes also play an essential role in measuring the structural similarity between process models. First, we extract the context for each place and define the similarity for a pair of place nodes that are from different process models from two perspectives: commonality and the graph edit distance. Then, the place mapping is transformed to classical assignment problem that can be solved by Hungarian algorithm efficiently. Furthermore, we propose a new process similarity measurement on the basis of the place similarity. The extensive experimental evaluation shows that our Hungarian based methods outperform the baseline algorithm in both retrieval quality and query response time.
ER  - 

TY  - CONF
TI  - Watch Only Once: An End-to-End Video Action Detection Framework
T2  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
SP  - 8158
EP  - 8167
AU  - S. Chen
AU  - P. Sun
AU  - E. Xie
AU  - C. Ge
AU  - J. Wu
AU  - L. Ma
AU  - J. Shen
AU  - P. Luo
PY  - 2021
KW  - Location awareness
KW  - Computer vision
KW  - Computational modeling
KW  - Pipelines
KW  - Detectors
KW  - Predictive models
KW  - Feature extraction
KW  - Video analysis and understanding
DO  - 10.1109/ICCV48922.2021.00807
JO  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
IS  - 
SN  - 2380-7504
VO  - 
VL  - 
JA  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
Y1  - 10-17 Oct. 2021
AB  - We propose an end-to-end pipeline, named Watch Once Only (WOO), for video action detection. Current methods either decouple video action detection task into separated stages of actor localization and action classification or train two separated models within one stage. In contrast, our approach solves the actor localization and action classification simultaneously in a unified network. The whole pipeline is significantly simplified by unifying the backbone network and eliminating many hand-crafted components. WOO takes a unified video backbone to simultaneously extract features for actor location and action classification. In addition, we introduce spatial-temporal action embeddings into our framework and design a spatial-temporal fusion module to obtain more discriminative features with richer information, which further boosts the action classification performance. Extensive experiments on AVA and JHMDB datasets show that WOO achieves state-of-the-art performance, while still reduces up to 16.7% GFLOPs compared with existing methods. We hope our work can inspire re-thinking the convention of action detection and serve as a solid baseline for end-to-end action detection. Code is available at https://github.com/ShoufaChen/WOO.
ER  - 

TY  - CONF
TI  - Meta Architecture for Point Cloud Analysis
T2  - 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
SP  - 17682
EP  - 17691
AU  - H. Lin
AU  - X. Zheng
AU  - L. Li
AU  - F. Chao
AU  - S. Wang
AU  - Y. Wang
AU  - Y. Tian
AU  - R. Ji
PY  - 2023
KW  - Point cloud compression
KW  - Analytical models
KW  - Three-dimensional displays
KW  - Systematics
KW  - Computational modeling
KW  - Architecture
KW  - Search methods
KW  - 3D from multi-view and sensors
DO  - 10.1109/CVPR52729.2023.01696
JO  - 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
IS  - 
SN  - 2575-7075
VO  - 
VL  - 
JA  - 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
Y1  - 17-24 June 2023
AB  - Recent advances in 3D point cloud analysis bring a diverse set of network architectures to the field. However, the lack of a unified framework to interpret those networks makes any systematic comparison, contrast, or analysis challenging, and practically limits healthy development of the field. In this paper, we take the initiative to explore and propose a unified framework called PointMeta, to which the popular 3D point cloud analysis approaches could fit. This brings three benefits. First, it allows us to compare different approaches in a fair manner, and use quick experiments to verify any empirical observations or assumptions summarized from the comparison. Second, the big picture brought by PointMeta enables us to think across different components, and revisit common beliefs and key design decisions made by the popular approaches. Third, based on the learnings from the previous two analyses, by doing simple tweaks on the existing approaches, we are able to derive a basic building block, termed PointMetaBase. It shows very strong performance in efficiency and effectiveness through extensive experiments on challenging benchmarks, and thus verifies the necessity and benefits of high-level interpretation, contrast, and comparison like PointMeta. In particular, PointMetaBase surpasses the previous state-of-the-art method by 0.7%/1.4/%2.1% mIoU with only 2%/11%/13% of the computation cost on the S3DIS datasets. The code and models are available at https://github.com/linhaojia13/PointMetaBase.
ER  - 

TY  - CONF
TI  - Functional resonance analysis method based-decision support tool for urban transport system resilience management
T2  - 2016 IEEE International Smart Cities Conference (ISC2)
SP  - 1
EP  - 7
AU  - E. Bellini
AU  - P. Nesi
AU  - G. Pantaleo
AU  - A. Venturi
PY  - 2016
KW  - Random access memory
KW  - Ferroelectric films
KW  - Nonvolatile memory
KW  - Computational modeling
KW  - Resilience
KW  - Analytical models
KW  - Decision support systems
KW  - smart city
KW  - Functional Resonance Analysis Method
KW  - Decision Support System
KW  - Resilience
KW  - Urban Stransport System
DO  - 10.1109/ISC2.2016.7580833
JO  - 2016 IEEE International Smart Cities Conference (ISC2)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2016 IEEE International Smart Cities Conference (ISC2)
Y1  - 12-15 Sept. 2016
AB  - Today, managing critical infrastructure resilience in smart city is a challenge that can be undertaken by adopting a new class of smart tools, which are able to integrate modeling capability with evidence driven decision support. The Resilience Decision Support tool, as presented in this article, is an innovative and powerful tool that aims at managing critical infrasctructure resilience through a more complex and expressive model based on the Functional Resonance Analysis Method and through the connection of such a model with a system thinking based decision support tool exploiting smart city data. Thanks to ResilienceDS, FRAM model becomes computable and the functional variability that is at the core of the resilience analysis can be quantified. Such quantification allows the decision support tool to compute specific strategies and recommendations for variability dampening at strategic, tactic and operational stage. The solution has been developed in the context of RESOLUTE H2020 project of the European Commission.
ER  - 

TY  - CONF
TI  - Comparing model development in Discrete Event Simulation and System Dynamics
T2  - Proceedings of the 2009 Winter Simulation Conference (WSC)
SP  - 979
EP  - 991
AU  - A. A. Tako
AU  - S. Robinson
PY  - 2009
KW  - Discrete event simulation
KW  - Protocols
KW  - Computational modeling
KW  - Switches
KW  - Buildings
KW  - Analytical models
KW  - Computer simulation
KW  - Stochastic processes
KW  - Statistical distributions
KW  - Problem-solving
DO  - 10.1109/WSC.2009.5429423
JO  - Proceedings of the 2009 Winter Simulation Conference (WSC)
IS  - 
SN  - 1558-4305
VO  - 
VL  - 
JA  - Proceedings of the 2009 Winter Simulation Conference (WSC)
Y1  - 13-16 Dec. 2009
AB  - This paper provides an empirical study on the comparison of model building in Discrete-Event Simulation (DES) and System Dynamics (SD). Verbal Protocol Analysis (VPA) is used to study the model building process of ten expert modellers (5 SD and 5 DES). Participants are asked to build a simulation model based on a prison population case study and to think aloud while modelling. The generated verbal protocols are divided into 7 modelling topics: problem structuring, conceptual modelling, data inputs, model coding, validation & verification, results & experimentation and implementation and then analyzed. Our results suggest that all modellers switch between modelling topics, however DES modellers follow a more linear progression compared to SD modellers. DES modellers focus significantly more on model coding and verification & validation, whereas SD modellers on conceptual modelling. This quantitative analysis of the processes followed by expert modellers contributes towards the comparison of DES and SD modelling.
ER  - 

TY  - CONF
TI  - Determining Accuracy Rate of Artificial Intelligence Models using Python and R-Studio
T2  - 2021 3rd International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)
SP  - 889
EP  - 894
AU  - A. Gupta
AU  - R. Parmar
AU  - P. Suri
AU  - R. Kumar
PY  - 2021
KW  - Computational modeling
KW  - Artificial neural networks
KW  - Data models
KW  - Libraries
KW  - Security
KW  - Artificial intelligence
KW  - Logistics
KW  - Artificial neural network
KW  - stock market
KW  - machine learning
KW  - BSE
DO  - 10.1109/ICAC3N53548.2021.9725687
JO  - 2021 3rd International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2021 3rd International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)
Y1  - 17-18 Dec. 2021
AB  - Research investigation in this study, an Artificial-Neural-Network (ANN) castoff to conjecture monetary market conduct. Our primary objective is to build up a neural system to see whether a stock pays a profit or not utilizing RStudio and Python. We propose and execute Artificial Neural Network to estimate monetary market conduct. This apparatus can be utilized for top to bottom examination of the securities exchange. Utilizing ANN, we foresee the reliance of the needy variable profit on the other autonomous factors like free income per share (fcfps), profit development, obligation to value proportion (de), showcase capitalization (mcap), and current proportion. We have prepared the neural system utilizing the neuralnet library and tried the precision of the model. We make the perplexity framework to think about the true/false positives and negatives. We yield an exactness rate of the neural system that estimate in deciding if a stock pays a profit or not.
ER  - 

TY  - CONF
TI  - Detection on application layer DDoS using random walk model
T2  - 2014 IEEE International Conference on Communications (ICC)
SP  - 707
EP  - 712
AU  - C. Xu
AU  - G. Zhao
AU  - G. Xie
AU  - S. Yu
PY  - 2014
KW  - Computer crime
KW  - Vectors
KW  - Probability distribution
KW  - Predictive models
KW  - Educational institutions
KW  - Computational modeling
KW  - Information systems
KW  - Asymmetric application layer DDoS attack
KW  - anomaly detection
KW  - random walk model
KW  - similarity
DO  - 10.1109/ICC.2014.6883402
JO  - 2014 IEEE International Conference on Communications (ICC)
IS  - 
SN  - 1938-1883
VO  - 
VL  - 
JA  - 2014 IEEE International Conference on Communications (ICC)
Y1  - 10-14 June 2014
AB  - Application Layer Distributed Denial of Service (ALDDoS) attacks have been increasing rapidly with the growth of Botnets and Ubiquitous computing. Differentiate to the former DDoS attacks, ALDDoS attacks cannot be efficiently detected, as attackers always adopt legitimate requests with real IP address, and the traffic has high similarity to legitimate traffic. In spite of that, we think, the attackers' browsing behavior will have great disparity from that of the legitimate users'. In this paper, we put forward a novel user behavior-based method to detect the application layer asymmetric DDoS attack. We introduce an extended random walk model to describe user browsing behavior and establish the legitimate pattern of browsing sequences. For each incoming browser, we observe his page request sequence and predict subsequent page request sequence based on random walk model. The similarity between the predicted and the observed page request sequence is used as a criterion to measure the legality of the user, and then attacker would be detected based on it. Evaluation results based on real collected data set has demonstrated that our method is very effective in detecting asymmetric ALDDoS attacks.
ER  - 

TY  - JOUR
TI  - Revisiting Analog Over-the-Air Machine Learning: The Blessing and Curse of Interference
T2  - IEEE Journal of Selected Topics in Signal Processing
SP  - 406
EP  - 419
AU  - H. H. Yang
AU  - Z. Chen
AU  - T. Q. S. Quek
AU  - H. V. Poor
PY  - 2022
KW  - Servers
KW  - Interference
KW  - Training
KW  - Convergence
KW  - Computational modeling
KW  - Machine learning
KW  - Fading channels
KW  - Distributed machine learning
KW  - analog over-the-air computing
KW  - heavy-tailed interference
KW  - convergence rate
KW  - generalization error
DO  - 10.1109/JSTSP.2021.3139231
JO  - IEEE Journal of Selected Topics in Signal Processing
IS  - 3
SN  - 1941-0484
VO  - 16
VL  - 16
JA  - IEEE Journal of Selected Topics in Signal Processing
Y1  - April 2022
AB  - We study a distributed machine learning problem carried out by an edge server and multiple agents in a wireless network. The objective is to minimize a global function that is a sum of the agents’ local loss functions. And the optimization is conducted by analog over-the-air model training. Specifically, each agent modulates its local gradient onto a set of waveforms and transmits to the edge server simultaneously. From the received analog signal the edge server extracts a noisy aggregated gradient which is distorted by the channel fading and interference, and uses it to update the global model and feedbacks to all the agents for another round of local computing. Since the electromagnetic interference generally exhibits a heavy-tailed intrinsic, we use the $\alpha$-stable distribution to model its statistic. In consequence, the global gradient has an infinite variance that hinders the use of conventional techniques for convergence analysis that rely on second-order moments’ existence. To circumvent this challenge, we take a new route to establish the analysis of convergence rate, as well as generalization error, of the algorithm. We also show that the training algorithm can be run in tandem with the momentum scheme to accelerate the convergence. Our analyses reveal a two-sided effect of the interference on the overall training procedure. On the negative side, heavy tail noise slows down the convergence rate of the model training: the heavier the tail in the distribution of interference, the slower the algorithm converges. On the positive side, heavy tail noise has the potential to increase the generalization power of the trained model: the heavier the tail, the better the model generalizes. This perhaps counterintuitive conclusion implies that the prevailing thinking on interference – that it is only detrimental to the edge learning system – is outdated and we shall seek new techniques that exploit, rather than simply mitigate, the interference for better machine learning in wireless networks.
ER  - 

TY  - CONF
TI  - Prediction of Stock Price Using Statistical and Ensemble learning Models: A Comparative Study
T2  - 2021 IEEE 8th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)
SP  - 1
EP  - 6
AU  - A. Durgapal
AU  - V. Vimal
PY  - 2021
KW  - Uncertainty
KW  - Computational modeling
KW  - Time series analysis
KW  - Predictive models
KW  - Boosting
KW  - Task analysis
KW  - Stock markets
KW  - Ensemble learning Models
KW  - ARIMA
KW  - Random Forest Model
KW  - Extreme gradient Boosting Model
KW  - Stock Price Prediction
DO  - 10.1109/UPCON52273.2021.9667644
JO  - 2021 IEEE 8th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)
IS  - 
SN  - 2687-7767
VO  - 
VL  - 
JA  - 2021 IEEE 8th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)
Y1  - 11-13 Nov. 2021
AB  - Prediction of the stock price has always been a challenging task due to irregular patterns of the market. Uncertainty has made researchers think of some new and robust predictive methods. Many studies are available in the literature, with many models to predict the stock price accurately. Statistical, machine learning, deep learning, and other related approaches can create a predictive model. ARIMA model is the most commonly used statistical model for time series prediction. But ensemble learning techniques have not been explored much to predict future stock price. So, the present study stresses comparing statistical methods with ensemble learning methods. This paper compares the ARIMA, Random Forest, and Extreme Gradient Boosting models based on root mean squared error (RMSE) and mean absolute percentage error (MAPE). The subject chosen is Google’s stocks, and the data used is from NASDAQ stock exchange. The analysis results show that the ARIMA model performed fairly well for short-term predictions but relatively high MAPE value. The extreme gradient boosting model gave the best performance with the lowest RMSE and MAPE value. Hence, it is evident that after proper hyperparameter tuning, ensemble learning techniques can be used to create robust stock price-prediction models.
ER  - 

