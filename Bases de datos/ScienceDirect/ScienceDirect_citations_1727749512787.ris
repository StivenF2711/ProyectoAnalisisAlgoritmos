TY  - JOUR
T1  - Demand response assisted energy and reserve procurement in renewable integrated dynamic energy market
AU  - Sharma, Akanksha
AU  - Sharma, Sumedha
JO  - Electric Power Systems Research
VL  - 236
SP  - 110932
PY  - 2024
DA  - 2024/11/01/
SN  - 0378-7796
DO  - https://doi.org/10.1016/j.epsr.2024.110932
UR  - https://www.sciencedirect.com/science/article/pii/S0378779624008186
KW  - Ancillary services
KW  - Demand response
KW  - Dynamic optimal power flow
KW  - Market clearing
KW  - Spinning reserve
AB  - As wind power integration increases, the need for heightened reserve procurement becomes imperative for maintaining system reliability. In the dynamic and deregulated multi-objective environment, this study investigates the impact of varying degrees of uncertainty in wind conditions on the acquisition of energy and spinning reserve ancillary services. The investigation focuses on obtaining reserve capacity through thermal generators and demand response (DR) offers, while addressing wind generation variability. To achieve this, the study employs the multi-objective particle swarm and electric field hybrid optimization algorithm to co-optimize total cost and emissions in the simultaneous market clearing of energy and SRAS procurement. The model’s assessment involves a comprehensive evaluation over a one-day period, encompassing 24 hourly intervals on both IEEE 30-bus and IEEE 118-bus test systems. The performance evaluation of the developed algorithm includes a comparative analysis with other heuristic methods, assessing objectives and statistical performance metrics like convergence and spread, complemented by corresponding box plots. The findings highlight how the presented model successfully tackles the challenges posed by fluctuating wind conditions and dynamic DR offers, providing valuable insights for optimizing energy procurement and reserve capacity in wind-integrated power systems.
ER  - 

TY  - JOUR
T1  - The curiosity-creativity element in HI-AI materials discovery
AU  - Ozin, Geoffrey
AU  - Siler, Todd
AU  - Qian, Chenxi
AU  - Zhou, Wenjie
JO  - Matter
VL  - 7
IS  - 3
SP  - 718
EP  - 722
PY  - 2024
DA  - 2024/03/06/
SN  - 2590-2385
DO  - https://doi.org/10.1016/j.matt.2024.01.001
UR  - https://www.sciencedirect.com/science/article/pii/S2590238524000018
AB  - A career materials chemist and a group of art-science colleagues explore the colorful tapestry of curiosity-creativity-imagination-intuition-wonderment elements inherent in the process of materials discovery in the past and today by human intelligence and in the future by artificial intelligence.
ER  - 

TY  - CHAP
T1  - Preface
AU  - Chan, C.C.
A2  - Chan, C.C.
A2  - Zhou, George You
A2  - Han, Wei
BT  - Integration of Energy, Information, Transportation and Humanity
PB  - Elsevier
SP  - xv
EP  - xix
PY  - 2024
DA  - 2024/01/01/
SN  - 978-0-323-95521-8
DO  - https://doi.org/10.1016/B978-0-323-95521-8.00022-1
UR  - https://www.sciencedirect.com/science/article/pii/B9780323955218000221
ER  - 

TY  - JOUR
T1  - Concept-cognitive learning survey: Mining and fusing knowledge from data
AU  - Guo, Doudou
AU  - Xu, Weihua
AU  - Ding, Weiping
AU  - Yao, Yiyu
AU  - Wang, Xizhao
AU  - Pedrycz, Witold
AU  - Qian, Yuhua
JO  - Information Fusion
VL  - 109
SP  - 102426
PY  - 2024
DA  - 2024/09/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2024.102426
UR  - https://www.sciencedirect.com/science/article/pii/S1566253524002045
KW  - Concept-cognitive learning
KW  - Data mining
KW  - Granular computing
KW  - Information fusion
KW  - Machine learning
AB  - Concept-cognitive learning (CCL), an emerging intelligence learning paradigm, has recently become a popular research subject in artificial intelligence and cognitive computing. A central notion of CCL is cognitive and learning things via concepts. In this process, concepts play a fundamental role when mining and fusing knowledge from data to wisdom. With the in-depth research and expansion of CCL in scopes, goals, and methodologies, some difficulties have gradually emerged, including some vague terminology, ambiguous views, and scattered research. Hence, a systematic and comprehensive review of the development process and advanced research about CCL is particularly necessary at the moment. This paper summarizes the theoretical significance, application value, and future development potential of CCL. More importantly, by synthesizing the reviewed related research, we can acquire some interesting results and answer three essential questions: (1) why examine a cognitive and learning framework based on concept? (2) what is the concept-cognitive learning? (3) how to make concept-cognitive learning? The findings of this work could act as a valuable guide for related studies in quest of a clear understanding of the closely related research issues around concept-cognitive learning.
ER  - 

TY  - JOUR
T1  - ACP-based social computing and parallel intelligence: Societies 5.0 and beyond
AU  - Wang, Xiao
AU  - Li, Lingxi
AU  - Yuan, Yong
AU  - Ye, Peijun
AU  - Wang, Fei-Yue
JO  - CAAI Transactions on Intelligence Technology
VL  - 1
IS  - 4
SP  - 377
EP  - 393
PY  - 2016
DA  - 2016/10/01/
SN  - 2468-2322
DO  - https://doi.org/10.1016/j.trit.2016.11.005
UR  - https://www.sciencedirect.com/science/article/pii/S246823221630083X
KW  - Social computing
KW  - Societies 5.0
KW  - Parallel intelligence
KW  - Knowledge automation
KW  - Cyber-physical-social system
KW  - Artificial societies
KW  - Computational experiments
KW  - Parallel execution
AB  - Social computing, as the technical foundation of future computational smart societies, has the potential to improve the effectiveness of open-source big data usage, systematically integrate a variety of elements including time, human, resources, scenarios, and organizations in the current cyber-physical-social world, and establish a novel social structure with fair information, equal rights, and a flat configuration. Meanwhile, considering the big modeling gap between the model world and the physical world, the concept of parallel intelligence is introduced. With the help of software-defined everything, parallel intelligence bridges the big modeling gap by means of constructing artificial systems where computational experiments can be implemented to verify social policies, economic strategies, and even military operations. Artificial systems play the role of “social laboratories” in which decisions are computed before they are executed in our physical society. Afterwards, decisions with the expected outputs are executed in parallel in both the artificial and physical systems to interactively sense, compute, evaluate and adjust system behaviors in real-time, leading system behaviors in the physical system converging to those proven to be optimal in the artificial ones. Thus, the smart guidance and management for our society can be achieved.
ER  - 

TY  - JOUR
T1  - Application of distance learning in mathematics through adaptive neuro-fuzzy learning method
AU  - Stojanović, Jelena
AU  - Petkovic, Dalibor
AU  - Alarifi, Ibrahim M
AU  - Cao, Yan
AU  - Denic, Nebojsa
AU  - Ilic, Jelena
AU  - Assilzadeh, Hamid
AU  - Resic, Sead
AU  - Petkovic, Biljana
AU  - Khan, Afrasyab
AU  - Milickovic, Milosav
JO  - Computers & Electrical Engineering
VL  - 93
SP  - 107270
PY  - 2021
DA  - 2021/07/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2021.107270
UR  - https://www.sciencedirect.com/science/article/pii/S0045790621002536
KW  - Pupils
KW  - E-learning
KW  - Distance learning
KW  - Moodle
KW  - Computational intelligent
AB  - The main aim of the study is analyzing of pupils’ knowledge in mathematics by adaptive neuro fuzzy inference system (ANFIS) after implementation of distance learning application or e-learning (electronic learning). Since a large number of faculties and other institutions are increasingly using e-learning, it can be stated that for this purpose the Modular object-oriented dynamic learning environment (Moodle) learning management system (LMS) is mostly used. This paper deals with the analysis of distance learning and the application of Moodle LMS in higher education institutions, taking into account the impact of such education on the quality of teaching and the acquisition of knowledge by students, and the methods teachers use in Serbia. The ANFIS is used to determine which factors are the most important for pupils’ performance in mathematics. The results show that the main influence on the pupils’ performance is their prior knowledge. The prior knowledge is more effective when it is combined with education software in the lectures of mathematics in elementary school. In secondary school, the prior knowledge is more effective if it is combined with motivation for learning mathematics.
ER  - 

TY  - JOUR
T1  - Automated Water Supply Model (AWSM): Streamlining and standardizing application of a physically based snow model for water resources and reproducible science
AU  - Havens, Scott
AU  - Marks, Danny
AU  - Sandusky, Micah
AU  - Hedrick, Andrew
AU  - Johnson, Micah
AU  - Robertson, Mark
AU  - Trujillo, Ernesto
JO  - Computers & Geosciences
VL  - 144
SP  - 104571
PY  - 2020
DA  - 2020/11/01/
SN  - 0098-3004
DO  - https://doi.org/10.1016/j.cageo.2020.104571
UR  - https://www.sciencedirect.com/science/article/pii/S0098300420305598
KW  - Hydrology
KW  - Computational method
KW  - Software engineering
KW  - Data assimilation
AB  - Reproducible science requires a shift in thinking and application for how data, code and analysis are shared. Now, scientists must act more like software engineers to design models and perform analysis that use principles and techniques pioneered by software developers. Creating reproducible models that are easy to use and understand is in the best interest for the snow and hydrology community, enabling studies by other researchers and facilitating technology transfer to operational applications. Here, we present the Automated Water Supply Model (AWSM) that streamlines and standardizes the workflow of a physically based snow model to create fully reproducible model simulations that can be utilized by researchers and operational water resource managers. AWSM orchestrates four core components that historically required significant, ad-hoc modeler interaction to load the input data, spatially interpolate to the modeling domain, run the models and process the outputs. Because AWSM was developed using principles and techniques from software engineering, users can quickly perform reproducible simulations on any operating system, from a laptop to the cloud. The three fully reproducible example case studies showcase the simplicity and flexibility of using AWSM to perform simulations from small research catchments to simulations that aid in real time water management decisions.
ER  - 

TY  - JOUR
T1  - An Inverse Optimization Model for Human Resource Allocation Problem Considering Competency Disadvantage Structure
AU  - Lili, Zhang
JO  - Procedia Computer Science
VL  - 112
SP  - 1611
EP  - 1622
PY  - 2017
DA  - 2017/01/01/
T2  - Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2017.08.248
UR  - https://www.sciencedirect.com/science/article/pii/S1877050917316575
KW  - inverse optimization
KW  - linear programming
KW  - human resource allocation
KW  - competency
KW  - evaluation according to disadvantage structure
AB  - Most of serious and major accidents that happened during the production procedure of process industry are caused by improper equipment operations, which is further owing to inappropriate human resources allocation and ignorance of individual competencies differences. In order to take both of competency disadvantage and adjustment requirement into consideration, we use an inverse optimization method to solve a human resource allocation problem, and furthermore, adjust equipment operating parameters to make the per-defined settings optimized, such as the total number of jobs, security-related parameters and so on.In the solving process, firstly a standard competence hierarchy system is conducted; secondly we propose an assessment method according to disadvantage structure; thirdly we use inverse optimization method to solve the problem and optimize the predefined allocation plan. Lastly, we give an example to prove its feasibility and effectiveness. In this paper a novel formulation of human resource allocation problem is proposed, in which some of main individual characteristics are considered and described mathematically, including psychology, behaviour and characteristics diged from them such as weakness. The other contribution of this paper is using inverse optimization to adjust parameters based on the given ideal allocation plan. Both of these propositions have a positive significance on promoting development and security construction for process industries.This research incorporates the academic thinking of inverse optimization, it not only puts psychology and behavior into optimization model, but also data mines weakness characteristics under the psychology and behavior data, and find a new way to introducing the weakness characteristics into decision making model. It provides a new thought for the following decision making problem, that is the ideal decision plan is known, and optimization parameters are changeable. It promotes the combining of psychology, behavior and operations research, it is good for process industries to develop in a safety and efficiency way.
ER  - 

TY  - JOUR
T1  - Diagnosing social failures in sustainable supply chains using a modified Pythagorean fuzzy distance to ideal solution
AU  - Hendiani, Sepehr
AU  - Lev, Benjamin
AU  - Gharehbaghi, Afsaneh
JO  - Computers & Industrial Engineering
VL  - 154
SP  - 107156
PY  - 2021
DA  - 2021/04/01/
SN  - 0360-8352
DO  - https://doi.org/10.1016/j.cie.2021.107156
UR  - https://www.sciencedirect.com/science/article/pii/S0360835221000607
KW  - Supply chain management
KW  - Corporate social responsibility
KW  - Social sustainability
KW  - Interval-valued Pythagorean fuzzy sets
KW  - Sustainable development
AB  - Social sustainability can be mentioned as one of the pivotal objectives towards sustainable development which has received the least attention comparing to environmental and economic dimensions during these past years. Due to its impact on organization’s competitive power, researchers have proposed models to measure social performance in supply chains. However, most of these researches reveal shortcomings once encountering the cases with a huge number of criteria due to their complex computations. In order to fill this gap, this study proposes a new soft computing multi-criteria interval-valued Pythagorean fuzzy distance to ideal solution approach based on interval-valued Pythagorean closeness which performs outstandingly in cases with a high fluctuation in the number of criteria. A new mechanism is defined to distinguish the weak performing social factors through supply chains by classifying them into four categorize based on their performance and distance to the best performing factors. This approach is unique in the sense that it both covers a remarkable amount of uncertainty and eases the computational processes of the previous multi-criteria decision making approaches by modifying the steps to select the most ideal solution. The feasibility and applicability of this approach have been validated by applications to a numerical case and comparative analysis.
ER  - 

TY  - JOUR
T1  - Dynamic neural reconfiguration for distinct strategies during competitive social interactions
AU  - Yang, Ruihan
AU  - Ma, Yina
AU  - Pan, Bao-Bao
AU  - Bhatt, Meghana A.
AU  - Lohrenz, Terry
AU  - Gu, Hua-Guang
AU  - Kanen, Jonathan W.
AU  - Camerer, Colin F.
AU  - Montague, P. Read
AU  - Luo, Qiang
JO  - NeuroImage
VL  - 263
SP  - 119585
PY  - 2022
DA  - 2022/11/01/
SN  - 1053-8119
DO  - https://doi.org/10.1016/j.neuroimage.2022.119585
UR  - https://www.sciencedirect.com/science/article/pii/S1053811922007005
KW  - Dynamic behavior modeling
KW  - Dynamic brain network
KW  - Information flow
KW  - Strategic deception
AB  - Information exchange between brain regions is key to understanding information processing for social decision-making, but most analyses ignore its dynamic nature. New insights on this dynamic might help us to uncover the neural correlates of social cognition in the healthy population and also to understand the malfunctioning neural computations underlying dysfunctional social behavior in patients with mental disorders. In this work, we used a multi-round bargaining game to detect switches between distinct bargaining strategies in a cohort of 76 healthy participants. These switches were uncovered by dynamic behavioral modeling using the hidden Markov model. Proposing a novel model of dynamic effective connectivity to estimate the information flow between key brain regions, we found a stronger interaction between the right temporoparietal junction (rTPJ) and the right dorsolateral prefrontal cortex (rDLPFC) for the strategic deception compared with the social heuristic strategies. The level of deception was associated with the information flow from the Brodmann area 10 to the rTPJ, and this association was modulated by the rTPJ-to-rDLPFC information flow. These findings suggest that dynamic bargaining strategy is supported by dynamic reconfiguration of the rDLPFC-and-rTPJ interaction during competitive social interactions.
ER  - 

TY  - JOUR
T1  - Call market book information and efficiency
AU  - Arifovic, Jasmina
AU  - Ledyard, John
JO  - Journal of Economic Dynamics and Control
VL  - 31
IS  - 6
SP  - 1971
EP  - 2000
PY  - 2007
DA  - 2007/06/01/
T2  - Tenth Workshop on Economic Heterogeneous Interacting Agents
SN  - 0165-1889
DO  - https://doi.org/10.1016/j.jedc.2007.01.006
UR  - https://www.sciencedirect.com/science/article/pii/S0165188907000073
KW  - Computer testbeds
KW  - Call markets
KW  - Learning
KW  - Experiments with human subjects
KW  - Closed book
KW  - Market design
AB  - What are the consequences of making bids and offers in the book available to traders in a call market? This is a problem in market design. We employ a computational mechanism design methodology to attack this problem and find that allocative efficiencies are higher in a closed book design. We validate our computational approach by running a series of tests with human subjects in exactly the same environments.
ER  - 

TY  - JOUR
T1  - Progress of independent component analysis and its recent application in spectroscopy quantitative analysis
AU  - Li, Yankun
AU  - Zhang, Mengsha
AU  - Bian, Xihui
AU  - Tian, Lu
AU  - Tang, Chen
JO  - Microchemical Journal
VL  - 202
SP  - 110836
PY  - 2024
DA  - 2024/07/01/
SN  - 0026-265X
DO  - https://doi.org/10.1016/j.microc.2024.110836
UR  - https://www.sciencedirect.com/science/article/pii/S0026265X24009482
KW  - Independent component analysis
KW  - Spectroscopy
KW  - Quantitative analysis
KW  - Chemometrics
AB  - Independent component analysis (ICA) is a blind source signal processing technique that separates the source signal from the mixed signal. ICA makes great progress in researches and applications in the field of spectroscopy. This review summed up the principles and theoretical foundations of ICA algorithm in spectral analysis, the commonly used and advanced ICA algorithms, and the strategies for determining the optimal number of independent components. Then the progress of researches and applications of ICA combined with other chemometric method for quantitative resolution in spectroscopy technique recently, including infrared, Raman, fluorescence, UV–visible and nuclear magnetic resonance spectroscopy were reviewed. The possible problems concerning ICA in the analysis of practical complex system were discussed and corresponding solutions were proposed, and the research trends and development futures of ICA in the field of quantitative analysis were also prospected. The review can provide a basis and reference for the selection and use of quantitative analytical strategies in the complex mixtures.
ER  - 

TY  - JOUR
T1  - Automatic identification of schizophrenia based on EEG signals using dynamic functional connectivity analysis and 3D convolutional neural network
AU  - Shen, Mingkan
AU  - Wen, Peng
AU  - Song, Bo
AU  - Li, Yan
JO  - Computers in Biology and Medicine
VL  - 160
SP  - 107022
PY  - 2023
DA  - 2023/06/01/
SN  - 0010-4825
DO  - https://doi.org/10.1016/j.compbiomed.2023.107022
UR  - https://www.sciencedirect.com/science/article/pii/S0010482523004870
KW  - ScZ
KW  - EEG
KW  - Cross mutual information
KW  - 3D convolutional neural network
KW  - Default mode network
AB  - Schizophrenia (ScZ) is a devastating mental disorder of the human brain that causes a serious impact of emotional inclinations, quality of personal and social life and healthcare systems. In recent years, deep learning methods with connectivity analysis only very recently focused into fMRI data. To explore this kind of research into electroencephalogram (EEG) signal, this paper investigates the identification of ScZ EEG signals using dynamic functional connectivity analysis and deep learning methods. A time-frequency domain functional connectivity analysis through cross mutual information algorithm is proposed to extract the features in alpha band (8–12 Hz) of each subject. A 3D convolutional neural network technique was applied to classify the ScZ subjects and health control (HC) subjects. The LMSU public ScZ EEG dataset is employed to evaluate the proposed method, and a 97.74 ± 1.15% accuracy, 96.91 ± 2.76% sensitivity and 98.53 ± 1.97% specificity results were achieved in this study. In addition, we also found not only the default mode network region but also the connectivity between temporal lobe and posterior temporal lobe in both right and left side have significant difference between the ScZ and HC subjects.
ER  - 

TY  - JOUR
T1  - Three-dimensional structures, dynamics and calcium-mediated interactions of the exopolysaccharide, Infernan, produced by the deep-sea hydrothermal bacterium Alteromonas infernus
AU  - Makshakova, Olga
AU  - Zykwinska, Agata
AU  - Cuenot, Stephane
AU  - Colliec-Jouault, Sylvia
AU  - Perez, Serge
JO  - Carbohydrate Polymers
VL  - 276
SP  - 118732
PY  - 2022
DA  - 2022/01/15/
SN  - 0144-8617
DO  - https://doi.org/10.1016/j.carbpol.2021.118732
UR  - https://www.sciencedirect.com/science/article/pii/S014486172101119X
KW  - Exopolysaccharides, 
KW  - 3 dimensional structures
KW  - Gel forming
KW  - Molecular dynamics
KW  - Quantum chemistry
KW  - Calcium binding
AB  - The exopolysaccharide Infernan, from the bacterial strain GY785, has a complex repeating unit of nine monosaccharides established on a double-layer of sidechains. A cluster of uronic and sulfated monosaccharides confers to Infernan functional and biological activities. We characterized the 3-dimensional structures and dynamics along Molecular Dynamics trajectories and clustered the conformations in extended two-fold and five-fold helical structures. The electrostatic potential distribution over all the structures revealed negatively charged cavities explored for Ca2+ binding through quantum chemistry computation. The transposition of the model of Ca2+complexation indicates that the five-fold helices are the most favourable for interactions. The ribbon-like shape of two-fold helices brings neighbouring chains in proximity without steric clashes. The cavity chelating the Ca2+ of one chain is completed throughout the interaction of a sulfate group from the neighbouring chain. The resulting is a ‘junction zone’ based on unique chain-chain interactions governed by a heterotypic binding mode.
ER  - 

TY  - JOUR
T1  - A mixed derivative terms removing method in multi-asset option pricing problems
AU  - Company, R.
AU  - Egorova, V.N.
AU  - Jódar, L.
AU  - Soleymani, F.
JO  - Applied Mathematics Letters
VL  - 60
SP  - 108
EP  - 114
PY  - 2016
DA  - 2016/10/01/
SN  - 0893-9659
DO  - https://doi.org/10.1016/j.aml.2016.04.011
UR  - https://www.sciencedirect.com/science/article/pii/S0893965916301252
KW  - Multiasset option pricing
KW  - Multidimensional partial differential equations
KW  - Mixed derivative terms
KW  -  factorization
KW  - Bunch–Kaufman factorization
AB  - The challenge of removing the mixed derivative terms of a second order multidimensional partial differential equation is addressed in this paper. The proposed method, which is based on proper algebraic factorization of the so-called diffusion matrix, depends on the semidefinite or indefinite character of this matrix. Computational cost of the transformed equation is considerably reduced and well-known numerical drawbacks are avoided.
ER  - 

TY  - JOUR
T1  - Clinical heterogeneity and ECT in patients with clozapine resistant schizophrenia
AU  - Markota, Matej
AU  - Croarkin, Paul E.
AU  - Coombes, Brandon J.
AU  - Gentry, Melanie T.
AU  - Leung, Jonathan G.
JO  - Schizophrenia Research
VL  - 272
SP  - 77
EP  - 78
PY  - 2024
DA  - 2024/10/01/
SN  - 0920-9964
DO  - https://doi.org/10.1016/j.schres.2024.08.002
UR  - https://www.sciencedirect.com/science/article/pii/S0920996424003736
ER  - 

TY  - JOUR
T1  - What is ‘wrong’ in a neural model
AU  - Plebe, Alessio
JO  - Cognitive Systems Research
VL  - 39
SP  - 4
EP  - 14
PY  - 2016
DA  - 2016/09/01/
T2  - From human to artificial cognition (and back): new perspectives of cognitively inspired AI systems
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2015.12.012
UR  - https://www.sciencedirect.com/science/article/pii/S1389041716000085
KW  - Moral cognition
KW  - Neural computation
KW  - Orbitofrontal cortex
KW  - Amygdala
KW  - Self-organization
AB  - Neural computation has an influential role in the study of human capacities and behaviors. It has been the dominant approach in the vision science of the last half century, and it is currently one of the fundamental methods of investigation for most higher cognitive functions. Yet, neurocomputational approaches to moral behavior are lacking. Computational modeling in general has been scarcely pursued in morality, and existent non-neural attempts have failed to account for the mental processes involved in morality. In this paper we argue that recently the situation has evolved in a way that subverted the insufficient knowledge on the basic organization of moral cognition in brain circuits, making the project of modeling morality in neurocomputational terms feasible. We will present an original architecture that combines reinforcement learning and Hebbian learning, aimed at simulating forms of moral behavior in a simple artificial context. The relationship between language and morality is controversial. In the analytic tradition of philosophy, morality is essentially the language of morals. On the other side, current cognitive ethology has shown how non human species display behaviors that are surprisingly similar to those prescribed by human ethics. Nevertheless, morality in humans is deeply entrenched with language, and the semantics of words like ‘wrong’ resists consensual explanations. The model here proposed includes an auditory processing pathway, with the purpose of showing how the coding of “wrong”, even if highly simplified with respect to its rich content in natural language, can emerge in the course of moral learning.
ER  - 

TY  - CHAP
T1  - Chapter 5 - Models for improving fresh produce chains
AU  - Aggarwal, Deepak
AU  - Prussia, Stanley E.
A2  - Florkowski, Wojciech J.
A2  - Banks, Nigel H.
A2  - Shewfelt, Robert L.
A2  - Prussia, Stanley E.
BT  - Postharvest Handling (Fourth Edition)
PB  - Academic Press
CY  - San Diego
SP  - 135
EP  - 164
PY  - 2022
DA  - 2022/01/01/
SN  - 978-0-12-822845-6
DO  - https://doi.org/10.1016/B978-0-12-822845-6.00005-1
UR  - https://www.sciencedirect.com/science/article/pii/B9780128228456000051
KW  - Soft systems
KW  - modeling
KW  - simulation
KW  - postharvest quality simulator
KW  - supply chain game
KW  - soft systems methodologies
AB  - Fresh produce passes through various links of refrigerated or nonrefrigerated value chains from the farmer’s plot to the consumer’s plate. Extensive research since the 1960s has focused on deciphering the ideal postharvest handling conditions to maximize product shelf life for different produce species. However, ideal conditions are seldom met in real-life value chains as the produce travels from field to sorting area, packaging, loading, transportation, unloading, retail display, and the consumer’s car. Further, retail and food service managers often are not provided information about previous handling that affects the remaining shelf life at their link of a value chain. The primary goal is to provide fresh produce with desirable qualities such as firmness, color, ripeness, rupture strength, and taste to the consumers. Postharvest value chains require assimilation of systems thinking, systems dynamics, and physiology of the fresh produce. These can be woven together using modeling and simulation games. Various types of models such as mental models, conceptual models, soft systems, and others can be applied. The underlying equations for the models are the value chain dynamics and the physiological changes in produce at varying storage conditions. The models can then be provided to the intended user as a simple spreadsheet model or as visually appealing games or videos, with the simulations running in the background. The models predicting postharvest quality changes could help decision makers alter shipment destinations and storage conditions so that fresh produce arrives with the desired consumer characteristics. Playing simulation games can be an entertaining method for everyone interested in fresh fruits and vegetables to experience the challenges and satisfactions of learning the consequences of decisions they make while playing the role of a manager at each link in a selected chain. Developing a model requires understanding about the interactions within a system and its surroundings. When developing models, information gaps often are found that require research to learn how a system works. Learning continues as users of the model gain experience without the costs or risks of changing real-life situations. Using soft systems methodology to study fresh fruit and vegetable value chains would include developing models of their activities, interconnections, flows of information, and political and social environments. This could improve our understanding of how chains could function as if they were systems. Other types of models would result from using the critical systems practice methodology as a guide for learning the technical, managerial, and social changes necessary to increase per capita consumption, reduce losses and waste, and improve profits for family farms and other global issues related to postharvest handling of fresh produce. Multiplayer simulation games would help managers and leaders learn how to improve entire fresh fruit and vegetable chains.
ER  - 

TY  - JOUR
T1  - Modeling combination therapies in patient cohorts and cell cultures using correlated drug action
AU  - Arun, Adith S.
AU  - Kim, Sung-Cheol
AU  - Ahsen, Mehmet Eren
AU  - Stolovitzky, Gustavo
JO  - iScience
VL  - 27
IS  - 3
SP  - 108905
PY  - 2024
DA  - 2024/03/15/
SN  - 2589-0042
DO  - https://doi.org/10.1016/j.isci.2024.108905
UR  - https://www.sciencedirect.com/science/article/pii/S2589004224001263
KW  - Computational chemistry
KW  - Applied computing
AB  - Summary
Characterizing the effect of combination therapies is vital for treating diseases like cancer. We introduce correlated drug action (CDA), a baseline model for the study of drug combinations in both cell cultures and patient populations, which assumes that the efficacy of drugs in a combination may be correlated. We apply temporal CDA (tCDA) to clinical trial data, and demonstrate the utility of this approach in identifying possible synergistic combinations and others that can be explained in terms of monotherapies. Using MCF7 cell line data, we assess combinations with dose CDA (dCDA), a model that generalizes other proposed models (e.g., Bliss response-additivity, the dose equivalence principle), and introduce Excess over CDA (EOCDA), a new metric for identifying possible synergistic combinations in cell culture.
ER  - 

TY  - JOUR
T1  - New Insights into the Human Brain’s Cognitive Organization: Views from the Top, from the Bottom, from the Left and, particularly, from the Right
AU  - Velichkovsky, Boris
AU  - Nedoluzhko, Artem
AU  - Goldberg, Elkhonon
AU  - Efimova, Olga
AU  - Sharko, Fedor
AU  - Rastorguev, Sergey
AU  - Krasivskaya, Anna
AU  - Sharaev, Maxim
AU  - Korosteleva, Anastasia
AU  - Ushakov, Vadim
JO  - Procedia Computer Science
VL  - 169
SP  - 547
EP  - 557
PY  - 2020
DA  - 2020/01/01/
T2  - Postproceedings of the 10th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2019 (Tenth Annual Meeting of the BICA Society), held August 15-19, 2019 in Seattle, Washington, USA
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2020.02.211
UR  - https://www.sciencedirect.com/science/article/pii/S1877050920303343
KW  - fMRI
KW  - effective connectivity
KW  - levels of cognitive organization
KW  - dynamic causal modeling (DCM)
KW  - protein-coding genes
KW  - microRNA
KW  - gene expression
KW  - modes of attention
KW  - hemispheric lateralization
AB  - The view that the left cerebral hemisphere in humans “dominates” over the “subdominant” right hemisphere has been so deeply entrenched in neuropsychology that no amount of evidence seems able to overcome it. In this article, we examine inhibitory cause-and-effect connectivity among human brain structures related to different parts of the triune evolutionary stratification —archicortex, paleocortex and neocortex— in relation to early and late phases of a prolonged resting-state functional magnetic resonance imaging (fMRI) experiment. With respect to the evolutionarily youngest parts of the human cortex, the left and right frontopolar regions, we also provide data on the asymmetries in underlying molecular mechanisms, namely on the differential expression of the protein-coding genes and regulatory microRNA sequences. In both domains of research, our results contradict the established view by demonstrating a pronounced right-to-left vector of causation in the hemispheric interaction at multiple levels of brain organization. There may be several not mutually exclusive explanations for the evolutionary significance of this pattern of lateralization. One of the explanations emphasizes the computational advantage of separating the neural substrates for processing novel information ("exploration") mediated predominantly by the right hemisphere, and processing with reliance on established cognitive routines and representations ("exploitation") mediated predominantly by the left hemisphere.
ER  - 

TY  - JOUR
T1  - An entrepreneurial education game for effectively Tracing the knowledge structure of college students - based on adaptive algorithms
AU  - Fang, Ming
AU  - Liu, Yan
AU  - Hu, Chenbang
AU  - Huang, Jian
AU  - Wu, Lei
JO  - Entertainment Computing
VL  - 49
SP  - 100632
PY  - 2024
DA  - 2024/03/01/
SN  - 1875-9521
DO  - https://doi.org/10.1016/j.entcom.2023.100632
UR  - https://www.sciencedirect.com/science/article/pii/S1875952123000873
KW  - Adaptive
KW  - Knowledge tracking
KW  - Entrepreneurship education
KW  - Games
KW  - Bayesian network
AB  - The application of games in the field of education has brought new developments and updated educational needs to games. To maintain and improve students' learning motivation and interest, and more effectively carry out personalized teaching capabilities, research focuses on students' personalized knowledge structure. Starting from tracking the differences in knowledge structures among different learners, a game model based on entrepreneurial education theory has been designed. Through modeling learner knowledge using Bayesian network, the research constructs a game framework of entrepreneurial education for adaptive learning. On this basis, a new feature crossover method is proposed to construct a deep knowledge tracking model based on feature embedding and attention mechanism. It was combined with adaptive learning technology to ultimately construct an entrepreneurial education game model that integrates adaptive learning and improved deep knowledge tracking. A total of 379 students participated in the experiment. The experimental results on the ASSISTments09 open data set show that the area value under the receptivity curve of this model is 0.913, which is 8.8% to 26.6% higher than that of advanced models of the same type. The performance of the research model is optimal on different training scale data. Students' adaptability to entrepreneurship education games is higher than classroom teaching, with a difference between 2% and 11%. The experimental data demonstrates the high applicability of this research method and also achieves the goal of game design, which has certain practical teaching application value.
ER  - 

TY  - CHAP
T1  - Chapter 12 - Chemical space and molecular descriptors for QSAR studies
AU  - Consonni, Viviana
AU  - Ballabio, Davide
AU  - Todeschini, Roberto
A2  - Roy, Kunal
BT  - Cheminformatics, QSAR and Machine Learning Applications for Novel Drug Development
PB  - Academic Press
SP  - 303
EP  - 327
PY  - 2023
DA  - 2023/01/01/
SN  - 978-0-443-18638-7
DO  - https://doi.org/10.1016/B978-0-443-18638-7.00022-0
UR  - https://www.sciencedirect.com/science/article/pii/B9780443186387000220
KW  - Molecular descriptors
KW  - Chemical space
KW  - Molecular similarity
KW  - Mathematical chemistry
KW  - QSAR
KW  - In silico modeling
KW  - Cheminformatics
AB  - With the continuous growth of the real and virtual chemical space, efficient computer-assisted methods are required to discover new substances with desired properties and/or predict properties of interest for untested molecules. These methods rely on the principle that the physicochemical and biological properties of compounds are the effects of their structural characteristics. Therefore, the starting point of any chemo- and bioinformatics application is the conversion of a symbolic representation of the molecular structure into numerical information through the calculation of molecular descriptors. Molecular descriptors encode a wide variety of specific molecular features with a different effect on experimental properties and impact on the perceived chemical similarity between molecules. The choice of molecular descriptors is crucial in determining the chemical space representation and computational modeling outcomes. After introducing the fundamental concepts of molecular descriptors in the current epistemological framework, this chapter reviews some of the well-known classical molecular descriptors and fingerprints.
ER  - 

TY  - CHAP
T1  - 17 - Bio-inspired design
AU  - Mistry, Yash
AU  - Anderson, Daniel
AU  - Bhate, Dhruv
A2  - Yadroitsev, Igor
A2  - Yadroitsava, Ina
A2  - du Plessis, Anton
A2  - MacDonald, Eric
BT  - Fundamentals of Laser Powder Bed Fusion of Metals
PB  - Elsevier
SP  - 467
EP  - 489
PY  - 2021
DA  - 2021/01/01/
T2  - Additive Manufacturing Materials and Technologies
SN  - 978-0-12-824090-8
DO  - https://doi.org/10.1016/B978-0-12-824090-8.00010-X
UR  - https://www.sciencedirect.com/science/article/pii/B978012824090800010X
KW  - Additive manufacturing
KW  - Bio-inspired design
KW  - Biomimicry
KW  - Cellular materials
KW  - Complexity
KW  - Hierarchy
KW  - Laser powder bed fusion
KW  - Periodicity
KW  - Texture
KW  - Topology optimization
AB  - Advances in additive manufacturing, computational design tools, and digitization techniques are converging in an exciting new era of engineering design, as humanity has never experienced before. Within this convergent domain, Bio-Inspired Design (BID) is a particularly promising area of research since the potential space for establishing structure-function correlation is vast, and the majority of it is untapped. In this chapter, bio-inspired design is first introduced, specifically in the context of the Laser Powder Bed Fusion (L-PBF) process. Practical approaches for implementing BID for L-PBF are discussed, followed by a discussion of key general design concepts that can be abstracted for BID. Examples of how BID and L-PBF have been combined are then presented, followed by a consideration of some of the most important design constraints posed by the L-PBF process that the bio-inspired designer needs to be aware of. The chapter concludes with a forward looking discussion of opportunities in this domain.
ER  - 

TY  - JOUR
T1  - AI for Technoscientific Discovery: A Human-Inspired Architecture
AU  - Tsao, J.Y.
AU  - Abbott, R.G.
AU  - Crowder, D.C.
AU  - Desai, S.
AU  - Dingreville, R.P.M.
AU  - Fowler, J.E.
AU  - Garland, A.
AU  - Iyer, P.P.
AU  - Murdock, J.
AU  - Steinmetz, S.T.
AU  - Yarritu, K.A.
AU  - Johnson, C.M.
AU  - Stracuzzi, D.J.
JO  - Journal of Creativity
VL  - 34
IS  - 2
SP  - 100077
PY  - 2024
DA  - 2024/08/01/
SN  - 2713-3745
DO  - https://doi.org/10.1016/j.yjoc.2024.100077
UR  - https://www.sciencedirect.com/science/article/pii/S2713374524000037
KW  - Artificial intelligence
KW  - creativity
KW  - extended neurosymbolic knowledge
KW  - technoscientific method
AB  - We present a high-level architecture for how artificial intelligences might advance and accumulate scientific and technological knowledge, inspired by emerging perspectives on how human intelligences advance and accumulate such knowledge. Agents advance knowledge by exercising a technoscientific method—an interacting combination of scientific and engineering methods. The technoscientific method maximizes a quantity we call “useful learning” via more-creative implausible utility (including the “aha!” moments of discovery), as well as via less-creative plausible utility. Society accumulates the knowledge advanced by agents so that other agents can incorporate and build on to make further advances. The proposed architecture is challenging but potentially complete: its execution might in principle enable artificial intelligences to advance and accumulate an equivalent of the full range of human scientific and technological knowledge.
ER  - 

TY  - JOUR
T1  - Does prior mathematics knowledge really lead to variation in elementary statistics performance? Evidence from a developing country
AU  - Woodward, George
AU  - Galagedera, Don
JO  - International Journal of Educational Development
VL  - 26
IS  - 6
SP  - 631
EP  - 639
PY  - 2006
DA  - 2006/11/01/
SN  - 0738-0593
DO  - https://doi.org/10.1016/j.ijedudev.2006.02.005
UR  - https://www.sciencedirect.com/science/article/pii/S0738059306000071
KW  - Curriculum
KW  - Mathematics
KW  - Educational policy
KW  - Elementary statistics
AB  - A model incorporating prerequisite mathematics performance and other variables deemed to be associated with learning elementary statistics (ES) is developed. The relationship between ES performance and the explanatory variables is well represented by the logistics form. Aptitude, effort and motivation are the only significant explanatory variables of ES performance. Since prerequisite mathematics is not significant, statistical thinking at the tertiary level may be mostly intuitive and non-mathematical. Students with low aptitude experience increasing returns to effort over the first half of the feasible effort interval, while high-aptitude students experience diminishing returns at all levels of effort. The levels of effort required to achieve a minimum pass are interpreted.
ER  - 

TY  - JOUR
T1  - On the geometric origin of spurious waves in finite-volume discretizations of shallow water equations on triangular meshes
AU  - Danilov, S.
AU  - Kutsenko, A.
JO  - Journal of Computational Physics
VL  - 398
SP  - 108891
PY  - 2019
DA  - 2019/12/01/
SN  - 0021-9991
DO  - https://doi.org/10.1016/j.jcp.2019.108891
UR  - https://www.sciencedirect.com/science/article/pii/S0021999119305893
KW  - Triangular meshes
KW  - Finite volume discretization
KW  - Computational dispersion branches
AB  - Computational wave branches are common to linearized shallow water equations discretized on triangular meshes. It is demonstrated that for standard finite-volume discretizations these branches can be traced back to the structure of the unit cell of triangular lattice, which includes two triangles with a common edge. Only subsets of similarly oriented triangles or edges possess the translational symmetry of unit cell. As a consequence, discrete degrees of freedom placed on triangles or edges are geometrically different, creating an internal structure inside unit cells. It implies a possibility of oscillations inside unit cells seen as computational branches in the framework of linearized shallow water equations, or as grid-scale noise generally. Adding dissipative operators based on smallest stencils to discretized equations is needed to control these oscillations in solutions. A review of several finite-volume discretization is presented with focus on computational branches and dissipative operators.
ER  - 

TY  - JOUR
T1  - Nursing students' perceptions of unfinished nursing care: A cross-sectional study
AU  - Kohanová, Dominika
AU  - Gurková, Elena
AU  - Kirwan, Marcia
AU  - Žiaková, Katarína
AU  - Kurucová, Radka
JO  - Nurse Education in Practice
VL  - 76
SP  - 103942
PY  - 2024
DA  - 2024/03/01/
SN  - 1471-5953
DO  - https://doi.org/10.1016/j.nepr.2024.103942
UR  - https://www.sciencedirect.com/science/article/pii/S1471595324000714
KW  - Clinical placement
KW  - Clinical practice
KW  - Nurse educators
KW  - Nursing
KW  - Nursing students
KW  - Unfinished nursing care
AB  - Aim
To investigate the prevalence, patterns and reasons for unfinished nursing care as perceived by nursing students.
Background
Unfinished nursing care (UNC) is a frequently observed phenomenon in the acute care setting. To date, studies have focused primarily on the perspective of nurses or patients, but another important perspective is that of nursing students who provide nursing care in all healthcare settings.
Design
A descriptive cross-sectional study.
Methods
The study included 738 undergraduate nursing students from nine Slovak universities. Data were collected between September 2022 and February 2023 using the Slovak version of the Unfinished Nursing Care Survey tool (UNCS). Data were analyzed using descriptive and inferential statistics.
Results
The mean composite score of UNCS was 2.48 (SD=0.68). In general, 100% of nursing students reported that nurses missed at least one or more nursing care activities during their last clinical placement. The average number of missed nursing care activities was 11.2 per nurse as perceived by nursing students during their last clinical placement. Nursing students reported that the most frequently omitted nursing care activity was spending time with patients and their caregivers (3.15 ± 1.11; 92.9%). The most frequently reported reason for UNC was an inadequate number of nurses on the ward (4.31 ± 1.01; 98.1%). In the study, reported UNC could be predicted by previous experience in healthcare, previous clinical rotation, number of patients per shift, perceived staff adequacy and outcome expectations (p <0.05).
Conclusions
The findings reveal that UNC is a widespread phenomenon and all nursing students report this phenomenon during their clinical placements. Spending time with patients and their caregivers emerged as the most frequently omitted nursing care activity, highlighting the importance of patient-centered care. The primary reason cited for UNC was an inadequate number of nurses, highlighting staffing issues as a significant contributing factor. These findings emphasize the need for targeted interventions to address staff shortages and improve nursing education to prepare students to address UNC in their future practice.
ER  - 

TY  - JOUR
T1  - In search of experimental evidence on Scratch programming and students’ achievements in the first-year college computing class? Consider these datasets
AU  - Campbell, Oladele O.
AU  - Atagana, Harrison I.
JO  - Data in Brief
VL  - 45
SP  - 108635
PY  - 2022
DA  - 2022/12/01/
SN  - 2352-3409
DO  - https://doi.org/10.1016/j.dib.2022.108635
UR  - https://www.sciencedirect.com/science/article/pii/S2352340922008411
KW  - CS1
KW  - Novice programming
KW  - Constructionism
KW  - Block-based programming
KW  - Experimental data
KW  - Coarsened Exact Matching
KW  - Quasi-experiment
AB  - This article presents datasets representing the demographics and achievements of computer science students in their first programming courses (CS1). They were collected from a research project comparing the effects of a constructionist Scratch programming and the conventional instructions on the achievements of CS1 students from selected Nigerian public colleges. The project consisted of two consecutive quasi-experiments. In both cases, we adopted a non-equivalent pretest-posttest control group design and multistage sampling. Institutions were selected following purposive sampling, and those selected were randomly assigned to the Scratch programming class (experimental) and the conventional (comparison) class. A questionnaire and pre- and post-introductory programming achievement tests were used to collect data. To strengthen the research design, we used the Coarsened Exact Matching (CEM) algorithm to create matched samples from the unmatched data obtained from both experiments. Future studies can use these data to identify the factors influencing CS1 students' performance, investigate how programming pedagogies or tools affect CS1 students' achievements in higher education, identify important trends using machine learning techniques, and address additional research ideas.
ER  - 

TY  - JOUR
T1  - A novel deep neural network based approach for sparse code multiple access
AU  - Lin, Jinzhi
AU  - Feng, Shengzhong
AU  - Zhang, Yun
AU  - Yang, Zhile
AU  - Zhang, Yong
JO  - Neurocomputing
VL  - 382
SP  - 52
EP  - 63
PY  - 2020
DA  - 2020/03/21/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2019.11.066
UR  - https://www.sciencedirect.com/science/article/pii/S0925231219316686
KW  - Sparse code multiple access
KW  - Non-orthogonal multiple access
KW  - Machine learning
KW  - Dense code multiple access
AB  - Sparse code multiple access (SCMA) has been one of the non-orthogonal multiple access (NOMA) schemes aiming to support high spectral efficiency and ubiquitous access requirements for 5G communication networks. Conventional SCMA approaches are confronting challenges in designing low-complexity high-accuracy decoding algorithm and constructing optimum codebooks. Fortunately, the recent spotlighted deep learning technologies are of significant potentials in solving many communication engineering problems. Inspired by this, we propose and train a deep neural network (DNN) called DL-SCMA to learn to decode SCMA modulated signals corrupted by additive white Gaussian noise (AWGN). An autoencoder called AE-SCMA is established and trained to generate optimal SCMA codewords and reconstruct original bits. Furthermore, by manipulating the mapping vectors, an autoencoder is able to generalize SCMA, thus a dense code multiple access (DCMA) scheme is proposed. Simulations show that the DNN SCMA decoder significantly outperforms the conventional message passing algorithm (MPA) in terms of bit error rate (BER), symbol error rate (SER) and computational complexity, and AE-SCMA also demonstrates better performances via constructing better SCMA codebooks. The performance of deep learning aided DCMA is superior to the SCMA.
ER  - 

TY  - JOUR
T1  - Toward Meta-level Control of Autonomous Agents
AU  - Dannenhauer, Dustin
AU  - Cox, Michael T.
AU  - Gupta, Shubham
AU  - Paisner, Matt
AU  - Perlis, Don
JO  - Procedia Computer Science
VL  - 41
SP  - 226
EP  - 232
PY  - 2014
DA  - 2014/01/01/
T2  - 5th Annual International Conference on Biologically Inspired Cognitive Architectures, 2014 BICA
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2014.11.107
UR  - https://www.sciencedirect.com/science/article/pii/S187705091401552X
KW  - Computational metacognition
KW  - cognitive architecture
KW  - metareasoning
KW  - long-duration autonomy
AB  - Metareasoning is an important capability for autonomous systems, particularly for those being deployed on long duration missions. An agent with increased self-observation and the ability to control itself in response to changing environments will be more capable in achieving its goals. This is essential for long-duration missions where system designers will not be able to, theoretically or practically, predict all possible problems that the agent may encounter. In this paper we describe preliminary work that integrates the metacognitive architecture MIDCA with an autonomous TREX agent, creating a more self-observable and adaptive agent.
ER  - 

TY  - JOUR
T1  - Emergence as a computability-theoretic phenomenon
AU  - Cooper, S. Barry
JO  - Applied Mathematics and Computation
VL  - 215
IS  - 4
SP  - 1351
EP  - 1360
PY  - 2009
DA  - 2009/10/15/
T2  - Physics and Computation
SN  - 0096-3003
DO  - https://doi.org/10.1016/j.amc.2009.04.050
UR  - https://www.sciencedirect.com/science/article/pii/S0096300309004159
KW  - Computability
KW  - Emergence
KW  - Definability
KW  - Turing invariance
AB  - In dealing with emergent phenomena, a common task is to identify useful descriptions of them in terms of the underlying atomic processes, and to extract enough computational content from these descriptions to enable predictions to be made. Generally, the underlying atomic processes are quite well understood, and (with important exceptions) captured by mathematics from which it is relatively easy to extract algorithmic content. A widespread view is that the difficulty in describing transitions from algorithmic activity to the emergence associated with chaotic situations is a simple case of complexity outstripping computational resources and human ingenuity. Or, on the other hand, that phenomena transcending the standard Turing model of computation, if they exist, must necessarily lie outside the domain of classical computability theory. In this talk we suggest that much of the current confusion arises from conceptual gaps and the lack of a suitably fundamental model within which to situate emergence. We examine the potential for placing emergent relations in a familiar context based on Turing’s 1939 model for interactive computation over structures described in terms of reals. The explanatory power of this model is explored, formalising informal descriptions in terms of mathematical definability and invariance, and relating a range of basic scientific puzzles to results and intractable problems in computability theory.
ER  - 

TY  - JOUR
T1  - Drinking from the firehose of experience
AU  - Kuipers, Benjamin
JO  - Artificial Intelligence in Medicine
VL  - 44
IS  - 2
SP  - 155
EP  - 170
PY  - 2008
DA  - 2008/10/01/
T2  - Artificial Consciousness
SN  - 0933-3657
DO  - https://doi.org/10.1016/j.artmed.2008.07.010
UR  - https://www.sciencedirect.com/science/article/pii/S0933365708000985
KW  - Consciousness
KW  - Sensory trackers
KW  - Information content
KW  - Dynamical systems
AB  - Summary
Objective
Computational concepts from robotics and computer vision hold great promise to account for major aspects of the phenomenon of consciousness, including philosophically problematical aspects such as the vividness of qualia, the first-person character of conscious experience, and the property of intentionality.
Methods
We present a dynamical systems model describing human or robotic agents and their interaction with the environment. In order to cope with the enormous information content of the sensory stream, this model includes trackers for selected coherent spatio–temporal portions of the sensory input stream, and a self-constructed plausible coherent narrative describing the recent history of the agent’s sensorimotor interaction with the world.
Results
We describe how an agent can autonomously learn its own intentionality by constructing computational models of hypothetical entities in the external world. These models explain regularities in the sensorimotor interaction, and serve as referents for the agent’s symbolic knowledge representation. The high information content of the sensory stream allows the agent to continually evaluate these hypothesized models, refuting those that make poor predictions. The high information content of the sensory input stream also accounts for the vividness and uniqueness of subjective experience. We then evaluate our account against 11 features of consciousness “that any philosophical–scientific theory should hope to explain”, according to the philosopher and prominent AI critic John Searle.
Conclusion
The essential features of consciousness can, in principle, be implemented on a robot with sufficient computational power and a sufficiently rich sensorimotor system, embodied and embedded in its environment.
ER  - 

TY  - CHAP
T1  - Chapter 14 - Beyond artificial intelligence ethics: exploring empathetic ethical outcomes for artificial intelligence
AU  - Cohen, Hart
AU  - Aulbach, Linda
A2  - Caballé, Santi
A2  - Casas-Roma, Joan
A2  - Conesa, Jordi
BT  - Ethics in Online AI-based Systems
PB  - Academic Press
SP  - 279
EP  - 295
PY  - 2024
DA  - 2024/01/01/
T2  - Intelligent Data-Centric Systems
SN  - 978-0-443-18851-0
DO  - https://doi.org/10.1016/B978-0-443-18851-0.00017-2
UR  - https://www.sciencedirect.com/science/article/pii/B9780443188510000172
KW  - Artificial intelligence
KW  - empathy
KW  - emotion
KW  - ethics
KW  - machine learning
AB  - This chapter will focus on the area of human emotion as the field of emotional AI or empathic AI is emerging and creating new possibilities—and ethical issues. Artificial intelligence (AI) has evolved into multiple spheres of everyday life and is quickly proving capable of affecting how we live, work and play in the world—with sometimes severe differences in usage, acceptance, legalities, and ethical practices both between countries and within countries. These discrepancies and ethical debates are only going to become more complex. Intelligence is no longer unique to the human species, therefore challenging the definition of what it means to be human. Our chapter uses three cases studies to illustrate how empathy is germane to intimacy, planetary survival, and recognition. Apart from the need to find the right amount and approach of empathy within AI systems to mitigate detrimental emotional effects on humans, there should also be an approach to bring empathy across all AI technologies, irrespective of having Emotional AI (EAI) as a focal point. In addition, there is reason to believe that adding empathy as an extra layer of ethics into official guidelines is not only necessary but desirable, ensuring that the increase of standardization and generalization in the AI field does not invalidate individuality. A lack of empathy could be considered as unethical in itself, so the ongoing developments in the field of empathy and AI and the link between both is to be welcomed.
ER  - 

TY  - CHAP
T1  - Fundamentals of Trajectory-Based Methods for Nonadiabatic Dynamics
AU  - Akimov, Alexey V.
A2  - Yáñez, Manuel
A2  - Boyd, Russell J.
BT  - Comprehensive Computational Chemistry (First Edition)
PB  - Elsevier
CY  - Oxford
SP  - 235
EP  - 272
PY  - 2024
DA  - 2024/01/01/
SN  - 978-0-12-823256-9
DO  - https://doi.org/10.1016/B978-0-12-821978-2.00034-9
UR  - https://www.sciencedirect.com/science/article/pii/B9780128219782000349
KW  - Coupled trajectories
KW  - Decoherence
KW  - Ehrenfest
KW  - Liouville equation
KW  - Mean-field
KW  - Nonadiabatic dynamics
KW  - Quantum-classical
KW  - Trajectory surface hopping
AB  - In this chapter, I outline the fundamental concepts and frameworks used to construct trajectory-based methods of nonadiabatic dynamics simulations. The chapter is organized according to a common anatomy of multiple trajectory-based approaches rather than as a collection of accounts on existing methods. It highlights the natural evolution of the ideas behind these methods and provides glimpses into a more than 30-years history of such developments. Many reported computational schemes are composed of common methodological “building blocks” – the groups of algorithms tailored to various types of calculations involved in computational algorithms. The chapter overviews a wide variety of possibilities to conduct one or another part of such calculations and that can be regarded the methodological “building blocks”.
ER  - 

TY  - JOUR
T1  - Analysing exposure diversity in collaborative recommender systems—Entropy fusion approach
AU  - Latha, R.
AU  - Nadarajan, R.
JO  - Physica A: Statistical Mechanics and its Applications
VL  - 533
SP  - 122052
PY  - 2019
DA  - 2019/11/01/
SN  - 0378-4371
DO  - https://doi.org/10.1016/j.physa.2019.122052
UR  - https://www.sciencedirect.com/science/article/pii/S0378437119311963
KW  - Clustering
KW  - Quadratic entropy
KW  - Exposure diversity
KW  - Novelty
KW  - Concordance
AB  - Recommender Systems are considered as essential business tools to leverage the potential growth of on-line services. Neighbourhood based collaborative filtering, a successful recommendation approach has mainly focused on improving accuracy of predictions. From user point of view, it is more valuable to obtain novel and diverse recommendations rather than monotonic preferences. Ratings given by a user for different categories of items are considered as a tool to access user exposure diversity which signifies his creative and divergent thinking. On the other hand, pair of items is concordant if highly correlated users agree in rating the items. Based on the user exposure diversity and item concordance, the neighbourhood selection process of item based collaborative recommender systems is refined. Rating predictions are made based on the newly selected neighbours. The performance of the proposed approach is investigated for accuracy and diversity of predictions on Movielens data sets. The results demonstrate that the proposed approach outperforms the state of the art recommendation approaches which address accuracy–diversity trade off. Statistical analysis is done to prove the efficiency of the proposed approach.
ER  - 

TY  - JOUR
T1  - Three-way decision with incomplete information based on similarity and satisfiability
AU  - Luo, Junfang
AU  - Hu, Mengjun
AU  - Qin, Keyun
JO  - International Journal of Approximate Reasoning
VL  - 120
SP  - 151
EP  - 183
PY  - 2020
DA  - 2020/05/01/
SN  - 0888-613X
DO  - https://doi.org/10.1016/j.ijar.2020.02.005
UR  - https://www.sciencedirect.com/science/article/pii/S0888613X19303421
KW  - Three-way decision
KW  - Rough set
KW  - Incomplete information
KW  - Similarity
KW  - Satisfiability
KW  - Fuzzy logic
AB  - Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual formulations. The computational formulation uses equivalence relations, and the conceptual formulation uses satisfiability of logic formulas. In this paper, based on a brief review of these two formulations, we generalize both formulations into three-way decision with incomplete information that is more practical in real-world applications. For the computational formulation, we propose a new measure of similarity degree of objects as a generalization of equivalence relations. Based on it, we discuss two approaches to three-way decision using α-similarity classes and approximability of objects, respectively. For the conceptual formulation, we propose a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability with complete information. Based on it, we study two approaches to three-way decision using α-meaning sets of formulas and confidence of formulas, respectively. While using similarity classes is a common method of analyzing incomplete information in the literature, the proposed concept of approximability and the two approaches in conceptual formulation point out new promising directions.
ER  - 

TY  - JOUR
T1  - Some neural networks compute, others don’t
AU  - Piccinini, Gualtiero
JO  - Neural Networks
VL  - 21
IS  - 2
SP  - 311
EP  - 321
PY  - 2008
DA  - 2008/03/01/
T2  - Advances in Neural Networks Research: IJCNN ’07
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2007.12.010
UR  - https://www.sciencedirect.com/science/article/pii/S089360800700250X
KW  - Connectionism
KW  - Neural network
KW  - Computation
KW  - Mechanism
KW  - Cognition
KW  - Brain
AB  - I address whether neural networks perform computations in the sense of computability theory and computer science. I explicate and defend the following theses. (1) Many neural networks compute—they perform computations. (2) Some neural networks compute in a classical way. Ordinary digital computers, which are very large networks of logic gates, belong in this class of neural networks. (3) Other neural networks compute in a non-classical way. (4) Yet other neural networks do not perform computations. Brains may well fall into this last class.
ER  - 

TY  - CHAP
T1  - Chapter 13 - Turning Specifications into Code
AU  - Celko, Joe
A2  - Celko, Joe
BT  - Joe Celko's Thinking in Sets
PB  - Morgan Kaufmann
CY  - San Francisco
SP  - 255
EP  - 271
PY  - 2008
DA  - 2008/01/01/
T2  - The Morgan Kaufmann Series in Data Management Systems
SN  - 978-0-12-374137-0
DO  - https://doi.org/10.1016/B978-012374137-0.50014-6
UR  - https://www.sciencedirect.com/science/article/pii/B9780123741370500146
AB  - Publisher Summary
This chapter delineates the importance of unlearning the procedural thinking and moves to a pure SQL view. Programmers tend to make the same kinds of errors in their designs and their code over and over. They confuse RDBMS with the file systems and 3GL- or OO-oriented programming environments they first learned. Programmers from the C family of languages tend to put the entire program in lowercase as if they were still using a teletype on a UNIX system. Mainframe programmers tend to put the entire program in uppercase as if they were still using punch cards or a 3270 video monitor for input. Cohesion is how well a module of code does one and only one thing, that it is logically coherent. There are several types of cohesion. The original definitions have been extended from procedural code to include OO and class hierarchies. The symptom in DDL is a table with lots of NULL-able columns. It is probably two or more entities crammed into a single table. The symptom in DML is a query or other statement that tries to do too many things. When the same procedure or query checks inventory and build a personnel report, cohesion problems crop up. The table-valued function shows that the programmer still wants to see procedural coding complete with parameters. An SQL programmer would think in terms of VIEWS and CTES.
ER  - 

TY  - JOUR
T1  - Differentially private data fusion and deep learning Framework for Cyber–Physical–Social Systems: State-of-the-art and perspectives
AU  - Gati, Nicholaus J.
AU  - Yang, Laurence T.
AU  - Feng, Jun
AU  - Nie, Xin
AU  - Ren, Zhian
AU  - Tarus, Samwel K.
JO  - Information Fusion
VL  - 76
SP  - 298
EP  - 314
PY  - 2021
DA  - 2021/12/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2021.04.017
UR  - https://www.sciencedirect.com/science/article/pii/S1566253521000890
KW  - Differential privacy
KW  - Deep computation
KW  - Data fusion
KW  - CPSS
AB  - The modern technological advancement influences the growth of the cyber–physical system and cyber–social system to a more advanced computing system cyber–physical–social system (CPSS). Therefore, CPSS leads the data science revolution by promoting tri-space information resource from a single space. The establishment of CPSSs increases the related privacy concerns. To provide privacy on CPSSs data, various privacy-preserving schemes have been introduced in the recent past. However, technological advancement in CPSSs requires the modifications of previous techniques to suit its dynamics. Meanwhile, differential privacy has emerged as an effective method to safeguard CPSSs data privacy. To completely comprehend the state-of-the-art developments and learn the field’s research directions, this article provides a comprehensive review of differentially private data fusion and deep learning in CPSSs. Additionally, we present a novel differentially private data fusion and deep learning Framework for Cyber–Physical–Social Systems , and various future research directions for CPSSs.
ER  - 

TY  - JOUR
T1  - Exploring crossing times and congestion patterns at scramble intersections in pedestrian dynamics models: A statistical analysis
AU  - Stock, Eduardo V.
AU  - da Silva, Roberto
JO  - Physica A: Statistical Mechanics and its Applications
VL  - 649
SP  - 129942
PY  - 2024
DA  - 2024/09/01/
SN  - 0378-4371
DO  - https://doi.org/10.1016/j.physa.2024.129942
UR  - https://www.sciencedirect.com/science/article/pii/S0378437124004515
KW  - Pedestrian dynamics
KW  - Scramble intersections
KW  - Stochastic process
KW  - Agent-based models
KW  - Complex mixed pedestrian flow
KW  - Monte Carlo simulations
AB  - In this study, we present a model designed to unravel the statistical complexities of pedestrian crossing times and related physical quantities in a unique pedestrian intersection, specifically a double intersecting diagonal crossing. Our model employs an agent-based stochastic process based on a lattice gas dynamics to describe a four-species interaction on an underlying square lattice representing the intersection. This model incorporates four static floor fields guiding each species within the scenario. Our findings emphasize the critical role that the density of highly driven pedestrians plays in the statistics of crossing times by triggering the transition from a normal distribution for low densities to a uniform distribution for a crowded scenario. In the steady state, we mapped the system mobility and showed that an anomalous mobile phase emerges when considering a scenario with high density of poorly driven pedestrians. To monitor these phenomena, we focus on two variables: directed mobility and average distance between agents. We conclude our analysis by overcoming a crucial limitation of the lattice gas model with the introduction of viscosity effects among pedestrians. We observe that mixed state regime emerges as the system presents a mobile-to-immobile phase transition when viscosity effects faints. Our research sheds light on the nuanced dynamics of scramble intersections, contributing to a deeper understanding of urban mobility challenges.
ER  - 

TY  - CHAP
T1  - 8.02 - Molecular Logic Gates as Fluorescent Sensors
AU  - Daly, B.
AU  - Silverson, V.A.D.
AU  - Yao, C.Y.
AU  - Chen, Z.Q.
AU  - de Silva, A.P.
A2  - Atwood, Jerry L.
BT  - Comprehensive Supramolecular Chemistry II
PB  - Elsevier
CY  - Oxford
SP  - 3
EP  - 19
PY  - 2017
DA  - 2017/01/01/
SN  - 978-0-12-803199-5
DO  - https://doi.org/10.1016/B978-0-12-409547-2.12626-5
UR  - https://www.sciencedirect.com/science/article/pii/B9780124095472126265
KW  - AND Logic
KW  - Fluorescent Sensors
KW  - IMPLICATION Logic
KW  - INHIBIT Logic
KW  - Intracellular AND Logic
KW  - Logic Gates
KW  - NAND Logic
KW  - XOR and XNOR Logic
KW  - YES Logic
AB  - Some recent developments in the use of molecular logic gates as fluorescent sensors are described. The discussion is classified in terms of the Boolean logical assignment of the sensor system. Even simple fluorescent sensors can be recognized as single-input logic gates. Several YES gates launch the analysis of examples. A consideration of various sensors driven by double inputs and higher multiple inputs then follows. Attention is particularly drawn to the appearance of double-input logical sensor molecules, which successfully operate within living cells—a milieu where conventional semiconductor-based logic devices would struggle on the grounds of compatibility and size. The value of molecular logical thinking in the understanding of fluorescent sensor behavior is emphasized throughout.
ER  - 

TY  - JOUR
T1  - When rules are over-ruled: Virtual bargaining as a contractualist method of moral judgment
AU  - Levine, Sydney
AU  - Kleiman-Weiner, Max
AU  - Chater, Nick
AU  - Cushman, Fiery
AU  - Tenenbaum, Joshua B.
JO  - Cognition
VL  - 250
SP  - 105790
PY  - 2024
DA  - 2024/09/01/
SN  - 0010-0277
DO  - https://doi.org/10.1016/j.cognition.2024.105790
UR  - https://www.sciencedirect.com/science/article/pii/S0010027724000763
KW  - Moral judgment
KW  - Contractualism
KW  - Virtual bargaining
AB  - Rules help guide our behavior—particularly in complex social contexts. But rules sometimes give us the “wrong” answer. How do we know when it is okay to break the rules? In this paper, we argue that we sometimes use contractualist (agreement-based) mechanisms to determine when a rule can be broken. Our model draws on a theory of social interactions – “virtual bargaining” – that assumes that actors engage in a simulated bargaining process when navigating the social world. We present experimental data which suggests that rule-breaking decisions are sometimes driven by virtual bargaining and show that these data cannot be explained by more traditional rule-based or outcome-based approaches.
ER  - 

TY  - JOUR
T1  - Solving Immunology?
AU  - Vodovotz, Yoram
AU  - Xia, Ashley
AU  - Read, Elizabeth L.
AU  - Bassaganya-Riera, Josep
AU  - Hafler, David A.
AU  - Sontag, Eduardo
AU  - Wang, Jin
AU  - Tsang, John S.
AU  - Day, Judy D.
AU  - Kleinstein, Steven H.
AU  - Butte, Atul J.
AU  - Altman, Matthew C.
AU  - Hammond, Ross
AU  - Sealfon, Stuart C.
JO  - Trends in Immunology
VL  - 38
IS  - 2
SP  - 116
EP  - 127
PY  - 2017
DA  - 2017/02/01/
SN  - 1471-4906
DO  - https://doi.org/10.1016/j.it.2016.11.006
UR  - https://www.sciencedirect.com/science/article/pii/S1471490616302022
KW  - mathematical modeling
KW  - conference
KW  - autoimmune disease
KW  - personalized medicine
KW  - translation
AB  - Emergent responses of the immune system result from the integration of molecular and cellular networks over time and across multiple organs. High-content and high-throughput analysis technologies, concomitantly with data-driven and mechanistic modeling, hold promise for the systematic interrogation of these complex pathways. However, connecting genetic variation and molecular mechanisms to individual phenotypes and health outcomes has proven elusive. Gaps remain in data, and disagreements persist about the value of mechanistic modeling for immunology. Here, we present the perspectives that emerged from the National Institute of Allergy and Infectious Disease (NIAID) workshop ‘Complex Systems Science, Modeling and Immunity’ and subsequent discussions regarding the potential synergy of high-throughput data acquisition, data-driven modeling, and mechanistic modeling to define new mechanisms of immunological disease and to accelerate the translation of these insights into therapies.
ER  - 

TY  - JOUR
T1  - Transformations between rotational and translational invariants formulated in reciprocal spaces
AU  - Baldwin, Philip R.
JO  - Journal of Structural Biology: X
VL  - 7
SP  - 100089
PY  - 2023
DA  - 2023/01/01/
SN  - 2590-1524
DO  - https://doi.org/10.1016/j.yjsbx.2023.100089
UR  - https://www.sciencedirect.com/science/article/pii/S2590152423000053
KW  - Bispectrum
KW  - Wilson statistics
KW  - Shape analysis
AB  - Correlation functions play an important role in the theoretical underpinnings of many disparate areas of the physical sciences: in particular, scattering theory. More recently, they have become useful in the classification of objects in areas such as computer vision and our area of cryoEM. Our primary classification scheme in the cryoEM image processing system, EMAN2, is now based on third order invariants formulated in Fourier space. This allows a factor of 8 speed up in the two classification procedures inherent in our software pipeline, because it allows for classification without the need for computationally costly alignment procedures. In this work, we address several formal and practical aspects of such multispectral invariants. We show that we can formulate such invariants in the representation in which the original signal is most compact. We explicitly construct transformations between invariants in different orientations for arbitrary order of correlation functions and dimension. We demonstrate that third order invariants distinguish 2D mirrored patterns (unlike the radial power spectrum), which is a fundamental aspects of its classification efficacy. We show the limitations of 3rd order invariants also, by giving an example of a wide family of patterns with identical (vanishing) set of 3rd order invariants. For sufficiently rich patterns, the third order invariants should distinguish typical images, textures and patterns.
ER  - 

TY  - CHAP
T1  - Cognitive Modeling: Connectionist Approaches
AU  - MacLennan, Bruce
A2  - Wright, James D.
BT  - International Encyclopedia of the Social & Behavioral Sciences (Second Edition)
PB  - Elsevier
CY  - Oxford
SP  - 84
EP  - 89
PY  - 2015
DA  - 2015/01/01/
SN  - 978-0-08-097087-5
DO  - https://doi.org/10.1016/B978-0-08-097086-8.43021-7
UR  - https://www.sciencedirect.com/science/article/pii/B9780080970868430217
KW  - Artificial intelligence
KW  - Backpropagation
KW  - Computability
KW  - Computational map
KW  - Connectionism
KW  - Correlational learning
KW  - Dynamic systems approach
KW  - Embodiment
KW  - Language of thought
KW  - Machine learning
KW  - Neural network
KW  - Perceptron
KW  - Representation
KW  - Situatedness
KW  - Subsymbolic
AB  - Connectionist approaches to cognitive modeling make use of large networks of simple computational units, which communicate by means of simple quantitative signals. Higher-level information processing emerges from the massively parallel interaction of these units by means of their connections, and a network may adapt its behavior by means of local changes in the strength of the connections. Connectionist approaches are related to neural networks and provide a distinct alternative to cognitive models inspired by the digital computer.
ER  - 

TY  - JOUR
T1  - Intelligent e-learning system in the development of preschool music education based on digital audio technology
AU  - Xu, Yajun
JO  - Entertainment Computing
VL  - 50
SP  - 100682
PY  - 2024
DA  - 2024/05/01/
SN  - 1875-9521
DO  - https://doi.org/10.1016/j.entcom.2024.100682
UR  - https://www.sciencedirect.com/science/article/pii/S1875952124000508
KW  - Digital audio technology
KW  - Intelligent voice
KW  - Entertainment robots
KW  - Preschool education
KW  - Music education
KW  - Development mode
AB  - In the current rapidly developing digital era, intelligent learning has become an important trend in preschool music education, and intelligent voice entertainment robots have become an emerging educational tool. This study aims to provide an intelligent preschool music education model by using digital audio technology to promote children's learning and music perception ability. The study explores the current challenges facing preschool music education, adopts an intelligent preschool music education model based on digital audio technology, utilizes advanced audio processing technology, converts music resources into digital audio formats, and builds an audio library. Through the use of intelligent learning system, according to the individual characteristics and learning needs of children, to provide them with personalized learning materials and learning paths. Finally, based on machine learning algorithms, music education content and interactive functions are integrated into the robot to provide a personalized learning experience. The results show that the study found that intelligent voice entertainment robots can effectively assist students in learning music knowledge and skills, improve learning motivation and interest, and promote interaction with robots.
ER  - 

TY  - JOUR
T1  - Utilizing sensor data to model students’ creativity in a digital environment
AU  - Muldner, Kasia
AU  - Burleson, Winslow
JO  - Computers in Human Behavior
VL  - 42
SP  - 127
EP  - 137
PY  - 2015
DA  - 2015/01/01/
T2  - Digital Creativity: New Frontier for Research and Practice
SN  - 0747-5632
DO  - https://doi.org/10.1016/j.chb.2013.10.060
UR  - https://www.sciencedirect.com/science/article/pii/S074756321300410X
KW  - Creativity
KW  - Student modeling
KW  - Eye tracking
KW  - EEG
KW  - Skin conductance
KW  - Intelligent Tutoring Systems
AB  - While creativity is essential for developing students’ broad expertise in Science, Technology, Engineering, and Math (STEM) fields, many students struggle with various aspects of being creative. Digital technologies have the unique opportunity to support the creative process by (1) recognizing elements of students’ creativity, such as when creativity is lacking (modeling step), and (2) providing tailored scaffolding based on that information (intervention step). However, to date little work exists on either of these aspects. Here, we focus on the modeling step. Specifically, we explore the utility of various sensing devices, including an eye tracker, a skin conductance bracelet, and an EEG sensor, for modeling creativity during an educational activity, namely geometry proof generation. We found reliable differences in sensor features characterizing low vs. high creativity students. We then applied machine learning to build classifiers that achieved good accuracy in distinguishing these two student groups, providing evidence that sensor features are valuable for modeling creativity.
ER  - 

TY  - JOUR
T1  - AI-assisted Optimal Energy Conversion for Cost-Effective and Sustainable Power Production from Biomass-Fueled SOFC Equipped with Hydrogen Production/Injection
AU  - Khosravi, Mohammadreza
AU  - Mousavi, Shadi Bashiri
AU  - Ahmadi, Pouria
AU  - Behzadi, Amirmohammad
AU  - Sadrizadeh, Sasan
JO  - Process Safety and Environmental Protection
PY  - 2024
DA  - 2024/08/13/
SN  - 0957-5820
DO  - https://doi.org/10.1016/j.psep.2024.08.045
UR  - https://www.sciencedirect.com/science/article/pii/S0957582024010176
KW  - Biomass
KW  - Solid oxide fuel cell
KW  - vanadium chlorine
KW  - super-critical CO cycle
KW  - multi-objective optimization
AB  - This study introduces a novel energy conversion and management framework to reduce carbon emissions in the energy sector and expedite the global shift towards sustainable practices. The system is driven by biomass-based solid oxide fuel cells for efficient power generation. Central to this approach lies the integration of additional hydrogen injection provided by a thermally-driven vanadium chloride cycle, aiming to enhance the quality of the syngas entering the fuel cells. The system is also combined with a super-critical CO2 cycle that generates power by passively enhancing performance through flue gas condensation. The proposed model's feasibility is evaluated in depth, techno-economically, considering thermodynamics and specific cost theories. As part of artificial intelligence, a neural network model is coupled with the genetic algorithm to determine the best operating status while minimizing computation time. According to the results, the suggested new integration results in higher efficiency and lower cost than a similar system without hydrogen injection. The results further show that the triple-objective optimization achieves output power, second-law efficiency, and overall system cost of 3425kW, 48.5%, and 2.3M$/year, respectively. Eventually, the gasifier is the main contributor to the highest level of exergy destruction, and fuel utilization and current density are the most important parameters in modeling.
ER  - 

TY  - JOUR
T1  - Graph signatures: Identification and optimization
AU  - Balasundaram, Balabhaskar
AU  - Borrero, Juan S.
AU  - Pan, Hao
JO  - European Journal of Operational Research
VL  - 296
IS  - 3
SP  - 764
EP  - 775
PY  - 2022
DA  - 2022/02/01/
SN  - 0377-2217
DO  - https://doi.org/10.1016/j.ejor.2021.03.051
UR  - https://www.sciencedirect.com/science/article/pii/S0377221721002770
KW  - Networks
KW  - Relational
KW  - Temporal
KW  - Cross-graph mining
KW  - Frequent subgraph mining
AB  - We introduce a new graph-theoretic paradigm called a graph signature that describes persistent patterns in a sequence of graphs. This framework is motivated by the need to detect subgraphs of significance in temporal networks, e.g., social and biological networks that evolve over time. Because the subgraphs of interest may not all “look alike” in the snapshots of the temporal network, the framework deems a subgraph to be persistent if it satisfies one of several preselected properties in each snapshot of a consecutive subsequence. The persistency requirement is parameterized by the length of this subsequence. This discrete mathematical framework can be viewed more broadly as a way to generalize classical graph properties and invariants associated with a single graph to a sequence of graphs. In this introductory article, we formulate the graph signature identification problem as a mixed-integer program and propose an algorithmic framework based on dynamic programming. This methodology is applicable to any collection of mixed-integer representable graph properties. We also demonstrate how this framework can be tailored to exploit property-specific decomposition and scale reduction techniques through three different computational case-studies. Our experiments show that the dynamic programming algorithm solves this problem across most instances in our test bed to optimality. Moreover, for the instances in our test bed, the optimal signature sizes are comparable to those of their static counterparts, suggesting that our new framework can identify subgraphs of significance in complex dynamic networks.
ER  - 

TY  - JOUR
T1  - Statistical prediction of waterflooding performance by K-means clustering and empirical modeling
AU  - Liao, Qin-Zhuo
AU  - Xue, Liang
AU  - Lei, Gang
AU  - Liu, Xu
AU  - Sun, Shu-Yu
AU  - Patil, Shirish
JO  - Petroleum Science
VL  - 19
IS  - 3
SP  - 1139
EP  - 1152
PY  - 2022
DA  - 2022/06/01/
SN  - 1995-8226
DO  - https://doi.org/10.1016/j.petsci.2021.12.032
UR  - https://www.sciencedirect.com/science/article/pii/S1995822622000097
KW  - Waterflooding
KW  - Statistical prediction
KW  - K-means clustering
KW  - Empirical modeling
KW  - Uncertainty quantification
AB  - Statistical prediction is often required in reservoir simulation to quantify production uncertainty or assess potential risks. Most existing uncertainty quantification procedures aim to decompose the input random field to independent random variables, and may suffer from the curse of dimensionality if the correlation scale is small compared to the domain size. In this work, we develop and test a new approach, K-means clustering assisted empirical modeling, for efficiently estimating waterflooding performance for multiple geological realizations. This method performs single-phase flow simulations in a large number of realizations, and uses K-means clustering to select only a few representatives, on which the two-phase flow simulations are implemented. The empirical models are then adopted to describe the relation between the single-phase solutions and the two-phase solutions using these representatives. Finally, the two-phase solutions in all realizations can be predicted using the empirical models readily. The method is applied to both 2D and 3D synthetic models and is shown to perform well in the P10, P50 and P90 of production rates, as well as the probability distributions as illustrated by cumulative density functions. It is able to capture the ensemble statistics of the Monte Carlo simulation results with a large number of realizations, and the computational cost is significantly reduced.
ER  - 

TY  - JOUR
T1  - Mapping geometric and electromagnetic feature spaces with machine learning for additively manufactured RF devices
AU  - Sessions, Deanna
AU  - Meenakshisundaram, Venkatesh
AU  - Gillman, Andrew
AU  - Cook, Alexander
AU  - Fuchi, Kazuko
AU  - Buskohl, Philip R.
AU  - Huff, Gregory H.
JO  - Additive Manufacturing
VL  - 50
SP  - 102549
PY  - 2022
DA  - 2022/02/01/
SN  - 2214-8604
DO  - https://doi.org/10.1016/j.addma.2021.102549
UR  - https://www.sciencedirect.com/science/article/pii/S2214860421006965
KW  - Additive manufacturing
KW  - Direct-ink write
KW  - Electromagnetics
KW  - Machine learning
KW  - Radio frequency
AB  - Multi-material additive manufacturing enables transformative capabilities in customized, low-cost, and multi-functional electromagnetic devices. However, process-specific fabrication anomalies can result in non-intuitive effects on performance; we propose a framework for identifying defect mechanisms and their performance impact by mapping geometric variances to electromagnetic performance metrics. This method can accelerate additive fabrication feedback while avoiding the high computational cost of in-line electromagnetic simulation. We first used dimension reduction to explore the population of geometric manufacturing anomalies and electromagnetic performance. Convolutional neural networks are then trained to predict the electromagnetic performance of the printed geometries. In generating the networks, we explored two inputs: one image-derived geometric description and one using the same description with additional simulated electromagnetic information. Network latent space analysis shows the networks learned both geometric and electromagnetic values even without electromagnetic input. This result demonstrates it is possible to create accelerated additive feedback systems predicting electromagnetic performance without in-line simulation.
ER  - 

TY  - CHAP
T1  - Chapter 2 - The System Perspective on Human Factors in Aviation
AU  - Sheridan, Thomas B.
A2  - Salas, Eduardo
A2  - Maurino, Dan
BT  - Human Factors in Aviation (Second Edition)
PB  - Academic Press
CY  - San Diego
SP  - 23
EP  - 63
PY  - 2010
DA  - 2010/01/01/
SN  - 978-0-12-374518-7
DO  - https://doi.org/10.1016/B978-0-12-374518-7.00002-X
UR  - https://www.sciencedirect.com/science/article/pii/B978012374518700002X
AB  - Publisher Summary
This chapter reviews the system perspective in terms of its origins and fundamental quantitative ideas. An appreciation of these basic concepts adds rigor to analysis and synthesis of human-machine systems, and in particular to such systems in aviation. The chapter represents an effort to remind the reader of the meaning of “system,” where it comes from, and what it implies for research, design, construction, operation, and evaluation in aviation, especially with regard to the human role in aviation. Human factors professionals, pilots, and operational personnel in air traffic management and related practitioners who know about “systems” only as a general and often vague term for something complex can benefit from knowing a bit of the history, the people, and the quantitative substance that underlies the terminology. The chapter begins by defining what is meant by a system, then discusses the history of the idea, the major contributors and what they contributed, and what made the systems idea different from previous ideas in technology. It goes on to give examples of systems thinking applied to design, development, and manufacturing of aviation systems in consideration of the people involved. Salient system models such as control, decision, information, and reliability are then explicated.
ER  - 

TY  - JOUR
T1  - Experimental and numerical methods to ensure comprehensible and replicable alternating current electrical stimulation experiments
AU  - Zimmermann, Julius
AU  - Sahm, Franziska
AU  - Arbeiter, Nils
AU  - Bathel, Henning
AU  - Song, Zezhong
AU  - Bader, Rainer
AU  - Jonitz-Heincke, Anika
AU  - van Rienen, Ursula
JO  - Bioelectrochemistry
VL  - 151
SP  - 108395
PY  - 2023
DA  - 2023/06/01/
SN  - 1567-5394
DO  - https://doi.org/10.1016/j.bioelechem.2023.108395
UR  - https://www.sciencedirect.com/science/article/pii/S1567539423000324
KW  - Electrical stimulation
KW  - Computational modelling
KW  - Computational electromagnetics
KW  - Electrochemical impedance spectroscopy
KW  - Regenerative medicine
KW  - Replicability
AB  - Electrical stimulation has received increasing attention for decades for its application in regenerative medicine. Applications range from bone growth stimulation over cartilage regeneration to deep brain stimulation. Despite all research efforts, translation into clinical use has not yet been achieved in all fields. Recent critical assessments have identified limited documentation and monitoring of preclinical in vitro and in vivo experiments as possible reasons hampering clinical translation. In this work, we present experimental and numerical methods to determine the crucial quantities of electrical stimulation such as the electric field or current density. Knowing the stimulation quantities contributes to comprehending the biological response to electrical stimulation and to finally developing a reliable dose–response curve. To demonstrate the methods, we consider a direct contact electrical stimulation experiment that stands representative for a broad class of stimulation experiments. Electrochemical effects are addressed and methods to integrate them into numerical simulations are evaluated. A focus is laid on affordable lab equipment and reproducible open-source software solutions. Finally, clear guidelines to ensure replicability of electrical stimulation experiments are formulated.
ER  - 

TY  - JOUR
T1  - Systemic modeling strategies in public policy: an appraisal from literature
AU  - Billi, Marco
AU  - Allendes, Angel
AU  - Jiliberto, Rodrigo
AU  - Ramos-Jiliberto, Rodrigo
AU  - Salinas, Bárbara
AU  - Urquiza, Anahí
JO  - Environmental Science & Policy
VL  - 153
SP  - 103668
PY  - 2024
DA  - 2024/03/01/
SN  - 1462-9011
DO  - https://doi.org/10.1016/j.envsci.2024.103668
UR  - https://www.sciencedirect.com/science/article/pii/S1462901124000029
KW  - System
KW  - System modeling
KW  - Public policy
KW  - Modeling strategies
KW  - Modeling public policy
AB  - Contemporary society has grown increasingly dependent on the integration of knowledge for decision-making. In this context, systemic modeling is acknowledged as a straightforward tool for representing and analyzing complex problems. To address how systemic modeling is being conducted to guide and support public policy-making, this study offers a brief synthesis of the literature on systemic modeling oriented to help public policy decision-making. The results are compared to three principles for good systemic modeling to support public policy, established by the authors: the model must a) be readable and manageable —to a basic level— by non-experts, b) require as little quantitative data as possible, and c) not generate spurious or ambiguous readings of their content or their outputs. To identify modeling patterns the models were subjected to a content analysis under eleven different categories. To depict the possible co-occurrence of these analyzed categories in order to describe different types of modeling, a multiple correspondence analysis was performed. We found different modeling patterns with a marked trend to use system modeling as a performative device to let emerging cognitively a new entity, the structure of a complex problem. Regarding our proposal for modeling public policy problems, it can be said that the modeling strategies that fit better with the proposed principles are those that were identified as qualitative and oriented to public policy.
ER  - 

TY  - CHAP
T1  - Chapter 15 - Parallel Machine Learning and Deep Learning Approaches for Bioinformatics
AU  - Madiajagan, M.
AU  - Raj, S. Sridhar
A2  - Sangaiah, Arun Kumar
BT  - Deep Learning and Parallel Computing Environment for Bioengineering Systems
PB  - Academic Press
SP  - 245
EP  - 255
PY  - 2019
DA  - 2019/01/01/
SN  - 978-0-12-816718-2
DO  - https://doi.org/10.1016/B978-0-12-816718-2.00022-1
UR  - https://www.sciencedirect.com/science/article/pii/B9780128167182000221
KW  - Machine learning
KW  - Deep Learning
KW  - Parallel processing
KW  - Bioinformatics
KW  - Parallel deep neural networks
AB  - Deep learning uses multiple layers of artificial neurons for classification and pattern recognition. The biggest drawbacks of deep learning algorithms have been the high computation cost, inter-processor communication bottlenecks and parameters training time. Hence, incorporating parallel computing into deep learning decreases the computation time of complex deep learning algorithms. This chapter presents how parallelization is applied over many processors which are loosely coupled. Up to 4096 processes are scaled linearly with higher accuracy and zero loss percentage. This capacity of huge scaling helps in training billions of training examples in just a few hours. Various applications of Hessian-free parallelization mechanism on bioinformatics applications are in gene therapy, drug development, antibiotic resistance research, waste cleanup, climate change studies, bioweapon creation, improving nutritional quality and veterinary science.
ER  - 

TY  - JOUR
T1  - Protein-Protein Docking: From Interaction to Interactome
AU  - Vakser, Ilya A.
JO  - Biophysical Journal
VL  - 107
IS  - 8
SP  - 1785
EP  - 1793
PY  - 2014
DA  - 2014/10/21/
SN  - 0006-3495
DO  - https://doi.org/10.1016/j.bpj.2014.08.033
UR  - https://www.sciencedirect.com/science/article/pii/S0006349514009382
AB  - The protein-protein docking problem is one of the focal points of activity in computational biophysics and structural biology. The three-dimensional structure of a protein-protein complex, generally, is more difficult to determine experimentally than the structure of an individual protein. Adequate computational techniques to model protein interactions are important because of the growing number of known protein structures, particularly in the context of structural genomics. Docking offers tools for fundamental studies of protein interactions and provides a structural basis for drug design. Protein-protein docking is the prediction of the structure of the complex, given the structures of the individual proteins. In the heart of the docking methodology is the notion of steric and physicochemical complementarity at the protein-protein interface. Originally, mostly high-resolution, experimentally determined (primarily by x-ray crystallography) protein structures were considered for docking. However, more recently, the focus has been shifting toward lower-resolution modeled structures. Docking approaches have to deal with the conformational changes between unbound and bound structures, as well as the inaccuracies of the interacting modeled structures, often in a high-throughput mode needed for modeling of large networks of protein interactions. The growing number of docking developers is engaged in the community-wide assessments of predictive methodologies. The development of more powerful and adequate docking approaches is facilitated by rapidly expanding information and data resources, growing computational capabilities, and a deeper understanding of the fundamental principles of protein interactions.
ER  - 

TY  - JOUR
T1  - Guided decisions processes
AU  - Baucells, Manel
AU  - Sarin, Rakesh K.
JO  - EURO Journal on Decision Processes
VL  - 1
IS  - 1
SP  - 29
EP  - 44
PY  - 2013
DA  - 2013/06/01/
SN  - 2193-9438
DO  - https://doi.org/10.1007/s40070-013-0003-8
UR  - https://www.sciencedirect.com/science/article/pii/S2193943821000108
KW  - Decision analysis
KW  - Behavioral decision making
KW  - Narrow bracket
KW  - Insurance
KW  - Multi-attribute decisions
AB  - The heuristics and bias research program has convincingly demonstrated that our judgments and choices are prone to systematic errors. Decision analysis requires coherent judgments about beliefs (probabilities) and tastes (utilities), and a rational procedure to combine them so that choices maximize subjective expected utility. A guided decision process is a middle-of-the-road between decision analysis and intuitive judgments in which the emphasis is on improving decisions through simple decision rules. These rules reduce cost of thinking, or decision effort, for the myriad decisions that one faces in daily life; but at the same time, they are personalized to the individual and produce near optimal choices. We discuss the principles behind the guided decision processes research program, and illustrate the approach using several examples.
ER  - 

TY  - JOUR
T1  - Common errors in reasoning about the future: Three informal fallacies
AU  - Dorr, Adam
JO  - Technological Forecasting and Social Change
VL  - 116
SP  - 322
EP  - 330
PY  - 2017
DA  - 2017/03/01/
SN  - 0040-1625
DO  - https://doi.org/10.1016/j.techfore.2016.06.018
UR  - https://www.sciencedirect.com/science/article/pii/S0040162516301275
KW  - Technological progress
KW  - Accelerating change
KW  - Computing
KW  - Fallacy
KW  - Errors in reasoning
AB  - The continued exponential growth of the price-performance of computing is likely to effectuate technologies that radically transform both the global economy and the human condition over the course of this century. Conventional visions of the next 50years fail to realistically account for the full implications of accelerating technological change driven by the exponential growth of computing, and as a result are deeply flawed. These flawed visions are, in part, a consequence of three interrelated errors in reasoning: 1) the linear projection fallacy, 2) the ceteris paribus fallacy, and 3) the arrival fallacy. Each of these informal fallacies is likely a manifestation of shortcomings in our intuitions about complex dynamic systems. Recognizing these errors and identifying when and where they affect our own reasoning is an important first step toward thinking more realistically about the future.
ER  - 

TY  - JOUR
T1  - Incorporación de la programación informática en el currículum de Biología
AU  - Carvajal-Rodríguez, Antonio
JO  - Magister
VL  - 27
IS  - 2
SP  - 76
EP  - 82
PY  - 2015
DA  - 2015/07/01/
SN  - 0212-6796
DO  - https://doi.org/10.1016/j.magis.2015.12.002
UR  - https://www.sciencedirect.com/science/article/pii/S0212679615000286
KW  - Docencia
KW  - Bioinformática
KW  - Biología computacional
KW  - Python
KW  - Teaching
KW  - Bioinformatics
KW  - Computational biology
KW  - Python
AB  - Resumen
La investigación en biología ha cambiado radicalmente debido al efecto combinado de los avances en biotecnología y ciencias de la computación. En consecuencia, la biología computacional y la bioinformática son tan esenciales para la biología del siglo xxi como la biología molecular lo fue en el anterior. Sin embargo, las competencias correspondientes a razonamiento matemático y computacional en el currículo de Biología apenas han cambiado en los últimos 25 años. La formación del biólogo debería ser tan sofisticada desde el punto de vista computacional como la del físico o la del ingeniero. La incorporación de estos cambios requiere tanto de un mayor esfuerzo de integración de las asignaturas cuantitativas existentes en el ámbito de los problemas biológicos como de la contextualización de las asignaturas propias de la biología desde un punto de vista más formal y de modelización. En este trabajo se revisan algunos de los esfuerzos que en este sentido se están haciendo en el panorama internacional y se presenta también la experiencia del autor en el diseño e impartición de un curso de iniciación a la programación para biólogos usando una metodología de aprendizaje basado en problemas.
The joint effect of biotechnology and computing has changed the research in biology. Consequently, computational biology is as essential for 21st-century biologists as molecular biology was in the 20th. However, Biology curricula have little emphasis in quantitative thinking and computation. The education for biologists should become as sophisticated as the computational education of physicists and engineers. The necessary changes to reach this goal require the connection of mathematics and quantitative subjects with real biological problems and at the same time, teaching some biological subjects from a modeling and computational perspective. In the present work, some of the current international effort in this path is reviewed and additionally, the author's experience when teaching an introduction to programming for biologists is presented.
ER  - 

TY  - JOUR
T1  - MetaIBM: A Python-based library for individual-based modelling of eco-evolutionary dynamics in spatial-explicit metacommunities
AU  - Lin, Jian-Hao
AU  - Quan, Yu-Juan
AU  - Han, Bo-Ping
JO  - Ecological Modelling
VL  - 492
SP  - 110730
PY  - 2024
DA  - 2024/06/01/
SN  - 0304-3800
DO  - https://doi.org/10.1016/j.ecolmodel.2024.110730
UR  - https://www.sciencedirect.com/science/article/pii/S0304380024001182
KW  - Community assembly
KW  - Eco-evolutionary processes
KW  - Individual-based model
KW  - Landscape network
KW  - Metacommunity
KW  - Python library
AB  - Individual-based modelling (IBM) is a powerful tool for simulating complex biological communities. By defining a population as comprising individuals that differ from one another, IBM can simulate the assembly and organisation of complex communities under various eco-evolutionary processes in a large spatial scale, with tremendous variables or parameters considered simultaneously. IBM disentangles a complex system into various sub-systems interacting with each other, allowing us to develop a unified library with a modular design for a wide range of complex scenarios in community assembly. In such a library, a number of parameters-controlled processes can be primitively coded as the sub-systems (or sub-models). Here, we released a Python-coded library as a framework for Metacommunity Individual-based Modelling (MetaIBM). As an open-source library, the MetaIBM has several merits, including: (a) it can be used to simulate a wide range of ecological problems of metacommunities. The metacommunity landscape and its environment gradients can be designed flexibly by users. Users can selectively turn off or on and set up parameters-controlled ecological processes according to their needs. (b) It adopts optimised algorithms and adapts to the high-performance computing devices, so that the users can explore a wide range of parameters space synchronously within a reasonable time. (c) It can be used to simulate a group of communities with up to millions of unique individuals, which is an originally plain portrayal of natural communities. To guide potential users, we provided the source codes of the library and a user manual. In the present article, we gave four examples to demonstrate how to design and model a metacommunity using the MetaIBM, simulating the community assembly in an islands-mainland model under the metacommunity framework with (a) neutral assumptions, (b) niche assumptions, (c) slow evolution scenarios, (d) rapid evolution scenarios. The examples showed that the MetaIBM can efficiently fit the community assembly, and reveal several intrigued species diversity patterns under the interaction of evolutionary processes and dispersal processes at multiple scales. The MetaIBM will be continuously maintained and updated to provide more functions in the future.
ER  - 

TY  - JOUR
T1  - Capital markets research in accounting: Lessons learnt and future implications
AU  - Karuna, Christo
JO  - Pacific-Basin Finance Journal
VL  - 55
SP  - 161
EP  - 168
PY  - 2019
DA  - 2019/06/01/
SN  - 0927-538X
DO  - https://doi.org/10.1016/j.pacfin.2019.03.001
UR  - https://www.sciencedirect.com/science/article/pii/S0927538X19301398
AB  - I review the capital markets literature in accounting by describing the journey taken by researchers since the inception of this stream of research in the late 1960s. Based on a discussion of topics related to the relation between earnings and stock returns, I show how thinking has evolved depending on changing paradigms, methodologies, and data availability. What is clear from a review of the literature is that the usefulness of earnings in determining firm value is both contextual and broadening over time with changes in the global environment. Thus, more research needs to be conducted on a broader notion of earnings that appeals to not just the shareholder but a wide range of firm stakeholders.
ER  - 

TY  - JOUR
T1  - A bio-inspired model of behavior considering decision-making and planning, spatial attention and basic motor commands processes
AU  - Ramirez-Pedraza, Raymundo
AU  - Vargas, Natividad
AU  - Sandoval, Carlos
AU  - del Valle-Padilla, Juan Luis
AU  - Ramos, Félix
JO  - Cognitive Systems Research
VL  - 59
SP  - 293
EP  - 303
PY  - 2020
DA  - 2020/01/01/
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2019.10.006
UR  - https://www.sciencedirect.com/science/article/pii/S138904171930508X
KW  - Brain model
KW  - Decision-making
KW  - Planning
KW  - Spatial attention
KW  - Motor system
KW  - Goal-driven
AB  - Cognitive architectures (CA) are an IA approach to implement computer systems with human-like behavior. Fundamental exhibited human capabilities include planning and decision-making. In that regard, numerous AI systems successfully exhibit human-like behavior but are limited to either achieving specific objectives or are restrained to too heavily constrained environments, which makes them unsuitable in the presence of unforeseen situations where autonomy is required. To try to alleviate the problem, we present a bio-inspired computational model to solve the autonomous navigation problem of a computational entity in a controlled context. This proposal is the result of the interaction between planning and decision-making, spatial attention and the motor cognitive functions. The proposed model is based on neuroscientific evidence concerning the involved cognitive functions and is part of a more general cognitive architecture. In the case study developed to validate our idea, we can see that the processes previously identified play an important role to accomplish spatial navigation. In the case study presented, an agent achieves the navigation over an unexplored maze from an initial to a final position successfully. The reunited results motivate us to continue improving our model considering attentional information to influence the agent’s motor behavior.
ER  - 

TY  - CHAP
T1  - Chapter 4 A Cognitive Approach to Context Effects on Individual Decision Making under Risk
AU  - Kokinov, Boicho
AU  - Raeva, Daniela
A2  - Topol, Richard
A2  - Walliser, Bernard
BT  - Contributions to Economic Analysis
PB  - Elsevier
VL  - 280
SP  - 99
EP  - 116
PY  - 2006
DA  - 2006/01/01/
T2  - Cognitive Economics
SN  - 0573-8555
DO  - https://doi.org/10.1016/S0573-8555(06)80005-2
UR  - https://www.sciencedirect.com/science/article/pii/S0573855506800052
KW  - choice under risk
KW  - computational models
KW  - context effects
AB  - This chapter compares and contrasts various approaches to understanding human decision making under risk, and is trying to formulate requirements for a cognitive economics theory of risky decision making. Then a first attempt is made to put forward such a theory by proposing a cognitive model JUDGEMAP based on the general cognitive architecture DUAL. This allows the model to be integrated with other cognitive processes such as perception, analogical reasoning, spreading activation memory retrieval, etc. The fact that all processes in DUAL are based on local computations and parallel processing allows for modelling the interplay between various cognitive processes during the decision-making process, in particular the model predicts that the unconscious and automatic process of spreading activation will influence the conscious process of argument building and comparison. This prediction is tested and confirmed by a psychological experiment that demonstrates that seemingly remote and irrelevant aspects of the environment can change the decision we make.
ER  - 

TY  - JOUR
T1  - Children’s construction of a volume calculation algorithm for a rectangular prism with a dynamic virtual manipulative
AU  - Rupnow, Theodore J.
AU  - O’Dell, Jenna R.
AU  - Barrett, Jeffrey E.
AU  - Cullen, Craig J.
AU  - Clements, Douglas H.
AU  - Sarama, Julie
AU  - Rutherford, George
JO  - The Journal of Mathematical Behavior
VL  - 67
SP  - 100998
PY  - 2022
DA  - 2022/09/01/
SN  - 0732-3123
DO  - https://doi.org/10.1016/j.jmathb.2022.100998
UR  - https://www.sciencedirect.com/science/article/pii/S0732312322000669
KW  - Volume measurement
KW  - Virtual manipulatives
KW  - Constructed algorithms
KW  - Children’s reasoning about volume
AB  - We report on the process of children’s construction of a volume calculation algorithm for rectangular prisms. We provided third- and fourth-grade students with traditional volume tasks and a dynamic virtual manipulative to support their three-dimensional reasoning and use of unit cubes to structure space. We investigated the challenges faced, evolving understandings, and supports for growth. We found four threads of understanding we called interpretation, structure, representation, and numeration, that interacted in complex ways as students constructed volume calculation algorithms. Across six patterns of growth, we found that these threads could have both positive and negative influences on one another. The representation thread tended to have the strongest dragging influence on coordinated understanding, and the structuring thread tended to produce the most enduring conceptualizations. We also found that feedback from the dynamic virtual manipulative and the interviewer played a critical role in overcoming challenges and reaching new understandings about volume.
ER  - 

TY  - JOUR
T1  - Modeling and urban planning: A systematic review of performance-based approaches
AU  - Pelorosso, Raffaele
JO  - Sustainable Cities and Society
VL  - 52
SP  - 101867
PY  - 2020
DA  - 2020/01/01/
SN  - 2210-6707
DO  - https://doi.org/10.1016/j.scs.2019.101867
UR  - https://www.sciencedirect.com/science/article/pii/S2210670719316968
KW  - Systems thinking
KW  - Thermodynamics of open systems
KW  - Standards
KW  - Spatial planning
KW  - Model classification
AB  - New planning approaches based on performance measures of the urban system are emerging to face the current challenges to the sustainability of cities. Through modelling, planners can understand the general behavior of the system and, consequently, decide the strategic allocation of land uses and human activities with respect to performances of the considered processes and the socio-ecological and economic uncertainties. Thus, model-based planning approaches present strong similarities with the performance-based planning (PBP) approaches and modelling can represent a valuable tool for the evolution and expansion of PBP. In this paper, a systematic review has explored a) the contribution of modelling within PBP approaches in moving cities towards sustainability; b) the applicability for modeling in PBP in urban contexts. Twelve operational examples of model-based urban planning and PBP have been identified in energy, water infrastructure, land use and ecological planning areas. A scoring system for potential model applicability in urban planning was tested in the sampled case studies. Moreover, several critical elements in the relation between modeling approaches and PBP have been identified. Finally, a discussion on the system performance concept as a new urban planning paradigm has been proposed.
ER  - 

TY  - JOUR
T1  - Sharks and minnows in a shoal of words: Measuring latent ideological positions based on text mining techniques
AU  - Diaf, Sami
AU  - Döpke, Jörg
AU  - Fritsche, Ulrich
AU  - Rockenbach, Ida
JO  - European Journal of Political Economy
VL  - 75
SP  - 102179
PY  - 2022
DA  - 2022/12/01/
SN  - 0176-2680
DO  - https://doi.org/10.1016/j.ejpoleco.2022.102179
UR  - https://www.sciencedirect.com/science/article/pii/S0176268022000015
KW  - Political economy
KW  - Ideology
KW  - Text scaling model
KW  - Wordfish
KW  - Wordshoal
KW  - Computational content analysis
KW  - Hierarchical factor model
KW  - Bayesian estimation
KW  - Polarization
KW  - Public policy
KW  - Monetary policy
KW  - Fiscal policy
AB  - We scale theoretical/ideological positions of economic research institutes over debates. Using only parts of German research institutes’ business cycle reports that deal with economic policy advice as an example, we extract sections from these reports dealing with monetary and fiscal policy issues from 1999 to 2020. To these corpora, we apply methods of unsupervised text scaling (Slapin and Proksch, 2008; Lauderdale and Herzog, 2016), namely Wordfish and Wordshoal. Roughly, results are in line with common sense in the public policy discourse. For monetary policy texts, we observe a strong, but short-lived consensus in debate-specific positions at the height of the financial crisis in 2008 and a larger polarization thereafter compared to the sample period before. For the fiscal policy text corpus, the polarization was similarly high before and after the crisis and decreases somewhat during the COVID-19 pandemic. For both policy areas, the German Institute of Economic Research (DIW), Berlin, and the Institute for World Economics (IfW), Kiel, tend to be the most diverse institutes within the spectrum of latent ideological positions. We argue that text-mining techniques might be useful to scale underlying ideological positions in policy-related publications.
ER  - 

TY  - JOUR
T1  - A swarm intelligence based sample average approximation algorithm for the capacitated reliable facility location problem
AU  - Aydin, Nezir
AU  - Murat, Alper
JO  - International Journal of Production Economics
VL  - 145
IS  - 1
SP  - 173
EP  - 183
PY  - 2013
DA  - 2013/09/01/
SN  - 0925-5273
DO  - https://doi.org/10.1016/j.ijpe.2012.10.019
UR  - https://www.sciencedirect.com/science/article/pii/S0925527312004604
KW  - Reliable
KW  - Facility location
KW  - Stochastic programming
KW  - Sample average approximation
KW  - Swarm intelligence
AB  - We present a novel hybrid method, swarm intelligence based sample average approximation (SIBSAA), for solving the capacitated reliable facility location problem (CRFLP). The CRFLP extends the well-known capacitated fixed-cost facility problem by accounting for the unreliability of facilities. The standard SAA procedure, while effectively used in many applications, can lead to poor solution quality if the selected sample sizes are not sufficiently large. With larger sample sizes, however, the SAA method is not practical due to the significant computational effort required. The proposed SIBSAA method addresses this limitation by using smaller samples and repetitively applying the SAA method while injecting social learning in the solution process inspired by the swarm intelligence of particle swarm optimization. We report on experimental study results showing that the SIBSAA improves the computational efficiency significantly while attaining same or better solution quality than the SAA method.
ER  - 

TY  - JOUR
T1  - Innovative integration of sustainable technologies in educational programs: Fostering freshwater production and environmental preservation awareness
AU  - Li, XiaoKe
JO  - Heliyon
VL  - 10
IS  - 19
SP  - e37978
PY  - 2024
DA  - 2024/10/15/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2024.e37978
UR  - https://www.sciencedirect.com/science/article/pii/S2405844024140091
KW  - Sustainable desalination technologies
KW  - Educational programs
KW  - Freshwater production
KW  - Environmental preservation
KW  - Renewable energy sources
AB  - This study highlights the integration of sustainable desalination technologies into educational programs to raise awareness of freshwater production and environmental preservation. Through a comprehensive curriculum, students explore innovative methods such as pressure-retarded osmosis, multi-effect desalination, and seawater source heat pumps, all powered by renewable seawater thermal energy. The curriculum emphasizes the importance of reducing greenhouse gas emissions, lowering reliance on fossil fuels, and protecting aquatic ecosystems. Students engage in practical evaluations of energy efficiency, economic viability, and environmental impact. Sensitivity analyses are incorporated to help students identify critical factors affecting system performance and optimize operational conditions for various modes. Through hands-on experiments, students learn that components like the heat pump condenser contribute the most to energy loss (29 %), followed by the expansion valve (12 %), compressor (11 %), and seawater heat exchanger (8 %). Economic analyses reveal that while the heat pump condenser and seawater heat exchanger have the lowest financial impact (0.33 % and 2.48 %, respectively), the pressure-retarded osmosis and compressor units have the highest (100 % and 60.3 %, respectively). The findings demonstrate that an optimally designed desalination system can produce freshwater at 80 % lower costs compared to traditional plants, while also reducing carbon emissions by 15 %. Educational experiments also show that integrating pressure-retarded osmosis downstream of multi-effect desalination significantly reduces brine salinity and temperature, highlighting the system's potential for environmental sustainability. This approach not only fosters a deeper understanding of desalination technologies but also equips students with the tools to address future global water challenges.
ER  - 

TY  - CHAP
T1  - Chapter 15 - Constraint optimization: solving engineering design problems using Whale Optimization Algorithm (WOA)
AU  - Moosavi, Syed Kumayl Raza
AU  - Akhter, Malik Naveed
AU  - Zafar, Muhammad Hamza
AU  - Mansoor, Majad
A2  - Mirjalili, Seyedali
BT  - Handbook of Whale Optimization Algorithm
PB  - Academic Press
SP  - 193
EP  - 216
PY  - 2024
DA  - 2024/01/01/
SN  - 978-0-323-95365-8
DO  - https://doi.org/10.1016/B978-0-32-395365-8.00021-X
UR  - https://www.sciencedirect.com/science/article/pii/B978032395365800021X
KW  - Constraint optimization
KW  - Meta-heuristic algorithm
KW  - Machine learning
KW  - Whale optimization algorithm
AB  - The presence of constraints in an engineering design problem complicates the search space solution and reduces the feasible region finding capabilities. Any particular constrained design problem is subject to numerous iterations of trial-and-error to find an optimal constraint handling methodology and fine tuning its requisite parameters. A drawback from such an approach is that it requires intensive computational load specially if the cost function is resourcefully expensive to locate. The work presented in this work suggests the use of a meta-heuristic algorithm namely; Whale Optimization Algorithm (WOA), to solve the constraint optimization problems. The nature inspired algorithm follows a spiral bubble-net hunting strategy, thereby it does not get stuck on a local minima solution even if the search space is discontinuous. For the validation and verification of the algorithm, WOA is applied against 12 structural engineering optimization problems reported in research literature. Performance of the algorithm is further gauged by drawing a comparison with other state-of-the-art meta-heuristic algorithms. Results indicate that the WOA algorithm by far provides the better optimal solutions than the existing methods. Finally, the salient features and future implications are discussed in detail.
ER  - 

TY  - JOUR
T1  - Information overload and environmental degradation: Learning from H.A. Simon and W. Wenders
AU  - Luzzati, Tommaso
AU  - Tucci, Ilaria
AU  - Guarnieri, Pietro
JO  - Ecological Economics
VL  - 202
SP  - 107593
PY  - 2022
DA  - 2022/12/01/
SN  - 0921-8009
DO  - https://doi.org/10.1016/j.ecolecon.2022.107593
UR  - https://www.sciencedirect.com/science/article/pii/S0921800922002555
KW  - Information overload
KW  - Knowledge
KW  - Awareness
KW  - Individual decision-making
KW  - Environmental concern
KW  - H.A. Simon
KW  - W. Wenders
KW  - Film
AB  - This paper discusses the relevance of information overload for explaining environmental degradation, insofar it can reduce individuals' awareness of the unsustainable side-effects of their choices. This “myopia” is reinforced by the increased distance from nature in everyday life brought about by the abundance of exosomatic energy. The departure point of the paper is to show that two outstanding intellectuals, engaged in very different fields, have set forth very similar reflections on the effects of information overload, namely the film director Wim Wenders and the social scientist, really a polymath, Herbert Simon, whose relevance to ecological economics has been recognised. The presentation of their ideas is then complemented by a presentation of the state of the art on information overload, which allows moving to our core argument about environmental degradation.
ER  - 

TY  - CHAP
T1  - Chapter 10 - Emotion-recognition-based music therapy system using electroencephalography signals
AU  - Vijay Sanker, Swatthi
AU  - Ramya Sri Bilakanti, Nivetha B.
AU  - Thomas, Anju
AU  - Gopi, Varun P.
AU  - Palanisamy P., 
A2  - Sridhar, Rajeswari
A2  - Gangadharan, G.R.
A2  - Sheng, Michael
A2  - Shankaran, Rajan
BT  - Edge-of-Things in Personalized Healthcare Support Systems
PB  - Academic Press
SP  - 217
EP  - 235
PY  - 2022
DA  - 2022/01/01/
T2  - Cognitive Data Science in Sustainable Computing
SN  - 978-0-323-90585-5
DO  - https://doi.org/10.1016/B978-0-323-90585-5.00009-6
UR  - https://www.sciencedirect.com/science/article/pii/B9780323905855000096
KW  - DEAP
KW  - EEG
KW  - emotion recognition
KW  - machine learning
KW  - music therapy
AB  - Recent times show increased levels of research in the development of music therapy systems which reduce stress levels in patients by playing songs based on current emotional state of the patient. In this paper, we propose a music recommendation system incorporating emotion recognition from electroencephalography signals to help patients suffering from mental health issues. Emotion recognition using EEG signals is a popular developing technique amidst other techniques such as facial recognition, ECG signals, etc. This technique makes use of machine learning algorithms to classify emotions. However, the detection accuracy of the algorithm has always been a major issue. In this paper, we attempt to improve the detection accuracy using a novel proposed method at reduced computational loads. In this method, the EEG signals are first decomposed into various frequency sub-bands and the band with the largest power is chosen. Following this, an optimum set of four features namely kurtosis parameter, Hjorth mobility, spectral entropy, and power spectral density from a specific set of 5 electrodes are extracted. They are then fed to a machine learning classifier algorithm that classifies the emotion by the valence arousal emotion model. After detecting the emotion, a music recommendation system is developed to suggest songs accordingly which help change the mood of the user. It is built as a user interface website. We implement the above method using the Database for Emotion Analysis using Physiological signals which resulted in an accuracy of 93.2% for valence classification and 95.3% for arousal classification using random forest classifier.
ER  - 

TY  - JOUR
T1  - Dynamic Difficulty Adjustment in Tower Defence
AU  - Sutoyo, Rhio
AU  - Winata, Davies
AU  - Oliviani, Katherine
AU  - Supriyadi, Dedy Martadinata
JO  - Procedia Computer Science
VL  - 59
SP  - 435
EP  - 444
PY  - 2015
DA  - 2015/01/01/
T2  - International Conference on Computer Science and Computational Intelligence (ICCSCI 2015)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2015.07.563
UR  - https://www.sciencedirect.com/science/article/pii/S187705091502092X
KW  - dynamic game balancing
KW  - tower defence
KW  - dynamic difficulty adjustment
KW  - computational intelligence
AB  - When we play tower defence game, generally we repeat the same stages several times with the same enemies. Moreover, when the players play a stage that is ridiculously hard or way too easy, they would probably quit the game because it ismoderately frustrating or boring. The purpose of this research is to createa game that can adapt to the players’ ability so the difficulty of the game becomes dynamic. In other words, the game will have different difficultiesof levels according to the players’ ability. High difficulty levels will be set if the players use good strategy and low difficulty levels will be set if the players use bad strategy. In this work, we determine the difficulties based on players’ lives, enemies’ health, and passive skills (skill points) that are chosen by the player. With three of these factors, players will have varies experience of playing tower defence because different combination will give different results to the system and difficulties of the games will be different for each gameplay. The result of this research is a dynamic difficulty tower defence game, dynamic difficulty adjustment (DDA) document, and gameplay outputs for best, average, and worst strategy cases.
ER  - 

TY  - JOUR
T1  - Locating influence sources in social network by senders and receivers spaces mapping
AU  - Ju, Weijia
AU  - Chen, Yixin
AU  - Chen, Ling
AU  - Li, Bin
JO  - Expert Systems with Applications
VL  - 248
SP  - 123327
PY  - 2024
DA  - 2024/08/15/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2024.123327
UR  - https://www.sciencedirect.com/science/article/pii/S0957417424001921
KW  - Online social network
KW  - Influence source locating
KW  - Latent space
KW  - Representation learning
AB  - Influence source locating is important for misinformation detecting and blocking. However, most of existing multiple sources locating methods use only the local structure of the nodes or the shortest path between them. In addition, some methods do not consider the influencing times of the observed nodes and the mutual effect between the influence cascades originated from various sources. These factors hinder these methods from obtaining high-quality multi-source detection results. To overcome such shortcomings, it is necessary to analyze the nodes’ latent structure characteristics in spreading and receiving the influences. This paper presents a representation learning-based approach to detect the influence sources. The algorithm detects the sources using the topological features of the influenced observed nodes. Firstly, a set of candidate sources is constructed by eliminating some nodes which obviously cannot influence the observed ones. The latent spaces of influence senders and receivers are defined to reveal the nodes' features in influence propagation. The nodes are mapped into the mentioned two latent spaces according to their influencing probabilities and influenced times. The latent spaces establish an influence propagation model, where each node’s representations can be used to obtain the probability that it becomes a source. To optimize the propagation model, negative sampling method is used to reduce the computation time. Our experimental results on data sets of 5 real networks and 3 synthetic networks demonstrate that precision of the result by our algorithm is on average 10 % higher than those of the other similar algorithms.
ER  - 

TY  - JOUR
T1  - A mechanistic survey of Alzheimer's disease
AU  - Tang, Yijing
AU  - Zhang, Dong
AU  - Gong, Xiong
AU  - Zheng, Jie
JO  - Biophysical Chemistry
VL  - 281
SP  - 106735
PY  - 2022
DA  - 2022/02/01/
SN  - 0301-4622
DO  - https://doi.org/10.1016/j.bpc.2021.106735
UR  - https://www.sciencedirect.com/science/article/pii/S0301462221002180
KW  - Alzheimer's disease
KW  - Amyloid-beta
KW  - Protein misfolding
KW  - Protein aggregation
AB  - Alzheimer's disease (AD) is the most common, age-dependent neurodegenerative disorder. While AD has been intensively studied from different aspects, there is no effective cure for AD, largely due to a lack of a clear mechanistic understanding of AD. In this mini-review, we mainly focus on the discussion and summary of mechanistic causes of Alzheimer's disease (AD). While different AD mechanisms illustrate different molecular and cellular pathways in AD pathogenesis, they do not necessarily exclude each other. Instead, some of them could work together to initiate, trigger, and promote the onset and development of AD. In a broader viewpoint, some AD mechanisms (e.g., amyloid aggregation mechanism, microbial infection/neuroinflammation mechanism, and amyloid cross-seeding mechanism) could also be applicable to other amyloid diseases including type II diabetes, Parkinson's disease, and prion disease. Such common mechanisms for AD and other amyloid diseases explain not only the pathogenesis of individual amyloid diseases, but also the spreading of pathologies between these diseases, which will inspire new strategies for therapeutic intervention and prevention for AD.
ER  - 

TY  - JOUR
T1  - Unveiling the dynamics of self-regulated learning in project-based learning environments
AU  - Wu, Xiu-Yi
JO  - Heliyon
VL  - 10
IS  - 5
SP  - e27335
PY  - 2024
DA  - 2024/03/15/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2024.e27335
UR  - https://www.sciencedirect.com/science/article/pii/S2405844024033668
KW  - Project-based learning
KW  - Self-regulated learning
KW  - Latent profile analysis
KW  - Epistemic network analysis
KW  - College English
AB  - Project-based learning (PBL) has been found to exert a positive influence on learners' academic achievements, while also fostering their intrinsic motivation and playing a crucial role in nurturing sustainable learning capacities. Understanding individual differences in self-regulated learning (SRL) within project-based foreign language learning can guide language teachers in delivering personalized instruction. This study utilized a blended learning management system to collect and analyze data on SRL from 95 learners enrolled in a project-based College English course. Through microanalysis, latent profile analysis (LPA), and epistemic network analysis (ENA), the study identified distinct learner profiles and traced their developmental trajectories in project-based language learning. The findings revealed that PBL facilitates the occurrence of SRL behaviors and strengthens connections across different regulation phases. Notably, learners with diverse profiles displayed variations in their SRL epistemic network structures and developmental trajectories. These results highlight the dynamic nature of SRL within the PBL context, underscoring the significance of considering individual differences and supporting learners’ evolving self-regulatory behaviors and strategies throughout their engagement in PBL activities. To enhance SRL in PBL, educators are encouraged to provide scaffolding support, promote help-seeking behaviors, and implement interventions targeting metacognitive processes and reflective practices.
ER  - 

TY  - JOUR
T1  - An empirical study on the driving factors and pathways of research talents innovation capability
AU  - Guo, Zheng
AU  - Liang, Lijun
AU  - Xie, Yundong
JO  - Procedia Computer Science
VL  - 242
SP  - 1425
EP  - 1432
PY  - 2024
DA  - 2024/01/01/
T2  - 11th International Conference on Information Technology and Quantitative Management (ITQM 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.08.105
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924018246
KW  - research talents
KW  - research institutions
KW  - research environment
KW  - innovative capability
KW  - driving factors
AB  - This study designed a survey questionnaire encompassing three levels: research institutions, research environment, and research talents, with 19 specific measurement indicators. The questionnaire was distributed to research personnel from over 20 research institutes, universities and related enterprises in China. Based on 537 valid responses, a structural equation model (SEM) was constructed to analyze the relational effects of the driving factors. The findings are as follows: (1) The innovative capability of research talents is a composite outcome of the interaction between multiple "external-internal" factors. Effective organizational support from research institutions and a favorable research environment, both soft and hard, are indispensable elements in enhancing this capability. (2) A key factor in enhancing innovation capability is the proper resolution of effective supply and scientific utilization of research resources by research institutions, along with the improvement of research satisfaction. (3) Research institutions should establish an integrated research mechanism that combines "environment-organization-talent" to achieve the generation and effective transformation of high-quality research outputs.
ER  - 

TY  - CHAP
T1  - Chapter 5 - Infrastructural intelligence: Contemporary entanglements between neuroscience and AI
AU  - Bruder, Johannes
A2  - Mahfoud, Tara
A2  - McLean, Sam
A2  - Rose, Nikolas
BT  - Progress in Brain Research
PB  - Elsevier
VL  - 233
SP  - 101
EP  - 128
PY  - 2017
DA  - 2017/01/01/
T2  - Vital Models
SN  - 0079-6123
DO  - https://doi.org/10.1016/bs.pbr.2017.06.004
UR  - https://www.sciencedirect.com/science/article/pii/S0079612317300547
KW  - Artificial intelligence
KW  - Computational neuroscience
KW  - Brain imaging
KW  - Google DeepMind technologies
KW  - Default mode network
AB  - In this chapter, I reflect on contemporary entanglements between artificial intelligence and the neurosciences by tracing the development of Google's recent DeepMind algorithms back to their roots in neuroscientific studies of episodic memory and imagination. Google promotes a new form of “infrastructural intelligence,” which excels by constantly reassessing its cognitive architecture in exchange with a cloud of data that surrounds it, and exhibits putatively human capacities such as intuition. I argue that such (re)alignments of biological and artificial intelligence have been enabled by a paradigmatic infrastructuralization of the brain in contemporary neuroscience. This infrastructuralization is based in methodologies that epistemically liken the brain to complex systems of an entirely different scale (i.e., global logistics) and has given rise to diverse research efforts that target the neuronal infrastructures of higher cognitive functions such as empathy and creativity. What is at stake in this process is no less than the shape of brains to come and a revised understanding of the intelligent and creative social subject.
ER  - 

TY  - JOUR
T1  - On an inferential model construction using generalized associations
AU  - Martin, Ryan
JO  - Journal of Statistical Planning and Inference
VL  - 195
SP  - 105
EP  - 115
PY  - 2018
DA  - 2018/05/01/
T2  - Confidence distributions
SN  - 0378-3758
DO  - https://doi.org/10.1016/j.jspi.2016.11.006
UR  - https://www.sciencedirect.com/science/article/pii/S0378375816301537
KW  - Likelihood
KW  - Marginalization
KW  - Monte Carlo
KW  - Plausibility function
KW  - Random set
KW  - Validity
AB  - The inferential model (IM) approach, like fiducial and its generalizations, depends on a representation of the data-generating process. Here, a particular variation on the IM construction is considered, one based on generalized associations. The resulting generalized IM is more flexible in that it does not require a complete specification of the data-generating process and is provably valid under mild conditions. Computation and marginalization strategies are discussed, and two applications of this generalized IM approach are presented.
ER  - 

TY  - JOUR
T1  - Combining machine-based and econometrics methods for policy analytics insights
AU  - Kauffman, Robert J.
AU  - Kim, Kwansoo
AU  - Lee, Sang-Yong Tom
AU  - Hoang, Ai-Phuong
AU  - Ren, Jing
JO  - Electronic Commerce Research and Applications
VL  - 25
SP  - 115
EP  - 140
PY  - 2017
DA  - 2017/09/01/
SN  - 1567-4223
DO  - https://doi.org/10.1016/j.elerap.2017.04.004
UR  - https://www.sciencedirect.com/science/article/pii/S1567422317300145
KW  - Causality
KW  - Computational Social Science
KW  - Data analytics
KW  - Econometrics
KW  - E-commerce
KW  - Empirical research
KW  - Fintech
KW  - Fusion analytics
KW  - Music popularity
KW  - Stock trading
KW  - Policy analytics
KW  - TV viewing
KW  - Video-on-demand (VoD)
AB  - Computational Social Science (CSS) has become a mainstream approach in the empirical study of policy analytics issues in various domains of e-commerce research. This article is intended to represent recent advances that have been made for the discovery of new policy-related insights in business, consumer and social settings. The approach discussed is fusion analytics, which combines machine-based methods from Computer Science (CS) and explanatory empiricism involving advanced Econometrics and Statistics. It explores several efforts to conduct research inquiry in different functional areas of Electronic Commerce and Information Systems (IS), with applications that represent different functional areas of business, as well as individual consumer, social and public issues. Recent developments and shifts in the scientific study of technology-related phenomena and Social Science issues in the presence of historically-large datasets prompt new forms of research inquiry. They include blended approaches to research methodology, and more interest in the production of research results that have direct application to industry contexts. This article showcases the methods shifts and several contemporary applications. They discuss: (1) feedback effects in mobile phone-based stock trading; (2) sustainability of top-rank chart popularity of music tracks; (3) household TV viewing patterns; and (4) household sampling and purchases of video-on-demand (VoD) services. The range of applicability of the ideas goes beyond the scope of these illustrations, to include issues in public services, healthcare, product and service deployment, public opinion and elections, electronic auctions, and travel and tourism services. In fact, the coverage is as broad as for-profit and for-non-profit, private and public, and governmental and non-governmental institutions.
ER  - 

TY  - JOUR
T1  - Metronomic reloaded: Theoretical models bringing chemotherapy into the era of precision medicine
AU  - Benzekry, Sébastien
AU  - Pasquier, Eddy
AU  - Barbolosi, Dominique
AU  - Lacarelle, Bruno
AU  - Barlési, Fabrice
AU  - André, Nicolas
AU  - Ciccolini, Joseph
JO  - Seminars in Cancer Biology
VL  - 35
SP  - 53
EP  - 61
PY  - 2015
DA  - 2015/12/01/
T2  - Complexity in Cancer Biology
SN  - 1044-579X
DO  - https://doi.org/10.1016/j.semcancer.2015.09.002
UR  - https://www.sciencedirect.com/science/article/pii/S1044579X15000759
KW  - Metronomic chemotherapy
KW  - Mathematical modeling
KW  - PK/PD
KW  - Precision medicine
AB  - Oncology has benefited from an increasingly growing number of groundbreaking innovations over the last decade. Targeted therapies, biotherapies, and the most recent immunotherapies all contribute to increase the number of therapeutic options for cancer patients. Consequently, substantial improvements in clinical outcomes for some disease with dismal prognosis such as lung carcinoma or melanoma have been achieved. Of note, the latest innovations in targeted therapies or biotherapies do not preclude the use of standard cytotoxic agents, mostly used in combination. Importantly, and despite the rise of bioguided (a.k.a. precision) medicine, the administration of chemotherapeutic agents still relies on the maximum tolerated drug (MTD) paradigm, a concept inherited from theories conceptualized nearly half a century ago. Alternative dosing schedules such as metronomic regimens, based upon the repeated and regular administration of low doses of chemotherapeutic drugs, and adaptive therapy (i.e. modulating the dose and frequency of cytotoxics administration to control disease progression rather than eradicate it at all cost) have emerged as possible strategies to improve response rates while reducing toxicities. The recent changes in paradigm in the way we theorize cancer biology and evolution, metastatic spreading and tumor ecology, alongside the recent advances in the field of immunotherapy, have considerably strengthened the interest for these alternative approaches. This paper aims at reviewing the recent evolutions in the field of theoretical biology of cancer and computational oncology, with a focus on the consequences these changes have on the way we administer chemotherapy. Here, we advocate for the development of model-guided strategies to refine doses and schedules of chemotherapy administration in order to achieve precision medicine in oncology.
ER  - 

TY  - JOUR
T1  - Bioart
AU  - Yetisen, Ali K.
AU  - Davis, Joe
AU  - Coskun, Ahmet F.
AU  - Church, George M.
AU  - Yun, Seok Hyun
JO  - Trends in Biotechnology
VL  - 33
IS  - 12
SP  - 724
EP  - 734
PY  - 2015
DA  - 2015/12/01/
SN  - 0167-7799
DO  - https://doi.org/10.1016/j.tibtech.2015.09.011
UR  - https://www.sciencedirect.com/science/article/pii/S016777991500205X
KW  - genetics
KW  - transgenic art
KW  - tissue engineering
KW  - ethics
KW  - aesthetics
AB  - Bioart is a creative practice that adapts scientific methods and draws inspiration from the philosophical, societal, and environmental implications of recombinant genetics, molecular biology, and biotechnology. Some bioartists foster interdisciplinary relationships that blur distinctions between art and science. Others emphasize critical responses to emerging trends in the life sciences. Since bioart can be combined with realistic views of scientific developments, it may help inform the public about science. Artistic responses to biotechnology also integrate cultural commentary resembling political activism. Art is not only about ‘responses’, however. Bioart can also initiate new science and engineering concepts, foster openness to collaboration and increasing scientific literacy, and help to form the basis of artists’ future relationships with the communities of biology and the life sciences.
ER  - 

TY  - CHAP
T1  - 9.05 - NMR of carboranes
AU  - Ellis, David
A2  - Reedijk, Jan
A2  - Poeppelmeier, Kenneth R.
BT  - Comprehensive Inorganic Chemistry III (Third Edition)
PB  - Elsevier
CY  - Oxford
SP  - 62
EP  - 106
PY  - 2023
DA  - 2023/01/01/
SN  - 978-0-12-823153-1
DO  - https://doi.org/10.1016/B978-0-12-823144-9.00058-3
UR  - https://www.sciencedirect.com/science/article/pii/B9780128231449000583
KW  - Antipodal effect
KW  - Boranes
KW  - Boron NMR
KW  - Carboranes
KW  - Computational chemistry
KW  - Dynamic NMR
KW  - Inorganic chemistry
KW  - NICS
KW  - NMR spectroscopy
KW  - Organometallics
KW  - Solid-state NMR
AB  - This contribution presents a survey of the literature on the NMR of carboranes from the early years of study to the present day. Following an introduction to the subject, subsequent sections deal with the principal nuclei concerned, namely the isotopes of boron, (overwhelmingly 11B), 1H, 13C and 19F (the latter as there are many examples of clusters where terminal B-Hs are substituted by B-F units, fluorine may therefore be regarded as a significant tool in the field). Despite the title, some literature on boron clusters (carbon-free) is included where it is felt they can illuminate the topic, also metallaboranes and metallacarboranes, with similar justification. Many journal articles describing synthetic and structural studies of carboranes will heavily feature NMR as a technique of characterization. Reference to these is limited, attention being focussed on work where novel or pioneering NMR concepts and discoveries are described. Significant attention is paid to computational methods, especially in relation to 11B NMR, and to the Antipodal Effect, a rich area of study over many years, both computationally and spectroscopically. The utility of NICS (nucleus-independent chemical shift) values in assessing three-dimensional aromaticity of some carboranes, is covered, including comparison with more conventional organic aromatics. Finally, there is included a relatively brief survey of instrumental methods, including 2D techniques, solid-state, and dynamic NMR spectroscopy. There is a vast literature on the NMR of carboranes and this chapter can only be a portal into that space, the reader is directed to the many relevant reviews, referenced in this work, for further information.
ER  - 

TY  - JOUR
T1  - Stochastic optimization of disruption-driven supply chain network design with a new resilience metric
AU  - Fattahi, Mohammad
AU  - Govindan, Kannan
AU  - Maihami, Reza
JO  - International Journal of Production Economics
VL  - 230
SP  - 107755
PY  - 2020
DA  - 2020/12/01/
SN  - 0925-5273
DO  - https://doi.org/10.1016/j.ijpe.2020.107755
UR  - https://www.sciencedirect.com/science/article/pii/S0925527320301407
KW  - Resilience metrics
KW  - Supply chain network design
KW  - Stochastic programming
KW  - Conic mixed-integer program
AB  - The supply chain (SC) ability to return quickly and effectively to its initial condition or even a more desirable state after a disruption is critically important, and is defined as SC resilience. Nevertheless, it has not been sufficiently quantified in the related literature. This study provides a new metric to quantify the SC resilience by using the stochastic programming. Our metric measures the expected value of the SC's cost increase due to a possible disruption event during its recovery period. Based on this measure, we propose a two-stage stochastic program for the supply chain network design under disruption events that optimizes location, allocation, inventory and order-size decisions. The stochastic program is formulated using quadratic conic optimization, and the sample average approximation (SAA) method is employed to handle the large number of disruption scenarios. A comprehensive computational study is carried out to highlight the applicability of the presented metric, the computational tractability of the stochastic program, and the performance of the SAA. Several key managerial and practical insights are gained based on the computational results. This new metric captures the time and cost of the SC's recovery after disruption events contrast to most of previous studies and main impacts of these two aspects on design decisions are highlighted. Further, it is shown computationally that the increase of SC's capacity is not a suitable strategy for designing resilient SCs in some business environments.
ER  - 

TY  - JOUR
T1  - A context-aware data mining process model based framework for supporting evaluation of data mining results
AU  - Osei-Bryson, Kweku-Muata
JO  - Expert Systems with Applications
VL  - 39
IS  - 1
SP  - 1156
EP  - 1164
PY  - 2012
DA  - 2012/01/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2011.07.117
UR  - https://www.sciencedirect.com/science/article/pii/S0957417411010797
KW  - Context
KW  - Data mining process
KW  - KDDM
KW  - Evaluation
KW  - Decision analysis
KW  - Multi-criteria decision analysis
KW  - Post-processing
AB  - The knowledge discovery via data mining process (KDDM) is a multiple phase that aims to at a minimum semi-automatically extract new knowledge from existing datasets. For many data mining tasks, the evaluation phase is a challenging one for various reasons. Given this challenge several studies have presented techniques that could be used for the semi-automated evaluation of data mining results. When taken together, these studies suggest the possibility of a common multi-criteria evaluation framework. The use of such a multi-criteria evaluation framework, however, requires that relevant objectives, measures and preference function be identified. This implies that the context of the DM problem is particularly important for the evaluation phase of the KDDM process. Our framework utilizes and integrates a pair of established tightly coupled techniques (i.e. Value Focused Thinking (VFT) and the Goal–Question–Metric (GQM) methods) as well as established techniques from multi-criteria decision analysis in order to explicate and utilize context information in order to facilitate semi-automated evaluation.
ER  - 

TY  - JOUR
T1  - Modeling quick autonomous response for virtual characters in safety education games
AU  - Liu, Tingting
AU  - Liu, Zhen
AU  - Wang, Yuanyi
AU  - Chai, Yanjie
JO  - Cognitive Systems Research
VL  - 88
SP  - 101276
PY  - 2024
DA  - 2024/12/01/
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2024.101276
UR  - https://www.sciencedirect.com/science/article/pii/S1389041724000706
KW  - Behavior
KW  - Emotion
KW  - Motivation
KW  - Perception
KW  - Virtual Character
AB  - Serious games have a wide range of applications. Modeling virtual character behaviors and emotions is a challenging task in developing serious games. To generate real-time responses, behavioral and emotional models must be simple and effective. Existing studies have paid little attention to the semantic understanding of virtual characters to external stimuli and have not effectively linked perceived semantics and motivation. This paper proposes a cognitive structure for the virtual character. The structure contains multiple modules: perception, personality, motivation, behavior, and emotion. Based on psychological theory, a semantic table that connects external stimuli, motivations, behaviors, and emotions is designed for each virtual character. Perceptivity is introduced to measure the degree of perception. According to Maslow’s motivation theory, a quantitative description of motivation is given and a discriminating method is proposed to generate behaviors and emotions. A prototype of a serious game is developed to verify the validity of the proposed method. The experimental results show that the proposed method can simulate the behavior and emotion of virtual characters in real time and will enhance the immersion of serious games.
ER  - 

TY  - JOUR
T1  - Multiple Criteria Optimization of the Carpooling Problem
AU  - Żak, Jacek
AU  - Hojda, Maciej
AU  - Filcek, Grzegorz
JO  - Transportation Research Procedia
VL  - 37
SP  - 139
EP  - 146
PY  - 2019
DA  - 2019/01/01/
T2  - 21st EURO Working Group on Transportation Meeting, EWGT 2018, 17th – 19th September 2018, Braunschweig, Germany
SN  - 2352-1465
DO  - https://doi.org/10.1016/j.trpro.2018.12.176
UR  - https://www.sciencedirect.com/science/article/pii/S235214651830591X
KW  - carpooling
KW  - multiple criteria optimisation
KW  - NSGA II
KW  - LBS
AB  - The paper presents a multiple criteria (MC) formulation of the carpooling optimization (CO) problem and a solution procedure that allows to solve it. The mathematical model of the MCCO problem includes two major sub-problems, such as planning of the routes and matching carpoolers (drivers and passengers). Different aspects, including: economic, social, technical and market-oriented are considered. The MCCO problem is solved with the application of an original computational procedure based on the multiple criteria genetic algorithm, called NSGA II and the solutions’ analysis and review technique, called Light Beam Search (LBS) method. The former method allows to generate a set of Pareto optimal solutions, while the latter assists the carpoolers in finding the most desired compromise solution (common route and match between carpoolers). The results of computational experiments are presented. We find that solving the formulating carpooling problem in a heuristic manner is possible in reasonable time
ER  - 

TY  - JOUR
T1  - Machine learning – A new kind of cultural tool? A “recontextualisation” perspective on machine learning + interprofessional learning
AU  - Guile, David
JO  - Learning, Culture and Social Interaction
VL  - 42
SP  - 100738
PY  - 2023
DA  - 2023/10/01/
SN  - 2210-6561
DO  - https://doi.org/10.1016/j.lcsi.2023.100738
UR  - https://www.sciencedirect.com/science/article/pii/S2210656123000545
KW  - Cultural tool
KW  - Machine learning
KW  - Interprofessional learning
KW  - Recontextualisation
KW  - Cultural ecosystem
AB  - The paper argues that (a) Machine Learning (ML) constitutes a cultural tool capable of learning through perceiving patterns in data, (b) the kind of learning ML is capable of nevertheless constitutes a more circumscribed kind of learning compared with how that concept has been interpreted in sociocultural (S-c) theory; and, (c) the development of ML is therefore further extending and distributing the complex relationship between human and machine cognition and learning. The paper explores these contentions by firstly, providing a broad-based account of the conception of cultural tools in S-c Theory. Secondly, offering a genealogy of ML, including the model of learning that underpins ML and highlights the challenge that a cultural too capable of some kind of learning presents for the extant S-c conception of a cultural tool. Thirdly, identifying the new human-machine working-learning problem the ML model of learning is generating. Finally, argues the concept of recontextualization offers a way to address that problem by providing a holistic perspective on the relationship between ML and IPL models of learning. In making this argument the paper distinguishes between the ML predictive and the Chat GPT answer to question(s) model of learning.
ER  - 

TY  - JOUR
T1  - Subnational sustainable development: The role of vertical intergovernmental transfers in reaching multidimensional goals
AU  - Guerrero, Omar A.
AU  - Castañeda, Gonzalo
AU  - Trujillo, Georgina
AU  - Hackett, Lucy
AU  - Chávez-Juárez, Florian
JO  - Socio-Economic Planning Sciences
VL  - 83
SP  - 101155
PY  - 2022
DA  - 2022/10/01/
SN  - 0038-0121
DO  - https://doi.org/10.1016/j.seps.2021.101155
UR  - https://www.sciencedirect.com/science/article/pii/S0038012121001476
KW  - Subnational development
KW  - SDGs
KW  - State finances
KW  - Fiscal federalism
KW  - Sustainability
KW  - Policy priorities
KW  - Agent-based model
AB  - From a public finance point of view, achieving sustainable development hinges on two critical factors: the subnational implementation of public policies and the efficient allocation of resources across regions through vertical intergovernmental transfers. We introduce a framework that links these two mechanisms for analyzing the impact of reallocating federal transfers in the presence of regional heterogeneity from development indicators, budget sizes, expenditure returns, and long-term structural factors. Our study focuses on the case of Mexico and its 32 states. Using an agent-based computational model, we estimate the development gaps that will remain by the year 2030, and characterize their sensitivity to changes in the states’ budget sizes. Then, we estimate the optimal distribution of federal transfers to minimize these gaps. Crucially, these distributions depend on the specific development objectives set by the national government, and by various interdependencies between the heterogeneous qualities of the states. This work sheds new light on the complex problem of budgeting for the Sustainable Development Goals at the subnational level, and it is especially relevant for the study of fiscal decentralization from the expenditure point of view.
ER  - 

TY  - JOUR
T1  - A multicriteria group decision-making method based on AIVIFSs, Z-numbers, and trapezium clouds
AU  - Jia, Qianlei
AU  - Hu, Jiayue
AU  - He, Qizhi
AU  - Zhang, Weiguo
AU  - Safwat, Ehab
JO  - Information Sciences
VL  - 566
SP  - 38
EP  - 56
PY  - 2021
DA  - 2021/08/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2021.02.042
UR  - https://www.sciencedirect.com/science/article/pii/S0020025521001845
KW  - Multicriteria group decision-making (MCGDM)
KW  - Atanassov’s interval-valued intuitionistic fuzzy sets (AIVIFSs)
KW  - Z-numbers
KW  - Z-trapezium-trapezium cloud (ZTTC)
KW  - Coronavirus Disease 2019 (COVID-19)
AB  - Multicriteria group decision-making (MCGDM), with the strong uncertainty and randomness, has always been a hotspot in the world. The chief purpose of the paper is to address the problem with Atanassov’s interval-valued intuitionistic fuzzy sets (AIVIFSs), Z-numbers, and trapezium clouds. First, some related concepts and former operators of AIVIFSs, Z-numbers, and trapezium clouds are reviewed, meanwhile, AIVIFSs and Z-numbers are synthesized to come up with a novel linguistic expression. Then, Z-trapezium-trapezium cloud (ZTTC) is proposed to quantify the linguistic evaluation information to avoid excessive computation caused by traditional methods. Later, a new approach of calculating the objective weight vector is presented based on entropy weight method (EWM). To take the huge advantages of technique for order preference by similarity to ideal solution (TOPSIS) method in ranking, 2-norm in mathematical theory is applied to derive a way of calculating the distance between different ZTTCs. Finally, an example about the grade assessment of coronavirus Disease 2019 (COVID-19) is given. For further confirming the validity and feasibility, sensitivity analysis and comparison with other methods are conducted.
ER  - 

TY  - CHAP
T1  - 2.20 - Translational Aspects in Drug Discovery
AU  - Detalle, L.
AU  - Vanheusden, K.
AU  - Sargentini-Maier, M.L.
AU  - Stöhr, T.
A2  - Chackalamannil, Samuel
A2  - Rotella, David
A2  - Ward, Simon E.
BT  - Comprehensive Medicinal Chemistry III
PB  - Elsevier
CY  - Oxford
SP  - 495
EP  - 529
PY  - 2017
DA  - 2017/01/01/
SN  - 978-0-12-803201-5
DO  - https://doi.org/10.1016/B978-0-12-409547-2.12335-2
UR  - https://www.sciencedirect.com/science/article/pii/B9780124095472123352
KW  - Animal model
KW  - Biomarker
KW  - Imaging
KW  - Modeling
KW  - Simulation
KW  - Translational medicine
AB  - The efficiency of drug development has seen a constant decline. This observation is somewhat paradoxical since during the same time there have been huge advancements in drug discovery and development technologies that made it much cheaper, faster, and easier to identify new drug targets and new drug molecules. Translational Science or Translational Medicine (TM) has arisen as an important discipline in modern drug discovery and development. It was triggered by the fact that many promising drugs failed in clinical trials. The challenge was thus to enhance the predictivity of the preclinical models and to design exploratory clinical trial designs and methodologies to test promising molecules earlier and faster. Despite some advancements, the number of drugs that finally receive regulatory approval is still at a low level. The main reason for this drug failure rate was a lack of efficacy observed in clinical trials of drug candidates that showed great promise in drug discovery. There may be two main factors responsible for this: (1) the industrialization of drug discovery and development led to huge specialized departments that operate in isolation. (2) Tools for successful translational research have only been developed in the last one or two decades. We will describe the tools used in translational research, that is, biomarkers, animal models, imaging, in silico modeling, and simulations. Their use will be illustrated with examples and tips of how to implement those into daily project work. We believe, however, that TM is more than these tools and technologies. It is not yet another discipline or department, it is a way of thinking that should become part of every discipline involved in drug development. Thus, in addition to describing the tools and how best to use them, we will elaborate how to design a translational research strategy and exemplify with some case studies as to how this has been successfully implemented in the past.
ER  - 

TY  - JOUR
T1  - The perils and pitfalls of explainable AI: Strategies for explaining algorithmic decision-making
AU  - de Bruijn, Hans
AU  - Warnier, Martijn
AU  - Janssen, Marijn
JO  - Government Information Quarterly
VL  - 39
IS  - 2
SP  - 101666
PY  - 2022
DA  - 2022/04/01/
SN  - 0740-624X
DO  - https://doi.org/10.1016/j.giq.2021.101666
UR  - https://www.sciencedirect.com/science/article/pii/S0740624X21001027
KW  - Artificial intelligence
KW  - XAI
KW  - Algorithms
KW  - Computational intelligence
KW  - Data-driven decision
KW  - Socio-tech
KW  - Transparency
KW  - Accountability
KW  - Trust
KW  - E-government
AB  - Governments look at explainable artificial intelligence's (XAI) potential to tackle the criticisms of the opaqueness of algorithmic decision-making with AI. Although XAI is appealing as a solution for automated decisions, the wicked nature of the challenges governments face complicates the use of XAI. Wickedness means that the facts that define a problem are ambiguous and that there is no consensus on the normative criteria for solving this problem. In such a situation, the use of algorithms can result in distrust. Whereas there is much research advancing XAI technology, the focus of this paper is on strategies for explainability. Three illustrative cases are used to show that explainable, data-driven decisions are often not perceived as objective by the public. The context might raise strong incentives to contest and distrust the explanation of AI, and as a consequence, fierce resistance from society is encountered. To overcome the inherent problems of XAI, decisions-specific strategies are proposed to lead to societal acceptance of AI-based decisions. We suggest strategies to embrace explainable decisions and processes, co-create decisions with societal actors, move away from an instrumental to an institutional approach, use competing and value-sensitive algorithms, and mobilize the tacit knowledge of professionals
ER  - 

TY  - JOUR
T1  - Application of computer image processing technology in old artistic design restoration
AU  - Chen, Guo
AU  - Wen, Zhiyong
AU  - Hou, Fazhong
JO  - Heliyon
VL  - 9
IS  - 11
SP  - e21366
PY  - 2023
DA  - 2023/11/01/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2023.e21366
UR  - https://www.sciencedirect.com/science/article/pii/S2405844023085742
KW  - Art design
KW  - Edge detection
KW  - Gradient distribution
KW  - Recurrent learning
KW  - Texture classification
AB  - Art designs exhibit different principles, textures, color combinations, and creative skills for vivid thinking visualizations. Art exhibits are far from ages, periods, and creators finding their digital patterns in recent years for resurrection. Degraded periodic artworks are digitally handled for reviving their legacy using digital image processing. This article introduces Textural Restoration Technique (TRT) using Deep Feature Processing (DFP) to augment such innovations. The proposed technique analyses the tampered image for its textures, and available features are extracted. The textures are expected to be sequential based on gradient distribution; the missing gradients are identified from the available features near the region of interest (ROI). The ROI is marked by combining missing and available features from which textural edges are sketched. In this process, recurrent learning is employed for verifying the gradient substitutions for even textures. The texture patterns are classified using high and low accuracy features exhibited between two successive ROIs. First, the learning model is trained using gradient distribution accuracy pursued by the texture completion edge. The second training is pursued by the first distribution, achieving the maximum restoration. The filled features and their gradient positions are marked by moving the ROIs for distinguishing textures. The restoration ratio is computed with high accuracy based on the filled edges.
ER  - 

TY  - JOUR
T1  - A note on VNP-completeness and border complexity
AU  - Ikenmeyer, Christian
AU  - Sanyal, Abhiroop
JO  - Information Processing Letters
VL  - 176
SP  - 106243
PY  - 2022
DA  - 2022/06/01/
SN  - 0020-0190
DO  - https://doi.org/10.1016/j.ipl.2021.106243
UR  - https://www.sciencedirect.com/science/article/pii/S0020019021001587
KW  - Theory of computation
KW  - Computational complexity
KW  - Algebraic complexity theory
KW  - Border complexity
KW  - Reductions
AB  - In 1979 Valiant introduced the complexity class VNP of p-definable families of polynomials, he defined the reduction notion known as p-projection and he proved that the permanent polynomial and the Hamiltonian cycle polynomial are VNP-complete under p-projections. In 2001 Mulmuley and Sohoni (and independently Bürgisser) introduced the notion of border complexity to the study of the algebraic complexity of polynomials. In this algebraic machine model, instead of insisting on exact computation, approximations are allowed. This gives VNP the structure of a topological space. In this short note we study the set VNPC of VNP-complete polynomials. We show that the complement VNP ∖ VNPC lies dense in VNP. Quite surprisingly, we also prove that VNPC lies dense in VNP. We prove analogous statements for the complexity classes VF, VBP, and VP. The density of VNP ∖ VNPC holds for several different reduction notions: p-projections, border p-projections, c-reductions, and border c-reductions. We compare the relationships of the completeness notions under these reductions and separate most of the corresponding sets. Border reduction notions were introduced by Bringmann, Ikenmeyer, and Zuiddam ((2018) [7]). Our paper is the first structured study of border reduction notions.
ER  - 

TY  - JOUR
T1  - The relationship between students' gender and their confidence in the correctness of their solutions to complex and difficult mathematics problems
AU  - McMurran, Meaghan
AU  - Weisbart, David
AU  - Atit, Kinnari
JO  - Learning and Individual Differences
VL  - 107
SP  - 102349
PY  - 2023
DA  - 2023/10/01/
SN  - 1041-6080
DO  - https://doi.org/10.1016/j.lindif.2023.102349
UR  - https://www.sciencedirect.com/science/article/pii/S1041608023000936
KW  - Gender
KW  - Mathematics
KW  - Confidence
KW  - Calibration
KW  - Problem difficulty
AB  - It is well established that men more frequently exhibit over-confidence than women in mathematics. Less is known about the relationship between gender and problem-specific confidence judgments and whether this relationship depends on problem difficulty. To investigate the relationship between gender, problem difficulty, and problem-specific confidence judgments, including how calibrated and under/over-confident men and women are, we examine data from 349 women and 279 men who were instructed to solve 13 difficult and complex mathematics problems and report their confidence in the correctness of their solutions. We find that men were more confident than women and that the gender gap in confidence decreases with increasing problem difficulty. Women were better calibrated than men and the gender gap in calibration increased with problem difficulty. As problem difficulty increased, women, but not men, transitioned from being under- to over-confident.
ER  - 

TY  - JOUR
T1  - A Padawan Programmer’s Guide to Developing Software Libraries
AU  - Yurkovich, James T.
AU  - Yurkovich, Benjamin J.
AU  - Dräger, Andreas
AU  - Palsson, Bernhard O.
AU  - King, Zachary A.
JO  - Cell Systems
VL  - 5
IS  - 5
SP  - 431
EP  - 437
PY  - 2017
DA  - 2017/11/22/
SN  - 2405-4712
DO  - https://doi.org/10.1016/j.cels.2017.08.003
UR  - https://www.sciencedirect.com/science/article/pii/S2405471217303368
AB  - With the rapid adoption of computational tools in the life sciences, scientists are taking on the challenge of developing their own software libraries and releasing them for public use. This trend is being accelerated by popular technologies and platforms, such as GitHub, Jupyter, R/Shiny, that make it easier to develop scientific software and by open-source licenses that make it easier to release software. But how do you build a software library that people will use? And what characteristics do the best libraries have that make them enduringly popular? Here, we provide a reference guide, based on our own experiences, for developing software libraries along with real-world examples to help provide context for scientists who are learning about these concepts for the first time. While we can only scratch the surface of these topics, we hope that this article will act as a guide for scientists who want to write great software that is built to last.
ER  - 

TY  - JOUR
T1  - An efficient conflict analysis method based on splitting and merging of formal contexts
AU  - Zhi, Huilai
AU  - Qi, Zhenhao
AU  - Li, Yinan
JO  - Information Sciences
VL  - 661
SP  - 120154
PY  - 2024
DA  - 2024/03/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2024.120154
UR  - https://www.sciencedirect.com/science/article/pii/S0020025524000677
KW  - Conflict analysis
KW  - Information fusion
KW  - Formal concept analysis
KW  - Three-way decision
AB  - Conflict situations are widespread nearly in all corners of social life, and the efficiency of conflict analysis still has much room especially for large-scale data sets. To this end, this study presents an information fusion method of fast conflict analysis based on formal concept analysis. Firstly, a novel type of three-way concepts is defined to neatly deal with three-valued formal contexts. Then, fast computation of conflict analysis is explored by using an information fusion technique. Specifically, conflict analysis based on horizontal splitting and merging of formal contexts and the one based on vertical splitting and merging of formal contexts are respectively investigated. Finally, systematic experiments are carried out on both synthetic data sets and real cases to evaluate the performance of the proposed method. According to the experimental results, conflict analysis based on vertical splitting and merging of formal contexts can effectively improve the performance, which may not be realized by using the horizontal splitting and merging strategy in some cases. This study may shed light on formal concept analysis based multi-source big data analysis.
ER  - 

TY  - JOUR
T1  - Air traffic controllers' mental fatigue recognition: A multi-sensor information fusion-based deep learning approach
AU  - Yu, Xiaoqing
AU  - Chen, Chun-Hsien
AU  - Yang, Haohan
JO  - Advanced Engineering Informatics
VL  - 57
SP  - 102123
PY  - 2023
DA  - 2023/08/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2023.102123
UR  - https://www.sciencedirect.com/science/article/pii/S1474034623002513
KW  - Air traffic management
KW  - Fatigue detection
KW  - Multi-modal information fusion
KW  - Human-automation collaboration
KW  - Intelligent ATC
AB  - With the growing density of air passenger traffic, accurately recognizing the level of mental fatigue (MF) experienced by air traffic controllers (ATCOs) is crucial for developing intelligent ATCOs' mental state monitoring systems, which can achieve a more effective and safer human–machine cooperative pattern. However, the existing methods for recognizing ATCOs' MF face significant challenges due to pattern variations between ATCOs and sensor artifacts. This study introduces a framework for ATCOs' MF recognition, utilizing a deep neural network called RecMF, which incorporates multi-sensor information fusion to enhance the performance of MF detection. Specifically, the RecMF employs an attention-enabled CNN-LSTM architecture that simultaneously captures time-series feature representations of electroencephalogram (EEG) signals and eye movements. To validate the effectiveness of RecMF, a fatigue-inducing experiment is conducted involving 28 subjects who are tasked with performing a series of air traffic control (ATC) tasks. The model's performance is evaluated across various time horizons and typical cognitive tasks to gain insights into its capabilities. The evaluation results indicate that the proposed model outperforms other existing methods, thereby confirming its feasibility and effectiveness. Additionally, the effects of MF on ATCOs' cognitive performance are analyzed using analysis of variance (ANOVA). The results reveal that higher levels of MF significantly reduce ATCOs' reaction speed and operational accuracy.
ER  - 

TY  - CHAP
T1  - Semantic Memory
AU  - Snowden, Julie S.
A2  - Wright, James D.
BT  - International Encyclopedia of the Social & Behavioral Sciences (Second Edition)
PB  - Elsevier
CY  - Oxford
SP  - 572
EP  - 578
PY  - 2015
DA  - 2015/01/01/
SN  - 978-0-08-097087-5
DO  - https://doi.org/10.1016/B978-0-08-097086-8.51059-9
UR  - https://www.sciencedirect.com/science/article/pii/B9780080970868510599
KW  - Amodal
KW  - Anterior temporal lobe
KW  - Brain networks
KW  - Conceptual knowledge
KW  - Distributed representations
KW  - Multimodal
KW  - Object knowledge
KW  - Schema
KW  - Semantic dementia
KW  - Semantic features
KW  - Semantic memory
KW  - Word knowledge
AB  - Semantic memory refers to our conceptual knowledge of the world. Understanding of semantic memory has come from several sources: cognitive studies of healthy individuals, computational modeling, patients with disordered semantic memory due to brain disease, and brain imaging and stimulation. The converging evidence indicates that semantic memory involves distributed brain networks, which, at least in part, are linked to the sensory processes involved in perception, action, and language. Whether there is also representation in amodal format remains an area of contention. Knowledge of the world, beyond word and object meanings, is a challenge for future studies of semantic memory.
ER  - 

TY  - CHAP
T1  - Planning and Design Scenarios for Liveable Cities
AU  - Clements-Croome, Derek
AU  - Marson, Matthew
AU  - Yang, Tong
AU  - Airaksinen, Miimu
A2  - Abraham, Martin A.
BT  - Encyclopedia of Sustainable Technologies (Second Edition)
PB  - Elsevier
CY  - Oxford
SP  - 13
EP  - 30
PY  - 2024
DA  - 2024/01/01/
SN  - 978-0-443-22287-0
DO  - https://doi.org/10.1016/B978-0-323-90386-8.00008-5
UR  - https://www.sciencedirect.com/science/article/pii/B9780323903868000085
KW  - City
KW  - Digital
KW  - Digital cities
KW  - Infrastructure
KW  - Innovation
KW  - Liveability
KW  - Quality of life
KW  - Sustainability
KW  - Sustainability indicators
KW  - Technology
KW  - Urbanity
AB  - As the urban populations increase, we must think more deeply about how to make cities less stressful and more creative for people to live in. Liveability and quality of life are key factors while designing and managing energy, water, pollution, and waste systems which are sustainable for the long term. The rapidly developing digital technologies can help to enable these aims to be achieved. Innovative approaches are proposed with recommendations for achieving these goals cities grow and change, digital technologies will be at the heart of improvement. This paper considers how observed trends will have implications on the digital cities of the future and how digital technologies will empower citizens and enable their cities to become intelligent, liveable, and sustainable.
ER  - 

TY  - JOUR
T1  - Discrete bending forces and their Jacobians
AU  - Tamstorf, Rasmus
AU  - Grinspun, Eitan
JO  - Graphical Models
VL  - 75
IS  - 6
SP  - 362
EP  - 370
PY  - 2013
DA  - 2013/11/01/
SN  - 1524-0703
DO  - https://doi.org/10.1016/j.gmod.2013.07.001
UR  - https://www.sciencedirect.com/science/article/pii/S1524070313000209
KW  - Discrete shells
KW  - Hinge angle Hessian
KW  - Bending force Jacobians
KW  - Dihedral angle
AB  - Computation of bending forces on triangle meshes is required for numerous simulation and geometry processing applications. In particular it is a key component in cloth simulation. A common quantity in many bending models is the hinge angle between two adjacent triangles. This angle is straightforward to compute, and its gradient with respect to vertex positions (required for the forces) is easily found in the literature. However, the Hessian of the bend angle, which is required to compute the associated force Jacobians is not documented in the literature. Force Jacobians are required for efficient numerics (e.g., implicit time stepping, Newton-based energy minimization) and are thus highly desirable. Readily available computations of the force Jacobian, such as those produced by symbolic algebra systems, or by autodifferentiation codes, are expensive to compute and therefore less useful. We present compact, easily reproducible, closed form expressions for the Hessian of the bend angle. Compared to automatic differentiation, we measure up to 7× speedup for the evaluation of the bending forces and their Jacobians.
ER  - 
