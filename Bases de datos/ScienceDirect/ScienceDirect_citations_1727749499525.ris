TY  - JOUR
T1  - How far has the globe gone in achieving One Health? Current evidence and policy implications based on global One Health index
AU  - Zhang, Qiyu
AU  - Liu, Jingshu
AU  - Han, Lefei
AU  - Li, Xinchen
AU  - Zhang, Chensheng
AU  - Guo, Zhaoyu
AU  - Chao, Anqi
AU  - Wang, Chenxi
AU  - Wan, Erya
AU  - Chen, Fumin
AU  - Zhao, Hanqing
AU  - Feng, Jiaxin
AU  - Xue, Jingbo
AU  - Huang, Lulu
AU  - Chen, Jin
AU  - Sun, Zhishan
AU  - Cheng, Zile
AU  - Yin, Jingxian
AU  - He, Zhengze
AU  - Huang, Liangyu
AU  - Wu, Logan
AU  - Fei, Siwei
AU  - Gu, Siyu
AU  - Jiang, Tiange
AU  - Li, Tianyun
AU  - Chen, Weiye
AU  - Zhou, Nan
AU  - Qiang, Ne
AU  - Li, Qin
AU  - He, Runchao
AU  - Zhang, Yi
AU  - Li, Min
AU  - Wang, Xiangcheng
AU  - Kassegne, Kokouvi
AU  - Zhu, Yongzhang
AU  - Xiu, Leshan
AU  - Hu, Qinqin
AU  - Yin, Kun
AU  - Xia, Shang
AU  - Li, Shizhu
AU  - Wang, Zhaojun
AU  - Guo, Xiaokui
AU  - Zhang, Xiaoxi
AU  - Zhou, Xiao-Nong
JO  - Science in One Health
VL  - 3
SP  - 100064
PY  - 2024
DA  - 2024/01/01/
SN  - 2949-7043
DO  - https://doi.org/10.1016/j.soh.2024.100064
UR  - https://www.sciencedirect.com/science/article/pii/S2949704324000039
KW  - Global One Health index (GOHI)
KW  - Zoonotic diseases
KW  - Antimicrobial resistance
KW  - Food security
KW  - Climate change
AB  - Background
In the 21st century, as globalization accelerates and global public health crises occur, the One Health approach, guided by the holistic thinking of human-animal-environment and emphasizing interdisciplinary collaboration to address global health issues, has been strongly advocated by the international community. An immediate requirement exists for the creation of an assessment tool to foster One Health initiatives on both global and national scales.
Methods
Built upon extensive expert consultations and dialogues, this follow-up study enhances the 2022 global One Health index (GOHI) indicator system. The GOHI framework is enriched by covering three indices, e.g. external drivers index (EDI), intrinsic drivers index (IDI), and core drivers index (CDI). The comprehensive indicator system incorporates 13 key indicators, 50 indicators, and 170 sub I-indicators, utilizing a fuzzy analytic hierarchy process to ascertain the weight for each indicator. Weighted and summed, the EDI, IDI, and CDI scores contribute to the computation of the overall GOHI 2022 score. By comparing the ranking and the overall scores among the seven regions and across 160 countries/territories, we have not only derived an overall profile of the GOHI 2022 scores, but also assessed the GOHI framework. We also compared rankings of indicators and sub I-indicators to provide greater clarity on the strengths and weaknesses of each region within the One Health domains.
Results
The GOHI 2022 performance reveals significant disparities between countries/territories ranged from 39.03 to 70.61. The global average score of the GOHI 2022 is 54.82. The average score for EDI, IDI, and CDI are 46.57, 58.01, and 57.25, respectively. In terms of global rankings, countries from North America, Europe and Central Asia, East Asia and Pacific present higher scores. In terms of One Health domains of CDI, the lowest scores are observed in antimicrobial resistance (median: 43.09), followed by food security (median: 53.78), governance (median: 54.77), climate change (median: 64.12) and zoonotic diseases (median: 69.23). Globally, the scores of GOHI vary spatially, with the highest score in North America while lowest in sub-Saharan Africa. In addition, evidence shows associations between the socio–demographic profile of countries/territories and their GOHI performance in certain One Health scenarios.
Conclusion
The objective of GOHI is to guide impactful strategies for enhancing capacity building in One Health. With advanced technology and an annually updated database, intensifying efforts to refine GOHI's data-mining methodologies become imperative. The goal is to offer profound insights into disparities and progressions in practical One Health implementation, particularly in anticipation of future pandemics.
ER  - 

TY  - JOUR
T1  - Formal system interactive failure analysis method based on systems theoretic process analysis model
AU  - Sun, Rui
AU  - Zhong, Deming
AU  - Li, Weigang
JO  - Engineering Failure Analysis
VL  - 106
SP  - 104141
PY  - 2019
DA  - 2019/12/01/
SN  - 1350-6307
DO  - https://doi.org/10.1016/j.engfailanal.2019.08.007
UR  - https://www.sciencedirect.com/science/article/pii/S1350630718314973
KW  - Engine failures
KW  - Aircraft failures
KW  - Failure analysis
AB  - Interactive failures are failures caused by two or more components that often occur in complex systems when the system is modified, upgraded, or simply designed inadequately. However, the official guideline provided, namely, common cause analysis, cannot discover these problems. It cannot establish a complex interactive system model, nor can it provide a unified analysis method for all parts of the system. Another method, systems theoretic process analysis, is limited to the control system. To solve this problem, a method called system theoretic formal analysis method (STFAM) is proposed in this paper. STFAM establishes a system-component-interactive model that provides an abundance of interactive information for failure analysis and presents a unified model to support the analysis of multiple components in the system. It is divided into three steps. First, a hierarchical system structure is built and then transformed into a formalized state machine. Next, the interactive failures are determined and converted into a linear temporal logic or computation tree logic model. Finally, NuSMV is used to verify the model and record the results. To evaluate the proposed method, a practical problem that occurred in full-authority digital engine control, in which in some cases, the valve closes for unknown reasons until the system is reset is presented. An analysis of the issue demonstrates the effectiveness of our method.
ER  - 

TY  - JOUR
T1  - Modeling and fabrication of catalytic converter for emission reduction
AU  - Venkateswarlu, K.
AU  - Kumar, Revuri Ajay
AU  - Krishna, Ram
AU  - Sreenivasan, M.
JO  - Materials Today: Proceedings
VL  - 33
SP  - 1093
EP  - 1099
PY  - 2020
DA  - 2020/01/01/
T2  - International Conference on Future Generation Functional Materials and Research 2020
SN  - 2214-7853
DO  - https://doi.org/10.1016/j.matpr.2020.07.125
UR  - https://www.sciencedirect.com/science/article/pii/S2214785320352159
KW  - Finite element analysis
KW  - Catalytic converter
KW  - CFD analysis
KW  - Thermal analysis
KW  - CO
KW  - HC
KW  - NOx
AB  - Automobiles throughout the world are the primary consumers of fossil fuels, which emit toxic gases when burnt; including HC, CO and NOx. Catalytic converters were developed to detoxify these gases into less harmful gases such as carbon dioxide and H2O.In this paper, the development of a catalytic converter for efficient emission reduction is presented. The results are presented after performing Computational Fluid Dynamics (CFD) on the proposed catalytic converter. In this catalytic converter Two Different materials used they are stainless steel wire mesh and ceramic stones at time and we are conducted tests with catalytic converter at different blended fluids and engine speeds such as methane, ethane and 1700,1900 RPM.3D modeling done by CATIA parametric software And analysis done in ANSYS software.
ER  - 

TY  - JOUR
T1  - Global sensitivity analysis of a CaO/Ca(OH)2 thermochemical energy storage model for parametric effect analysis
AU  - Xiao, Sinan
AU  - Praditia, Timothy
AU  - Oladyshkin, Sergey
AU  - Nowak, Wolfgang
JO  - Applied Energy
VL  - 285
SP  - 116456
PY  - 2021
DA  - 2021/03/01/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2021.116456
UR  - https://www.sciencedirect.com/science/article/pii/S0306261921000222
KW  - Thermochemical energy storage
KW  - Variance-based sensitivity analysis
KW  - Regional sensitivity analysis
KW  - Polynomial chaos expansion
AB  - Simulation models have been widely used for thermochemical energy storage to better understand its behavior and consequently to improve operational control of the device. However, incomplete knowledge of system properties leads to a significant number of uncertain parameters in the simulation models, which in turn cause uncertainties in system predictions. In this work, we perform global sensitivity analysis to identify the effect of uncertain parameters on the outputs of a thermochemical energy storage model, so that we can better understand the predictive uncertainties, proceed with targeted data acquisition or even simplify the corresponding uncertainty quantification. To get reliable sensitivity analysis results, we use both variance-based and regional sensitivity analysis since they focus on different probabilistic features of model outputs. Since the simulation model is computationally expensive, we use model reduction via the (arbitrary) polynomial chaos expansion. Then, to further confirm the results, the regional sensitivity index is also estimated based on the original model with the same given sample set. Based on the results of both sensitivity analysis methods, we can find that there are 8 unimportant parameters among 16 analyzed parameters. Thus, we can focus resources on investigating the important uncertain parameters. Also, we can ignore the uncertainty of unimportant parameters to simplify the corresponding uncertainty quantification.
ER  - 

TY  - JOUR
T1  - Gender norms in high school: Impacts on risky behaviors from adolescence to adulthood
AU  - Rodríguez-Planas, Nuria
AU  - Sanz-de-Galdeano, Anna
AU  - Terskaya, Anastasia
JO  - Journal of Economic Behavior & Organization
VL  - 196
SP  - 429
EP  - 456
PY  - 2022
DA  - 2022/04/01/
SN  - 0167-2681
DO  - https://doi.org/10.1016/j.jebo.2022.01.015
UR  - https://www.sciencedirect.com/science/article/pii/S016726812200021X
KW  - Gender norms
KW  - short-
KW  - medium- and long-run effects
KW  - risky behaviors and labor market outcomes
KW  - Add health
AB  - Engagement in risky behaviors is traditionally more prevalent among males than females, and the gap increases as youths move from adolescence to adulthood. Using the National Longitudinal Study of Adolescent to Adult Health, we identify a causal effect of exposure to high-school grade-mates with mothers who think that important skills for both boys and girls to possess are traditionally masculine ones (such as to think for oneself or work hard) as opposed to traditionally feminine ones (namely, to be well-behaved, popular, or help others) on the gender gap in teenagers’ engagement in risky behaviors. We find that a higher proportion of grade-mates’ mothers with non-traditional or non-stereotypical gender views who believe that independent thinking and working hard matter for either gender is associated with a reduction of the gender gap in risky behaviors both in the short and medium run. These results are driven by males curbing risky behaviors, suggesting that the relaxation of gender stereotypes results in boys behaving “more like girls”. In the long run, being exposed to grade-mates whose mothers have non-stereotypical gender beliefs reduces the gender gap in labor market outcomes by improving women's performance. This evidence, together with our exploration of several potential mechanisms, suggests that the transmission of gender norms is driving our results.
ER  - 

TY  - JOUR
T1  - Spreadsheets for assisting Transport Phenomena Laboratory experiences
AU  - Stammitti, Aurelio
JO  - Education for Chemical Engineers
VL  - 8
IS  - 2
SP  - e58
EP  - e71
PY  - 2013
DA  - 2013/04/01/
SN  - 1749-7728
DO  - https://doi.org/10.1016/j.ece.2013.02.005
UR  - https://www.sciencedirect.com/science/article/pii/S1749772813000067
KW  - Educational spreadsheets
KW  - Transport Phenomena Laboratory
KW  - Laboratory experience quality
KW  - Data processing task
KW  - Hands-on learning
KW  - Student analytical thinking
AB  - Academic laboratories have been traditionally used for complementing and reinforcing in a practical way the theoretical instruction received in classroom lectures. However, data processing and model evaluation tasks are time consuming and do not add much value to the student's learning experience as they reduce available time for result analysis, critical thinking and report writing skills development. Therefore, this project addressed this issue by selecting three experiences of the Transport Phenomena Laboratory, namely: metallic bar temperature profiles, transient heat conduction and fixed and fluidised bed behaviour, and developed a spreadsheet for each one of them. These spreadsheets, without demanding programming skills, easily process experimental data sets, evaluate complex analytical and numerical models and correlations, not formerly considered and, convey results in tables and plots. Chemical engineering students that tested the spreadsheets were surveyed and expressed the added value of the sheets, being user-friendly, helped them to fulfil lab objectives by reducing their workload and, allowed them to complete deeper analyses that instructors could not request before, as they were able to quickly evaluate, compare and validate different model assumptions and correlations. Students also provided valuable suggestions for improving the spreadsheet experience. Through these sheets, students’ lab learning experience was updated.
ER  - 

TY  - JOUR
T1  - Making sense of the modularity debate
AU  - Egeland, Jonathan
JO  - New Ideas in Psychology
VL  - 75
SP  - 101108
PY  - 2024
DA  - 2024/12/01/
SN  - 0732-118X
DO  - https://doi.org/10.1016/j.newideapsych.2024.101108
UR  - https://www.sciencedirect.com/science/article/pii/S0732118X24000369
KW  - Cognition
KW  - Evolutionary psychology
KW  - Modularity
KW  - Levels of analysis
KW  - Scientific explanation
AB  - For several decades scientists and philosophers studying how the mind works have debated the issue of modularity. Their main disagreements concern the massive modularity hypothesis, according to which all (or most) of our cognitive mechanisms are modular in nature. Pietraszewski and Wertz (2022) have recently suggested that the modularity debate is based on a confusion about the levels of analysis at which the mind can be explained. This article argues that their position suffers from three major problems: (1) the argument is unsound, with untrue premises; (2) it glosses over important empirical issues; and (3) the guidelines it offers are not sufficient for avoiding future confusions. As these criticisms are developed, this article will provide a way of making sense of the modularity debate—with an eye for what really is at stake both conceptually and empirically—and, by identifying a false assumption often shared by proponents and opponents of the massive modularity hypothesis alike, it will sketch out some guidelines for moving the debate forward.
ER  - 

TY  - JOUR
T1  - From viewsheds to viewscapes: Trends in landscape visibility and visual quality research
AU  - Inglis, Nicole C.
AU  - Vukomanovic, Jelena
AU  - Costanza, Jennifer
AU  - Singh, Kunwar K.
JO  - Landscape and Urban Planning
VL  - 224
SP  - 104424
PY  - 2022
DA  - 2022/08/01/
SN  - 0169-2046
DO  - https://doi.org/10.1016/j.landurbplan.2022.104424
UR  - https://www.sciencedirect.com/science/article/pii/S0169204622000731
KW  - GIS
KW  - Landscape aesthetics
KW  - Landscape visibility
KW  - Line-of-sight
KW  - Visual assessment
AB  - The study of visibility and visual quality (VVQ) spans scientific disciplines, methods, frameworks and eras. Recent advances in line-of-sight computation and geographic information systems (GIS) have propelled VVQ research into the realm of high performance computing via a cache of geospatial tools accessible to a broad range of research disciplines. However, in the disciplines that use VVQ analysis most (archaeology, architecture, geosciences and planning), methods and terminology can vary markedly, which may encumber interdisciplinary progress. A multidisciplinary systematic review of past VVQ research is timely to assess past efforts and effectively advance the field. In this study, we summarize the state of VVQ research in a systematic review of peer-reviewed publications spanning the past two decades. Our search yielded 528 total studies, 176 of which we reviewed in depth. VVQ analysis in peer-reviewed research increased 21-fold in the last 20 years, applied primarily in archaeology and natural resources research. We found that methods, tools and study designs varied across disciplines and scales. Research disproportionately represented the Global North and primarily employed medium resolution bare-earth elevation models, despite their known limitations. We propose a framework for standardized reporting of methods that emphasizes cross-disciplinary collaboration to propel visibility research into the future.
ER  - 

TY  - JOUR
T1  - Dataset of active avoidance in Wistar-Kyoto and Sprague Dawley rats: Experimental data and reinforcement learning model code and output
AU  - Palmieri, John
AU  - Spiegler, Kevin M.
AU  - Pang, Kevin C.H.
AU  - Myers, Catherine E.
JO  - Data in Brief
VL  - 32
SP  - 106074
PY  - 2020
DA  - 2020/10/01/
SN  - 2352-3409
DO  - https://doi.org/10.1016/j.dib.2020.106074
UR  - https://www.sciencedirect.com/science/article/pii/S2352340920309689
KW  - Avoidance learning
KW  - Reinforcement learning
KW  - Neurosciences
KW  - Computational modelling
KW  - Computational biology
KW  - Strain differences
KW  - Wistar Kyoto rat
AB  - Data were collected from 40 Wistar-Kyoto (WKY) and 40 Sprague Dawley (SD) rats during an active escape-avoidance experiment. Footshock could be avoided by pressing a lever during a danger period prior to onset of shock. If avoidance did not occur, a series of footshocks was administered, and the rat could press a lever to escape (terminate shocks). For each animal, data were simplified to the presence or absence of lever press and stimuli in each 12-second time frame. Using the pre-processed dataset, a reinforcement learning (RL) model, based on an actor-critic architecture, was utilized to estimate several different model parameters that best characterized each rat's behaviour during the experiment. Once individual model parameters were determined for all 80 rats, behavioural recovery simulations were run using the RL model with each animal's “best-fit” parameters; the simulated behaviour generated avoidance data (percent of trials avoided during a given experimental session) that could be compared across simulated rats, as is customarily done with empirical data. The datasets representing both the experimental data and the model-generated data can be interpreted in various ways to gain further insight into rat behaviour during avoidance and escape learning. Furthermore, the estimated parameters for each individual rat can be compared across groups. Thus, possible between-strain differences in model parameters can be detected, which might provide insights into strain differences in learning. The software implementing the RL model can also be applied to or serve as a template for other experiments involving acquisition learning. Reference for Co-Submission: K.M. Spiegler, J. Palmieri, K.C.H. Pang, C.E. Myers, A reinforcement-learning model of active avoidance behavior: Differences between Sprague-Dawley and Wistar-Kyoto rats. Behav. Brain Res. (2020 Jun 22[epub ahead of print])  doi: 10.1016/j.bbr.2020.112784
ER  - 

TY  - JOUR
T1  - Synaptic clustering within dendrites: An emerging theory of memory formation
AU  - Kastellakis, George
AU  - Cai, Denise J.
AU  - Mednick, Sara C.
AU  - Silva, Alcino J.
AU  - Poirazi, Panayiota
JO  - Progress in Neurobiology
VL  - 126
SP  - 19
EP  - 35
PY  - 2015
DA  - 2015/03/01/
SN  - 0301-0082
DO  - https://doi.org/10.1016/j.pneurobio.2014.12.002
UR  - https://www.sciencedirect.com/science/article/pii/S0301008214001373
KW  - Plasticity
KW  - Active dendrites
KW  - Associative memory
KW  - Synapse clustering
KW  - Synaptic tagging and capture
AB  - It is generally accepted that complex memories are stored in distributed representations throughout the brain, however the mechanisms underlying these representations are not understood. Here, we review recent findings regarding the subcellular mechanisms implicated in memory formation, which provide evidence for a dendrite-centered theory of memory. Plasticity-related phenomena which affect synaptic properties, such as synaptic tagging and capture, synaptic clustering, branch strength potentiation and spinogenesis provide the foundation for a model of memory storage that relies heavily on processes operating at the dendrite level. The emerging picture suggests that clusters of functionally related synapses may serve as key computational and memory storage units in the brain. We discuss both experimental evidence and theoretical models that support this hypothesis and explore its advantages for neuronal function.
ER  - 

TY  - JOUR
T1  - Treatment of Epistemic Uncertainty in Conjunction Analysis with Dempster-Shafer Theory
AU  - Sánchez, Luis
AU  - Vasile, Massimiliano
AU  - Sanvido, Silvia
AU  - Merz, Klaus
AU  - Taillan, Christophe
JO  - Advances in Space Research
PY  - 2024
DA  - 2024/09/12/
SN  - 0273-1177
DO  - https://doi.org/10.1016/j.asr.2024.09.014
UR  - https://www.sciencedirect.com/science/article/pii/S0273117724009347
KW  - Space Traffic Management
KW  - Conjunction Data Message
KW  - Epistemic Uncertainty
KW  - Dempster-Shafer theory of evidence
KW  - Conjunction Assessment
KW  - Decision-making
AB  - The paper presents an approach to the modelling of epistemic uncertainty in Conjunction Data Messages (CDM) and the classification of conjunction events according to the confidence in the probability of collision. The approach proposed in this paper is based on Dempster-Shafer Theory (DSt) of evidence and starts from the assumption that the observed CDMs are drawn from a family of unknown distributions. The Dvoretzky–Kiefer–Wolfowitz (DKW) inequality is used to construct robust bounds on such a family of unknown distributions starting from a time series of CDMs. A DSt structure is then derived from the probability boxes constructed with DKW inequality. The DSt structure encapsulates the uncertainty in the CDMs at every point along the time series and allows the computation of the belief and plausibility in the realisation of a given probability of collision. The methodology proposed in this paper is tested on a number of real events and compared against existing practices in the European and French Space Agencies. We will show that the classification system proposed in this paper is more conservative than the approach taken by the European Space Agency but provides an added quantification of uncertainty in the probability of collision.
ER  - 

TY  - CHAP
T1  - Math Instruction for Children with Special Needs
AU  - Bottge, B.A.
A2  - Peterson, Penelope
A2  - Baker, Eva
A2  - McGaw, Barry
BT  - International Encyclopedia of Education (Third Edition)
PB  - Elsevier
CY  - Oxford
SP  - 767
EP  - 773
PY  - 2010
DA  - 2010/01/01/
SN  - 978-0-08-044894-7
DO  - https://doi.org/10.1016/B978-0-08-044894-7.01126-X
UR  - https://www.sciencedirect.com/science/article/pii/B978008044894701126X
KW  - Cognitive strategy instruction
KW  - Concrete-to-representations-to-abstract (CRA) sequence
KW  - Curriculum-based assessment
KW  - Enhanced anchored instruction
KW  - K-12 math instruction
KW  - Learning disabilities
KW  - Meta-cognition
KW  - Schema-based instruction
AB  - Students with learning disabilities in math (denoted MD) display difficulties in developing conceptual understanding of number, in computation, and in formulating correct strategies for solving problems. Often, these students have concomitant reading difficulty, which severely limits their understanding of text-based problems. While explicit instruction of basic computation skills remains important, a greater emphasis is placed on the ability to solve problems, especially as a growing number of students with MD are included in general education classrooms. This article summarizes a small sample and brief descriptions of instructional interventions that hold promise for educating students with MD.
ER  - 

TY  - JOUR
T1  - Cognitive-inspired Computing: Advances and Novel Applications
AU  - Zhu, Rongbo
AU  - Liu, Lu
AU  - Ma, Maode
AU  - Li, Hongxiang
JO  - Future Generation Computer Systems
VL  - 109
SP  - 706
EP  - 709
PY  - 2020
DA  - 2020/08/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2020.03.017
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X20308384
KW  - Cognitive-inspired computing
KW  - Systems
KW  - Intelligent health analysis
KW  - Security and privacy
KW  - Novel applications
AB  - Cognition is emerging as a new and promising methodology with the development of cognitive-inspired computing and interaction systems, which enables a large class of applications and has emerged with a significance to change our life. However, recent advances on artificial intelligence (AI), edge computing, big data, and cognitive computational theory show that multidisciplinary cognitive-inspired computing still struggles with fundamental, long-standing problems, such as computational models and decision-making mechanisms based on the neurobiological processes of the brain, cognitive sciences, and psychology. How to enhance human cognitive performance with machine learning (ML), common sense, intelligent interaction, privacy security and novel applications is worth exploring. The objective of this special issue is to report high-quality state-of-the-art research contributions that address these key aspects of cognitive-inspired computing and novel applications. By presenting a selection of papers on various topics related to cognitive-inspired computing and applications, we hope to shed light on the multiple aspects of this emerging multidisciplinary paradigm. The papers included in this issue propose solutions for cognitive-inspired systems, AI-assisted computing, intelligent health analysis, security and privacy issues, as well as novel applications.
ER  - 

TY  - JOUR
T1  - Consciousness and working memory: Current trends and research perspectives
AU  - Velichkovsky, Boris B.
JO  - Consciousness and Cognition
VL  - 55
SP  - 35
EP  - 45
PY  - 2017
DA  - 2017/10/01/
SN  - 1053-8100
DO  - https://doi.org/10.1016/j.concog.2017.07.005
UR  - https://www.sciencedirect.com/science/article/pii/S1053810017301654
KW  - Consciousness
KW  - Working memory
KW  - Visual masking
KW  - Attentional blink
KW  - Implicit working memory
AB  - Working memory has long been thought to be closely related to consciousness. However, recent empirical studies show that unconscious content may be maintained within working memory and that complex cognitive computations may be performed on-line. This promotes research on the exact relationships between consciousness and working memory. Current evidence for working memory being a conscious as well as an unconscious process is reviewed. Consciousness is shown to be considered a subset of working memory by major current theories of working memory. Evidence for unconscious elements in working memory is shown to come from visual masking and attentional blink paradigms, and from the studies of implicit working memory. It is concluded that more research is needed to explicate the relationship between consciousness and working memory. Future research directions regarding the relationship between consciousness and working memory are discussed.
ER  - 

TY  - JOUR
T1  - Automated detection of Alzheimer's disease using bi-directional empirical model decomposition
AU  - Koh, Joel En Wei
AU  - Jahmunah, Vicnesh
AU  - Pham, The-Hanh
AU  - Oh, Shu Lih
AU  - Ciaccio, Edward J
AU  - Acharya, U Rajendra
AU  - Yeong, Chai Hong
AU  - Fabell, Mohd Kamil Mohd
AU  - Rahmat, Kartini
AU  - Vijayananthan, Anushya
AU  - Ramli, Norlisah
JO  - Pattern Recognition Letters
VL  - 135
SP  - 106
EP  - 113
PY  - 2020
DA  - 2020/07/01/
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2020.03.014
UR  - https://www.sciencedirect.com/science/article/pii/S0167865520300921
AB  - The build-up of beta-amyloid and rapid spread of tau proteins in the brain cause the death of neurons, leading to Alzheimer's disease (AD). AD is a form of dementia, and the symptoms include memory loss and decision-making difficulties. Current advanced diagnostic modalities are costly or unable to detect the histopathological features of AD. Hence a computational intelligence tool (CIT) for AD diagnosis is proposed in this study. The magnetic resonance images (MRI) of the brain are pre-processed using an adaptive histogram, and decomposed into four IMFS using bidirectional empirical mode decomposition (BEMD). Local binary patterns (LBP) are then computed per IMF, and the histograms are concatenated. Adaptive synthetic sampling (ADASYN) is applied to balance the dataset and Student's t-test is utilized for selection of highly significant features, within each fold for ten-fold validation. Amongst other classifiers, SVM-Poly 1 and random forest(RF) were employed for classification, yielding the highest accuracy of 93.9% each. Our study concludes that the recommended CIT is useful for the automatic classification of AD versus normal MRI imagery in hospitals.
ER  - 

TY  - JOUR
T1  - A comparative study and validation of state estimation algorithms for Li-ion batteries in battery management systems
AU  - Klee Barillas, Joaquín
AU  - Li, Jiahao
AU  - Günther, Clemens
AU  - Danzer, Michael A.
JO  - Applied Energy
VL  - 155
SP  - 455
EP  - 462
PY  - 2015
DA  - 2015/10/01/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2015.05.102
UR  - https://www.sciencedirect.com/science/article/pii/S0306261915007357
KW  - Lithium-ion battery
KW  - Battery management system
KW  - State of charge estimation
KW  - Robustness analysis
KW  - Sliding-mode observer
KW  - Kalman-based SOC estimation
AB  - To increase lifetime, safety, and energy usage battery management systems (BMS) for Li-ion batteries have to be capable of estimating the state of charge (SOC) of the battery cells with a very low estimation error. The accurate SOC estimation and the real time reliability are critical issues for a BMS. In general an increasing complexity of the estimation methods leads to higher accuracy. On the other hand it also leads to a higher computational load and may exceed the BMS limitations or increase its costs. An approach to evaluate and verify estimation algorithms is presented as a requisite prior the release of the battery system. The approach consists of an analysis concerning the SOC estimation accuracy, the code properties, complexity, the computation time, and the memory usage. Furthermore, a study for estimation methods is proposed for their evaluation and validation with respect to convergence behavior, parameter sensitivity, initialization error, and performance. In this work, the introduced analysis is demonstrated with four of the most published model-based estimation algorithms including Luenberger observer, sliding-mode observer, Extended Kalman Filter and Sigma-point Kalman Filter. The experiments under dynamic current conditions are used to verify the real time functionality of the BMS. The results show that a simple estimation method like the sliding-mode observer can compete with the Kalman-based methods presenting less computational time and memory usage. Depending on the battery system’s application the estimation algorithm has to be selected to fulfill the specific requirements of the BMS.
ER  - 

TY  - JOUR
T1  - FsQCA in corporate bankruptcy research. An innovative approach in food industry
AU  - Boratyńska, Katarzyna
JO  - Journal of Business Research
VL  - 69
IS  - 11
SP  - 5529
EP  - 5533
PY  - 2016
DA  - 2016/11/01/
SN  - 0148-2963
DO  - https://doi.org/10.1016/j.jbusres.2016.04.166
UR  - https://www.sciencedirect.com/science/article/pii/S0148296316303733
KW  - Complexity theory
KW  - fsQCA
KW  - Corporate bankruptcy
KW  - Food industry
AB  - This study focuses on fsQCA in corporate bankruptcy research. This research aims at revealing how an fsQCA approach can overcome the knowledge gap of current conceptual and methodological attempts to expose corporate bankruptcy's architecture of causalities. The article discusses the economic literature concerning using fsQCA in corporate bankruptcy studies through complexity theory and a critical perspective. The study concentrates on implementing fsQCA and asymmetric thinking to corporate bankruptcy cases in food industry. The research examines the main reasons for corporate bankruptcy, namely: lack of financial liquidity, too high level of liabilities, losses, weak management, and too late recovery actions. The study attempts to build theory from food industry cases.
ER  - 

TY  - JOUR
T1  - In memory of Professor David Alexander Yuen
AU  - Morra, Gabriele
AU  - Tufo, Henry M.
JO  - Earthquake Research Advances
VL  - 4
IS  - 2
SP  - 100291
PY  - 2024
DA  - 2024/04/01/
SN  - 2772-4670
DO  - https://doi.org/10.1016/j.eqrea.2024.100291
UR  - https://www.sciencedirect.com/science/article/pii/S2772467024000174
ER  - 

TY  - CHAP
T1  - Chapter 2 - Visual artistic creativity and the brain
AU  - Heilman, Kenneth M.
AU  - Acosta, Lealani Mae
A2  - Finger, Stanley
A2  - Zaidel, Dahlia W.
A2  - Boller, François
A2  - Bogousslavsky, Julien
BT  - Progress in Brain Research
PB  - Elsevier
VL  - 204
SP  - 19
EP  - 43
PY  - 2013
DA  - 2013/01/01/
T2  - The Fine Arts, Neurology, and Neuroscience
SN  - 0079-6123
DO  - https://doi.org/10.1016/B978-0-444-63287-6.00002-6
UR  - https://www.sciencedirect.com/science/article/pii/B9780444632876000026
KW  - artistic creativity
KW  - hemispheric functions
KW  - visuospatial skills
KW  - creative innovation
KW  - divergent thinking
KW  - imagery
KW  - global and focal attention
AB  - Creativity is the development of a new or novel understanding—insight that leads to the expression of orderly relationships (e.g., finding and revealing the thread that unites). Visual artistic creativity plays an important role in the quality of human lives, and the goal of this chapter is to describe some of the brain mechanisms that may be important in visual artistic creativity. The initial major means of learning how the brain mediates any activity is to understand the anatomy and physiology that may support these processes. A further understanding of specific cognitive activities and behaviors may be gained by studying patients who have diseases of the brain and how these diseases influence these functions. Physiological recording such as electroencephalography and brain imaging techniques such as PET and fMRI have also allowed us to gain a better understanding of the brain mechanisms important in visual creativity. In this chapter, we discuss anatomic and physiological studies, as well as neuropsychological studies of healthy artists and patients with neurological disease that have helped us gain some insight into the brain mechanisms that mediate artistic creativity.
ER  - 

TY  - JOUR
T1  - Quantitative -omic data empowers bottom-up systems biology
AU  - Yurkovich, James T
AU  - Palsson, Bernhard O
JO  - Current Opinion in Biotechnology
VL  - 51
SP  - 130
EP  - 136
PY  - 2018
DA  - 2018/06/01/
T2  - Systems biology • Nanobiotechnology
SN  - 0958-1669
DO  - https://doi.org/10.1016/j.copbio.2018.01.009
UR  - https://www.sciencedirect.com/science/article/pii/S0958166917302276
AB  - The large-scale generation of ‘-omic’ data holds the potential to increase and deepen our understanding of biological phenomena, but the ability to synthesize information and extract knowledge from these data sets still represents a significant challenge. Bottom-up systems biology overcomes this hurdle through the integration of disparate -omic data types, and absolutely quantified experimental measurements allow for direct integration into quantitative, mechanistic models. The human red blood cell has served as a starting point for the application of systems biology approaches and has been the focus of a recent burst of generated quantitative metabolomics and proteomics data. Thus, the red blood cell represents the perfect case study through which to examine our ability to glean knowledge from the integration of multiple disparate data types.
ER  - 

TY  - CHAP
T1  - Chapter 9 - Fuzzy Methods
AU  - Profillidis, V.A.
AU  - Botzoris, G.N.
A2  - Profillidis, V.A.
A2  - Botzoris, G.N.
BT  - Modeling of Transport Demand
PB  - Elsevier
SP  - 383
EP  - 417
PY  - 2019
DA  - 2019/01/01/
SN  - 978-0-12-811513-8
DO  - https://doi.org/10.1016/B978-0-12-811513-8.00009-1
UR  - https://www.sciencedirect.com/science/article/pii/B9780128115138000091
KW  - 4-step model
KW  - Accidents
KW  - Airports
KW  - Crisp
KW  - Fuzzification
KW  - Fuzzy logic
KW  - Fuzzy model
KW  - Fuzzy regression
KW  - Gaussian
KW  - Linear programming
KW  - Membership degree
KW  - Membership function
KW  - Objective function
KW  - Railways
KW  - Traffic
KW  - Transport economics
KW  - Trapezoidal
KW  - Triangular
AB  - This chapter deals with applications of fuzzy methods, which give the ability to study quantitatively problems characterized by ambiguity, imprecision, uncertainty, linguistic variables, and missing or few or no data. The fuzzy method introduces another way of thinking: a statement, instead of being true or false, may be partially true or false. Thus, instead of taking into account the typically used fixed numerical values (such as, e.g., 2.34), the fuzzy method employs a set of plausible values (e.g., around the value 2.34) within a specific domain. Although this approach may look similar to the error of statistical methods, the fuzzy method can tackle situations (such as missing or vague data), for which classic methods are inefficient. The principles of fuzzy numbers, fuzzy sets, and fuzzy logic are presented. The case of symmetric triangular fuzzy numbers is analyzed in detail. Next, linear regression analysis with the use of fuzzy numbers is explained. A detailed application of fuzzy linear regression for a transport demand problem is surveyed analytically. The chapter includes many applications of fuzzy linear regression for the forecast of a variety of transport demand problems: air transport, rail transport, road transport, transport at urban level, and transport economics. Applications of the fuzzy method to other transport problems are explained: route choice, road safety, accident analysis, logistics and routing of freight vehicles, and the optimization of capacity of airports.
ER  - 

TY  - JOUR
T1  - A tribute to D.B. Spalding and his contributions in science and engineering
AU  - Artemov, V.
AU  - Beale, S.B.
AU  - de Vahl Davis, G.
AU  - Escudier, M.P.
AU  - Fueyo, N.
AU  - Launder, B.E.
AU  - Leonardi, E.
AU  - Malin, M.R.
AU  - Minkowycz, W.J.
AU  - Patankar, S.V.
AU  - Pollard, A.
AU  - Rodi, W.
AU  - Runchal, A.
AU  - Vanka, S.P.
JO  - International Journal of Heat and Mass Transfer
VL  - 52
IS  - 17
SP  - 3884
EP  - 3905
PY  - 2009
DA  - 2009/08/01/
T2  - Special Issue Honoring Professor D. Brian Spalding
SN  - 0017-9310
DO  - https://doi.org/10.1016/j.ijheatmasstransfer.2009.03.038
UR  - https://www.sciencedirect.com/science/article/pii/S0017931009002026
KW  - D.B. Spalding
KW  - Fluid dynamics
KW  - Heat transfer
KW  - Mass transfer
KW  - Combustion
AB  - This paper presents a summary of some of the scientific and engineering contributions of Prof. D.B. Spalding up to the present time. Starting from early work on combustion, and his unique work in mass transfer theory, Spalding’s unpublished “unified theory” is described briefly. Subsequent to this, developments in algorithms by the Imperial College group led to the birth of modern computational fluid dynamics, including the well-known SIMPLE algorithm. Developments in combustion, multi-phase flow and turbulence modelling are also described. Finally, a number of academic and industrial applications of computational fluid dynamics and heat transfer applications considered in subsequent years are mentioned.
ER  - 

TY  - JOUR
T1  - RSEAP2: An enhanced version of RSEAP, an RFID based authentication protocol for vehicular cloud computing
AU  - Safkhani, Masoumeh
AU  - Camara, Carmen
AU  - Peris-Lopez, Pedro
AU  - Bagheri, Nasour
JO  - Vehicular Communications
VL  - 28
SP  - 100311
PY  - 2021
DA  - 2021/04/01/
SN  - 2214-2096
DO  - https://doi.org/10.1016/j.vehcom.2020.100311
UR  - https://www.sciencedirect.com/science/article/pii/S2214209620300826
KW  - Vehicular cloud computing
KW  - Authentication
KW  - Elliptic curve based cryptography
KW  - Security analysis
KW  - Tag/reader impersonation
KW  - Distance bounding attacks
AB  - RSEAP is a recently proposed RFID based authentication protocol for vehicular cloud computing whose authors claimed to be secure and efficient. In this article, we challenge these claims. More precisely, we show that RSEAP does not provide the desired security, and it is possible to conduct both tag and reader impersonation attacks efficiently. Besides, despite the use of timestamps, we show how this protocol also suffers from a range of relay attacks. The complexity of any of the proposed attacks is negligible while the success probability is maximum (i.e., the adversary's success probability is ‘1’ since all the proposed attacks are deterministic). To improve the security of RSEAP scheme, we suggest the required patches for fixing the security vulnerabilities mentioned above. We show that the improved protocol, called RSEAP2, is more efficient (computation and communication costs) than the original RSEAP, while provides a higher security level. The security of RSEAP2 is evaluated informally and also formally using the Scyther tool, which is a well-known and automated tool to assess the security of cryptographic protocols. Additionally, we have formally verified the security of the proposed scheme under the Real-or-Random oracle model.
ER  - 

TY  - JOUR
T1  - Adaptive process monitoring via online dictionary learning and its industrial application
AU  - Huang, Keke
AU  - Wu, Yiming
AU  - Long, Cheng
AU  - Ji, Hongquan
AU  - Sun, Bei
AU  - Chen, Xiaofang
AU  - Yang, Chunhua
JO  - ISA Transactions
VL  - 114
SP  - 399
EP  - 412
PY  - 2021
DA  - 2021/08/01/
SN  - 0019-0578
DO  - https://doi.org/10.1016/j.isatra.2020.12.046
UR  - https://www.sciencedirect.com/science/article/pii/S0019057820305656
KW  - Adaptive process monitoring
KW  - Online dictionary learning
KW  - Time-varying process
KW  - Computational complexity
AB  - For industrial processes, one common drawback of conventional process monitoring methods is that they would make an increasing number of false alarms in cases of various factors such as catalyst deactivation, seasonal fluctuation and so forth. To address this issue, the present work proposes an online dictionary learning method, which can fulfill the process monitoring and fault diagnosis task adaptively. The proposed method would incorporate currently available information to update the dictionary and control limit, instead of keeping a fixed monitoring model. The online dictionary learning method are more superior than conventional methods. Firstly, compared with some traditional offline methods based on small amounts of historical data, the proposed method can augment train data with online dictionary updating, thus it copes with time-varying processes well. Secondly, the proposed method enjoys a lower computational complexity than the offline learning method with mass data, which is appealing in the era of industrial big data. Thirdly, the proposed method performs more reliably than the existing recursive principal component analysis-based methods because it can resolve the anomaly of principal component or non-orthogonality of eigenvectors problem which was often confronted in the recursive principal component analysis-based methods. Finally, some experiments were designed and carried out to demonstrate the advantage of the online dictionary learning.
ER  - 

TY  - JOUR
T1  - Modeling combination therapies in patient cohorts and cell cultures using correlated drug action
AU  - Arun, Adith S.
AU  - Kim, Sung-Cheol
AU  - Ahsen, Mehmet Eren
AU  - Stolovitzky, Gustavo
JO  - iScience
VL  - 27
IS  - 3
SP  - 108905
PY  - 2024
DA  - 2024/03/15/
SN  - 2589-0042
DO  - https://doi.org/10.1016/j.isci.2024.108905
UR  - https://www.sciencedirect.com/science/article/pii/S2589004224001263
KW  - Computational chemistry
KW  - Applied computing
AB  - Summary
Characterizing the effect of combination therapies is vital for treating diseases like cancer. We introduce correlated drug action (CDA), a baseline model for the study of drug combinations in both cell cultures and patient populations, which assumes that the efficacy of drugs in a combination may be correlated. We apply temporal CDA (tCDA) to clinical trial data, and demonstrate the utility of this approach in identifying possible synergistic combinations and others that can be explained in terms of monotherapies. Using MCF7 cell line data, we assess combinations with dose CDA (dCDA), a model that generalizes other proposed models (e.g., Bliss response-additivity, the dose equivalence principle), and introduce Excess over CDA (EOCDA), a new metric for identifying possible synergistic combinations in cell culture.
ER  - 

TY  - JOUR
T1  - Adaptive timing in a dynamic field architecture for natural human–robot interactions
AU  - Wojtak, Weronika
AU  - Ferreira, Flora
AU  - Louro, Luís
AU  - Bicho, Estela
AU  - Erlhagen, Wolfram
JO  - Cognitive Systems Research
VL  - 82
SP  - 101148
PY  - 2023
DA  - 2023/12/01/
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2023.101148
UR  - https://www.sciencedirect.com/science/article/pii/S1389041723000761
KW  - Temporal cognition
KW  - Human–robot interactions
KW  - Neurodynamics
KW  - Adaptation
KW  - Error monitoring
AB  - A close temporal coordination of actions and goals is crucial for natural and fluent human–robot interactions in collaborative tasks. How to endow an autonomous robot with a basic temporal cognition capacity is an open question. In this paper, we present a neurodynamics approach based on the theoretical framework of dynamic neural fields (DNF) which assumes that timing processes are closely integrated with other cognitive computations. The continuous evolution of neural population activity towards an attractor state provides an implicit sensation of the passage of time. Highly flexible sensorimotor timing can be achieved through manipulations of inputs or initial conditions that affect the speed with which the neural trajectory evolves. We test a DNF-based control architecture in an assembly paradigm in which an assistant hands over a series of pieces which the operator uses among others in the assembly process. By watching two experts, the robot first learns the serial order and relative timing of object transfers to subsequently substitute the assistant in the collaborative task. A dynamic adaptation rule exploiting a perceived temporal mismatch between the expected and the realized transfer timing allows the robot to quickly adapt its proactive motor timing to the pace of the operator even when an additional assembly step delays a handover. Moreover, the self-stabilizing properties of the population dynamics support the fast internal simulation of acquired task knowledge allowing the robot to anticipate serial order errors.
ER  - 

TY  - JOUR
T1  - A graph attention network under probabilistic linguistic environment based on Bi-LSTM applied to film classification
AU  - Yu, Bin
AU  - Cai, Ruipeng
AU  - Zhang, Jing
AU  - Fu, Yu
AU  - Xu, Zeshui
JO  - Information Sciences
VL  - 649
SP  - 119632
PY  - 2023
DA  - 2023/11/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2023.119632
UR  - https://www.sciencedirect.com/science/article/pii/S0020025523012173
KW  - Probabilistic linguistic term set
KW  - Bi-LSTM
KW  - Graph attention network
KW  - Film classification
AB  - Film reviews contain rich and complex linguistic information that can reflect the opinions and emotions of the reviewers. However, existing methods for emotion classification of film reviews rely on quantifying qualitative evaluations numerically. This approach can lead to difficulties in interpretation, information loss, and performance degradation under massive data. In this paper, we propose a novel method that utilizes a probabilistic linguistic term set (PLTS) and graph attention network (GAT) to classify films based on their emotional content in long reviews. Firstly, the Bi-directional long short-term memory (Bi-LSTM) method is used to convert film reviews into distributed emotional probabilities. This approach not only captures the emotional information in reviews, but also avoids the limitations of numerical quantification. Secondly, using PLTS to represent emotional information not only considers the relationships of linguistic features but also captures multiple emotional information simultaneously. Finally, we utilize multiple GATs to learn and aggregate the distributed emotional probabilities, enabling our method to fully perceive multiple emotional information in the reviews. Experimental results demonstrate that our method outperforms other models in classification accuracy on the IMDB film review dataset. Our method emulates human thinking to analyze emotional information in reviews and uses a human-like attention mechanism to learn the interrelationship between emotions in film reviews. Therefore, our method exhibits significant improvements in both accuracy and interpretability compared to current models, making it applicable to diverse domains that necessitate the analysis of linguistic data. Overall, the proposed method in this paper presents a novel and effective approach to analyzing and classifying films based on linguistic reviews.
ER  - 

TY  - JOUR
T1  - UK Net Zero policy design and deep uncertainty – The need for an alternative approach
AU  - Rodriguez Mendez, Quirina
AU  - Workman, Mark
AU  - Darch, Geoff
JO  - Environmental Science & Policy
VL  - 151
SP  - 103619
PY  - 2024
DA  - 2024/01/01/
SN  - 1462-9011
DO  - https://doi.org/10.1016/j.envsci.2023.103619
UR  - https://www.sciencedirect.com/science/article/pii/S146290112300268X
KW  - United Kingdom Net Zero target
KW  - Carbon dioxide removal
KW  - Climate modelling
KW  - Integrated assessment modelling
KW  - Robust decision making
KW  - exploratory modelling
AB  - The majority of global emissions scenarios compatible with holding global warming to less than 2 °C depend on the large-scale use of Greenhouse Gas Removal (GGR) technologies. Recent critiques have highlighted the concerns of building long-term climate policy on such speculative technological scenarios emerging from orthodox modelling approaches – including integrated assessment modelling prominently assessed by the IPCC. Through a stakeholder consultation process with the UK modelling and policy community, we critically examine the integration of GGR technologies into UK Net Zero scenarios and the decision-making philosophy underlying the use of orthodox modelling to inform UK climate policy. We identify a number of features of orthodox modelling approaches which are unable to manage the pervasive extent of deep uncertainty in possible UK climate and energy futures. We further argue that a more fundamental issue lies in the way that the models are used by UK climate policy makers: that the handling of uncertainties which pervade the integration of GGR into Net Zero policy are resulting in substantial distortions in net-zero policy design and associated decision-making. Drawing on the principles of decision-making under deep uncertainty techniques, exemplified by Robust Decision Making, we recommend an alternative approach that explicitly embraces uncertainty, multiple values and diversity among stakeholders and viewpoints, and in which modelling exists in an iterative exchange with policy development rather than separate from it. We advocate that such an approach would provide more relevant and robust information to near-term policymaking and enable an inclusive societal dialogue about the appropriate role of GGR within UK climate policy.
ER  - 

TY  - JOUR
T1  - Uncertainty, politics, and technology: Expert perceptions on energy transitions in the United Kingdom
AU  - Li, Francis G.N.
AU  - Pye, Steve
JO  - Energy Research & Social Science
VL  - 37
SP  - 122
EP  - 132
PY  - 2018
DA  - 2018/03/01/
SN  - 2214-6296
DO  - https://doi.org/10.1016/j.erss.2017.10.003
UR  - https://www.sciencedirect.com/science/article/pii/S2214629617303304
KW  - Climate policy
KW  - Energy policy
KW  - Uncertainty analysis
KW  - Decision-making
AB  - Energy policy is beset by deep uncertainties, owing to the scale of future transitions, the long-term timescales for action, and numerous stakeholders. This paper provides insights from semi-structured interviews with 31 UK experts from government, industry, academia, and civil society. Participants were asked for their views on the major uncertainties surrounding the ability of the UK to meet its 2050 climate targets. The research reveals a range of views on the most critical uncertainties, how they can be mitigated, and how the research community can develop approaches to better support strategic decision-making. The study finds that the socio-political dimensions of uncertainty are discussed by experts almost as frequently as technological ones, but that there exist divergent perspectives on the role of government in the transition and whether or not there is a requirement for increased societal engagement. Finally, the study finds that decision-makers require a new approach to uncertainty assessment that overcomes analytical limits to existing practice, is more flexible and adaptable, and which better integrates qualitative narratives with quantitative analysis. Policy design must escape from ‘caged’ thinking concerning what can or cannot be included in models, and therefore what types of uncertainties can or cannot be explored.
ER  - 

TY  - JOUR
T1  - On measuring inconsistency in graph databases with regular path constraints
AU  - Grant, John
AU  - Parisi, Francesco
JO  - Artificial Intelligence
VL  - 335
SP  - 104197
PY  - 2024
DA  - 2024/10/01/
SN  - 0004-3702
DO  - https://doi.org/10.1016/j.artint.2024.104197
UR  - https://www.sciencedirect.com/science/article/pii/S0004370224001334
KW  - Inconsistency measures
KW  - Graph databases
KW  - Computational complexity
AB  - Real-world data are often inconsistent. Although a substantial amount of research has been done on measuring inconsistency, this research concentrated on knowledge bases formalized in propositional logic. Recently, inconsistency measures have been introduced for relational databases. However, nowadays, real-world information is always more frequently represented by graph-based structures which offer a more intuitive conceptualization than relational ones. In this paper, we explore inconsistency measures for graph databases with regular path constraints, a class of integrity constraints based on a well-known navigational language for graph data. In this context, we define several inconsistency measures dealing with specific elements contributing to inconsistency in graph databases. We also define some rationality postulates that are desirable properties for an inconsistency measure for graph databases. We analyze the compliance of each measure with each postulate and find various degrees of satisfaction; in fact, one of the measures satisfies all the postulates. Finally, we investigate the data and combined complexity of the calculation of all the measures as well as the complexity of deciding whether a measure is lower than, equal to, or greater than a given threshold. It turns out that for a majority of the measures these problems are tractable, while for the other different levels of intractability are exhibited.
ER  - 

TY  - JOUR
T1  - A videographic assessment of ferrofluid during magnetic drug targeting: An application of artificial intelligence in nanomedicine
AU  - Sohail, Ayesha
AU  - Fatima, Maryam
AU  - Ellahi, Rahamt
AU  - Akram, Khush Bakhat
JO  - Journal of Molecular Liquids
VL  - 285
SP  - 47
EP  - 57
PY  - 2019
DA  - 2019/07/01/
SN  - 0167-7322
DO  - https://doi.org/10.1016/j.molliq.2019.04.022
UR  - https://www.sciencedirect.com/science/article/pii/S0167732219315399
KW  - Ferrofluids
KW  - Drug targeting
KW  - Artificial intelligence
KW  - Videographic footage
AB  - Forecasting the thresholds via the computational analysis of magnetic drug targeting, is a useful approach since it can help to design the nanoscale experiments to get the best results and efficiency. In such investigations, an artificial intelligence when interlinked with the computational techniques provide better insight specially for rheological problems. In the proposed model mathematical framework for the magnetic drug targeting is adopted while the flow of the ferrofluid, with different concentrations is taken into account. The flow without any obstruction is compared with the flow having obstruction. The nanoscale dynamics sensitive to such obstructions are documented by videographic footage. Nanaoscale approach and the response of the nanomedicine relative to external agents are used. The pressure gradient, the magnetic susceptibility and the velocity profile of the ferrofluid provides useful thresholds to identify the geometry of the obstacle, and to forecast the resulting dynamics.
ER  - 

TY  - JOUR
T1  - Digital learning, face-to-face learning and climate change
AU  - Davies, David Liam
AU  - Lawal, AbdulAzeez
AU  - Orji, Angela E.
AU  - Tytherleigh, Chloe
AU  - Walsh, Kieran
JO  - Future Healthcare Journal
VL  - 11
IS  - 3
SP  - 100156
PY  - 2024
DA  - 2024/09/01/
SN  - 2514-6645
DO  - https://doi.org/10.1016/j.fhj.2024.100156
UR  - https://www.sciencedirect.com/science/article/pii/S2514664524015467
KW  - Digital learning
KW  - Medical education
KW  - Climate change
AB  - Debates about digital learning, face-to-face learning and blended learning often focus on their effectiveness in achieving a few core educational outcomes. The cost or convenience of using different methods to achieve certain outcomes have increasingly come into the educational framework over the past two decades. However, only rarely do educators or learners consider the climate footprint of their various activities. This is an important shortcoming, as all learning activities can contribute to our overall climate footprint. Providers of education should do their best to minimise the carbon footprint associated with their learning. But learners also have responsibility to ensure that how they access learning is also associated with minimal environmental cost. Both providers and learners should focus on activities that are likely to have the greatest impact. This is relevant both to face-to-face education and digital learning.
ER  - 

TY  - JOUR
T1  - Perfect implementation
AU  - Izmalkov, Sergei
AU  - Lepinski, Matt
AU  - Micali, Silvio
JO  - Games and Economic Behavior
VL  - 71
IS  - 1
SP  - 121
EP  - 140
PY  - 2011
DA  - 2011/01/01/
T2  - Special Issue In Honor of John Nash
SN  - 0899-8256
DO  - https://doi.org/10.1016/j.geb.2010.05.003
UR  - https://www.sciencedirect.com/science/article/pii/S0899825610000758
KW  - Mechanism design
KW  - Trust
KW  - Privacy
AB  - Privacy and trust affect our strategic thinking, yet have not been precisely modeled in mechanism design. In settings of incomplete information, traditional implementations of a normal-form mechanism—by disregarding the players' privacy, or assuming trust in a mediator—may fail to reach the mechanism's objectives. We thus investigate implementations of a new type. We put forward the notion of a perfect implementation of a normal-form mechanism M: in essence, a concrete extensive-form mechanism exactly preserving all strategic properties of M, without relying on trusted mediators or violating the players' privacy. We prove that any normal-form mechanism can be perfectly implemented by a verifiable mediator using envelopes and an envelope-randomizing device. Differently from a trusted mediator, a verifiable one only performs prescribed public actions, so that everyone can verify that he is acting properly, and that he never learns any information that should remain private.
ER  - 

TY  - JOUR
T1  - Mental distress through the prism of predictive processing theory
AU  - Van de Cruys, Sander
AU  - Van Dessel, Pieter
JO  - Current Opinion in Psychology
VL  - 41
SP  - 107
EP  - 112
PY  - 2021
DA  - 2021/10/01/
T2  - Psychopathology
SN  - 2352-250X
DO  - https://doi.org/10.1016/j.copsyc.2021.07.006
UR  - https://www.sciencedirect.com/science/article/pii/S2352250X21001056
KW  - Predictive processing
KW  - Mental distress
KW  - Psychopathology
KW  - Emotion
KW  - Depression
KW  - Anxiety
KW  - Active inference
KW  - Addiction
KW  - Learning
KW  - Psychotherapy
KW  - Computational psychiatry
AB  - Summary
We review the predictive processing theory’s take on goals and affect, to shed new light on mental distress and how it develops into psychopathology such as in affective and motivational disorders. This analysis recovers many of the classical factors known to be important in those disorders, like uncertainty and control, but integrates them in a mechanistic model of adaptive and maladaptive cognition and behavior. We derive implications for treatment that have so far remained underexposed in existing predictive processing accounts of mental disorder, specifically with regard to the model-dependent construction of value, the importance of model validation (evidence), and the introduction and learning of new, adaptive beliefs that relieve suffering.
ER  - 

TY  - JOUR
T1  - A recursion-theoretic approach to NP
AU  - Oitavem, I.
JO  - Annals of Pure and Applied Logic
VL  - 162
IS  - 8
SP  - 661
EP  - 666
PY  - 2011
DA  - 2011/08/01/
SN  - 0168-0072
DO  - https://doi.org/10.1016/j.apal.2011.01.010
UR  - https://www.sciencedirect.com/science/article/pii/S016800721100011X
KW  - Computational complexity
KW  - Implicit characterization
KW  - Recursion schemes
KW  - NP
AB  - An implicit characterization of the class NP is given, without using any minimization scheme. This is the first purely recursion-theoretic formulation of NP.
ER  - 

TY  - CHAP
T1  - Chapter 3.2 - Dynamic Knowledge Representation and the Power of Model Making
AU  - Vodovotz, Yoram
AU  - An, Gary
A2  - Vodovotz, Yoram
A2  - An, Gary
BT  - Translational Systems Biology
PB  - Academic Press
CY  - Boston
SP  - 63
EP  - 68
PY  - 2015
DA  - 2015/01/01/
SN  - 978-0-12-397884-4
DO  - https://doi.org/10.1016/B978-0-12-397884-4.00009-4
UR  - https://www.sciencedirect.com/science/article/pii/B9780123978844000094
KW  - Systems biology
KW  - mathematical modeling
KW  - computational biology
KW  - computational modeling
KW  - knowledge representation
KW  - conceptual model
AB  - This chapter focuses on describing the primary tool used in Translational Systems Biology: dynamic computational modeling. This chapter discusses the conceptual basis and rationale for modeling, with particular emphasis on the role of dynamic computational and mathematical models in biomedical research. We introduce the concept of using models as means of Dynamic Knowledge Representation, with the scientific target of facilitating the visualization, instantiation, evaluation, and falsification of biological hypotheses. We compare and contrast the use of modeling and simulation for this purpose versus the development and use of “engineering grade” quantitative models, noting specifically that given the state of biological knowledge, biomedical Dynamic Knowledge Representation is aimed at facilitating discovery, as opposed to the engineering goal of optimizing solutions. We discuss the fundamental step in model construction, mapping, and explain its role in the use and potential interpretation of both biological proxy models and computational models. We introduce the concept of Conceptual Model Verification, and its role as a means of accelerating the Scientific Cycle.
ER  - 

TY  - JOUR
T1  - An efficient method to compute different types of generalized inverses based on linear transformation
AU  - Ma, Jie
AU  - Gao, Feng
AU  - Li, Yongshu
JO  - Applied Mathematics and Computation
VL  - 349
SP  - 367
EP  - 380
PY  - 2019
DA  - 2019/05/15/
SN  - 0096-3003
DO  - https://doi.org/10.1016/j.amc.2018.12.064
UR  - https://www.sciencedirect.com/science/article/pii/S0096300318311251
KW  - Generalized inverse
KW  - Linear transformation
KW  - Rational matrix
KW  - MATHEMATICA
AB  - In this paper, we present functional definitions of all types of generalized inverses related to the {1}-inverse, which is a continuation of the work of Campbell and Meyer (2009). According to these functional definitions, we further derive novel representations for all types of generalized inverses related to the {1}-inverse in terms of the bases for R(A*), N(A) and N(A*). Based on these representations, we present the corresponding algorithm for computing various generalized inverses related to the {1}-inverse of a matrix and analyze the computational complexity of our algorithm for a constant matrix. Finally, we implement our algorithm and several known algorithms for symbolic computation of the Moore-–Penrose inverse in the symbolic computational package MATHEMATICA and compare their running times. Numerical experiments show that our algorithm outperforms these known algorithms when applied to compute the Moore–Penrose inverse of one-variable rational matrices, but is not the best choice for two-variable rational matrices in practice.
ER  - 

TY  - JOUR
T1  - An energy future beyond climate neutrality: Comprehensive evaluations of transition pathways
AU  - Martin, Nick
AU  - Talens-Peiró, Laura
AU  - Villalba-Méndez, Gara
AU  - Nebot-Medina, Rafael
AU  - Madrid-López, Cristina
JO  - Applied Energy
VL  - 331
SP  - 120366
PY  - 2023
DA  - 2023/02/01/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2022.120366
UR  - https://www.sciencedirect.com/science/article/pii/S0306261922016233
KW  - Sustainable energy transition
KW  - Renewable energy
KW  - Energy modelling
KW  - Integrated assessment
KW  - Life cycle assessment
KW  - Critical raw materials
AB  - Many of the long-term policy decisions surrounding the sustainable energy transition rely on models that fail to consider environmental impacts and constraints beyond direct greenhouse gas emissions and land occupation. Such assessments offer incomplete and potentially misleading information about the true sustainability issues of transition pathways. Meanwhile, although decision-makers desire greater access to a broader range of environmental, material and socio-economic indicators, few tools currently address this gap. Here, we introduce ENBIOS, a framework that integrates a broader range of such indicators into energy modelling and policymaking practices. By calculating sustainability-related indicators across hierarchical levels, we reach deeper understandings of the potential energy systems to be derived. With ENBIOS, we analyse a series of energy pathways designed by the Calliope energy system optimization model for the European energy system in 2030 and 2050. Although overall emissions will drop significantly, considerable rises in land, labour and critical raw material requirements are likely. These outcomes are further reflected in unfavourable shifts in key metabolic indicators during this period; energy metabolic rate of the system will drop by 25.6%, land requirement-to-energy will quadruple, while the critical raw material supply risk-to-energy ratio will rise by 74.2%. Heat from biomass and electricity from wind and solar are shown to be the dominant future processes across most indicator categories.
ER  - 

TY  - CHAP
T1  - Gross, Maurice (1934–2001)
AU  - Piot, M.
A2  - Brown, Keith
BT  - Encyclopedia of Language & Linguistics (Second Edition)
PB  - Elsevier
CY  - Oxford
SP  - 163
EP  - 164
PY  - 2006
DA  - 2006/01/01/
SN  - 978-0-08-044854-1
DO  - https://doi.org/10.1016/B0-08-044854-2/05135-X
UR  - https://www.sciencedirect.com/science/article/pii/B008044854205135X
KW  - comparative linguistics
KW  - computational linguistics
KW  - computer dictionaries
KW  - French language
KW  - linguistic theory
KW  - machine translation
KW  - mathematical models
KW  - syntax-based lexicon
AB  - Gross, Maurice (1934–2001) was a pioneer thinker in the field of modern linguistics. Long before computers could facilitate large-scale, lexically-based language study, he built an exhaustive, empirically based inventory of the ‘lexicon-grammar’ of French: the world's first lexical grammar. Since then, researchers in other countries have adopted the Gross model of description, which serves as a computational model for any language.
ER  - 

TY  - JOUR
T1  - Geovisual evaluation of public participation in decision making: The grapevine
AU  - Aguirre, Robert
AU  - Nyerges, Timothy
JO  - Journal of Visual Languages & Computing
VL  - 22
IS  - 4
SP  - 305
EP  - 321
PY  - 2011
DA  - 2011/08/01/
T2  - Part Special Issue on Challenging Problems in Geovisual Analytics
SN  - 1045-926X
DO  - https://doi.org/10.1016/j.jvlc.2010.12.004
UR  - https://www.sciencedirect.com/science/article/pii/S1045926X10000790
KW  - Grapevine
KW  - Geovisual analytics
KW  - Public participation
KW  - Decision making
KW  - Spatio-temporal events
KW  - Human–computer–human interaction
AB  - This article reports on a three-dimensional (time–space) geovisual analytic called a “grapevine.” People often use metaphors to describe the temporal and spatial structure of online discussions, e.g., “threads” growing as a result of message exchanges. We created a visualization to evaluate the temporal and spatial structure of online message exchanges based on the shape of a grapevine naturally cultivated in a vineyard. Our grapevine visualization extends up through time with features like buds, nodes, tendrils, and leaves produced as a result of message posting, replying, and voting. Using a rotatable and fully interactive three-dimensional GIS (Geographic Information System) environment, a geovisual analyst can evaluate the quality of deliberation in the grapevine visualization by looking for productive patterns in fine-grained human–computer–human interaction (HCHI) data and then sub-sampling the productive parts for content analysis. We present an example of how we used the technique in a study of participatory interactions during an online field experiment about improving transportation in the central Puget Sound region of Washington called the Let's Improve Transportation (LIT) Challenge. We conclude with insights about how our grapevine could be applied as a general purpose technique for evaluation of any participatory learning, thinking, or decision making situation.
ER  - 

TY  - JOUR
T1  - Non-negative Tucker decomposition with graph regularization and smooth constraint for clustering
AU  - Liu, Qilong
AU  - Lu, Linzhang
AU  - Chen, Zhen
JO  - Pattern Recognition
VL  - 148
SP  - 110207
PY  - 2024
DA  - 2024/04/01/
SN  - 0031-3203
DO  - https://doi.org/10.1016/j.patcog.2023.110207
UR  - https://www.sciencedirect.com/science/article/pii/S0031320323009044
KW  - Non-negative Tucker decomposition
KW  - Graph regularization
KW  - Randomized algorithm
KW  - Clustering
AB  - Non-negative Tucker decomposition (NTD) and its graph regularized extensions are the most popular techniques for representing high-dimensional non-negative data, which are typically found in a low-dimensional sub-manifold of ambient space, from a geometric perspective. Therefore, the performance of the graph-based NTD methods relies heavily on the low-dimensional representation of the original data. However, most existing approaches treat the last factor matrix in NTD as a low-dimensional representation of the original data. This treatment leads to the loss of the original data’s multi-linear structure in the low-dimensional subspace. To remedy this defect, we propose a novel graph regularized Lp smooth NTD (GSNTD) method for high-dimensional data representation by incorporating graph regularization and an Lp smoothing constraint into NTD. The new graph regularization term constructed by the product of the core tensor and the last factor matrix in NTD, and it is used to uncover hidden semantics while maintaining the intrinsic multi-linear geometric structure of the data. The addition of the Lp smoothing constraint to NTD may produce a more accurate and smoother solution to the optimization problem. The update rules and the convergence of the GSNTD method are proposed. In addition, a randomized variant of the GSNTD algorithm based on fiber sampling is proposed. Finally, the experimental results on four standard image databases show that the proposed method and its randomized variant have better performance than some other state-of-the-art graph-based regularization methods for image clustering.
ER  - 

TY  - JOUR
T1  - Hybrid fuzzy-genetic system for optimising cabled-truss structures
AU  - Finotto, V.C.
AU  - da Silva, W.R.L.
AU  - Valášek, M.
AU  - Štemberk, P.
JO  - Advances in Engineering Software
VL  - 62-63
SP  - 85
EP  - 96
PY  - 2013
DA  - 2013/08/01/
T2  - Special Issue dedicated to Professor Zden ek Bittnar on the occasion of his Seventieth Birthday: Part I
SN  - 0965-9978
DO  - https://doi.org/10.1016/j.advengsoft.2013.04.012
UR  - https://www.sciencedirect.com/science/article/pii/S0965997813000513
KW  - Hybrid system
KW  - Structural optimisation
KW  - Cabled-truss
KW  - Fuzzy logic
KW  - Genetic algorithm
KW  - Nonlinear finite element analysis
AB  - This paper demonstrates an application of a hybrid fuzzy-genetic system in the optimisation of lightweight cabled-truss structures. These structures are described as a system of cables and triangular bar formations jointed at their ends by hinged connections to form a rigid framework. The optimised lightweight structure is determined through a stochastic discrete topology and sizing optimisation procedure that uses ground structure approach, nonlinear finite element analysis, genetic algorithm, and fuzzy logic. The latter is used to include expertise into the evolutionary search with the aim of filtering individuals with low survival possibility, thereby decreasing the total number of evaluations. This is desired because cables, which are inherently nonlinear elements, demand the use of iterative procedures for computing the structural response. Such procedures are computationally costly since the stiffness matrix is evaluated in each iteration until the structure is in equilibrium. Initially, the proposed system is applied to truss benchmarks. Next, the use of cables is investigated and the system’s performance is compared against genetic algorithms. The results indicate that the hybrid system considerably decreased the number of evaluations over genetic algorithms. Also, cabled-trusses showed a significant improvement in structural mass minimisation when compared with trusses.
ER  - 

TY  - JOUR
T1  - Machine learning for battery research
AU  - Wei, Zheng
AU  - He, Qiu
AU  - Zhao, Yan
JO  - Journal of Power Sources
VL  - 549
SP  - 232125
PY  - 2022
DA  - 2022/11/30/
SN  - 0378-7753
DO  - https://doi.org/10.1016/j.jpowsour.2022.232125
UR  - https://www.sciencedirect.com/science/article/pii/S0378775322011028
KW  - Machine learning
KW  - Battery materials
KW  - Battery state prediction
AB  - Batteries are vital energy storage carriers in industry and in our daily life. There is continued interest in the developments of batteries with excellent service performance and safety. Traditional trial-and-error experimental approaches have the limitations of high-cost and low-efficiency. Atomistic computational simulations are relatively expensive and take long time to screen massive materials. The rapid development of machine learning (ML) has brought innovations in many fields and has also changed the paradigm of the battery research. Numerous ML applications have emerged in the battery community, such as novel materials discovery, property prediction, and characterization. In this review, we introduced the workflow of ML, where the task, data, feature engineering, and evaluation were involved. Several typical ML models used in batteries were highlighted. In addition, we summarized the applications of ML for the discovery of novel materials, and for property and battery state prediction. The challenges for the application of ML in batteries were also discussed.
ER  - 

TY  - JOUR
T1  - Training model of practical innovative talents in polytechnic colleges based on fuzzy set and its extended modeling
AU  - Xin, Wang
AU  - Zhengying, Yan
AU  - Sheng, Wang
AU  - Lili, Wang
JO  - Learning and Motivation
VL  - 84
SP  - 101941
PY  - 2023
DA  - 2023/11/01/
SN  - 0023-9690
DO  - https://doi.org/10.1016/j.lmot.2023.101941
UR  - https://www.sciencedirect.com/science/article/pii/S0023969023000723
KW  - Practical and Innovative Talents
KW  - Fuzzy Set
KW  - Fuzzy Comprehensive Evaluation
KW  - Extended Modeling
AB  - Currently, some problems still exist in the cultivation system of innovative and entrepreneurial talents. Therefore, the education department should also continue to carry out practice on the relevant talent training mode, to determine the talent training mode most suitable for the growth of polytechnic colleges. Colleges and universities should take entrepreneurship and innovation ability as the fundamental purpose so that students are not only job seekers, but also creators. The fuzzy set and its extended modelling are crucial for developing students' innovation skills. Therefore, on this basis, this paper proposed a model for cultivating innovative talents with fuzzy sets as the core. The fuzzy comprehensive evaluation (FCE) method is one of the most widely utilized and efficient evaluation methods, which applies to multi-objective evaluation models, thus reflecting the comprehensive and complex nature of the assessment. The ultimate purpose was to derive the decision rules and help the decision-makers make better decisions. The experimental findings of this article showed that there were 3 and 4 students with strong practical ability in Model 1 and Model 2 before the experiment, and there were 8 and 33 students with strong practical ability in Model 1 and Model 2 after the experiment.
ER  - 

TY  - JOUR
T1  - Boosting the performance of SOTA convolution-based networks with dimensionality reduction: An application on hyperspectral images of wine grape berries
AU  - Silva, Rui
AU  - Gramaxo Freitas, Osvaldo
AU  - Melo-Pinto, Pedro
JO  - Intelligent Systems with Applications
VL  - 19
SP  - 200252
PY  - 2023
DA  - 2023/09/01/
SN  - 2667-3053
DO  - https://doi.org/10.1016/j.iswa.2023.200252
UR  - https://www.sciencedirect.com/science/article/pii/S2667305323000777
KW  - Hyperspectral images
KW  - Wine grape berries
KW  - Oenological parameters
KW  - InceptionTime
KW  - OmniScale 1D-CNN
KW  - Dimensionality reduction
AB  - Precision viticulture is an area that is very dependent on methods that allow for a sustainable assessment of grape maturity and, in this work, we apply two state-of-the-art (SOTA) convolution-based networks, namely InceptionTime and OmniScale 1D-CNN, to hyperspectral images of wine grape berries to estimate sugar content. Since attaining generalization capacity and processing the information in such high-dimensional data are the two biggest challenges to overcome in problems of this nature, we also study the impact of two dimensionality reduction techniques, Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE), on the models' performance. Both models underwent different tests with different vintages and varieties of wine grapes in the training/validation steps, as to form a true test to their generalization capacity. Our results show that both PCA and t-SNE succeed in improving the performance of these deep networks when an adequate number of components is chosen that minimizes the ratio between information loss and removing redundant features: additionally, both techniques significantly reduce computational cost, a very important trait when training deep learning models. Both models showed good generalization ability with very competitive results across different varieties and vintages even despite their significant differences in variability, which is an indicator that a relationship between spectras can be found that is reflected on sugar content values.
ER  - 

TY  - JOUR
T1  - Diverse perspectives on interdisciplinarity from Members of the College of the Royal Society of Canada
AU  - Cooke, Steven J.
AU  - Nguyen, Vivian M.
AU  - Anastakis, Dimitry
AU  - Scott, Shannon D.
AU  - Turetsky, Merritt R.
AU  - Amirfazli, Alidad
AU  - Hearn, Alison
AU  - Milton, Cynthia E.
AU  - Loewen, Laura
AU  - Smith, Eric E.
AU  - Norris, D. Ryan
AU  - Lavoie, Kim L.
AU  - Aiken, Alice
AU  - Ansari, Daniel
AU  - Antle, Alissa N.
AU  - Babel, Molly
AU  - Bailey, Jane
AU  - Bernstein, Daniel M.
AU  - Birnbaum, Rachel
AU  - Bourassa, Carrie
AU  - Calcagno, Antonio
AU  - Campana, Aurélie
AU  - Chen, Bing
AU  - Collins, Karen
AU  - Connelly, Catherine E.
AU  - Denov, Myriam
AU  - Dupont, Benoît
AU  - George, Eric
AU  - Gregory-Eaves, Irene
AU  - High, Steven
AU  - Hill, Josephine M.
AU  - Jackson, Philip L.
AU  - Jette, Nathalie
AU  - Jurdjevic, Mark
AU  - Kothari, Anita
AU  - Khairy, Paul
AU  - Lamoureux, Sylvie A.
AU  - Ladner, Kiera
AU  - Landry, Christian R.
AU  - Légaré, François
AU  - Lehoux, Nadia
AU  - Leuprecht, Christian
AU  - Lieverse, Angela R.
AU  - Luczak, Artur
AU  - Mallory, Mark L.
AU  - Manning, Erin
AU  - Mazalek, Ali
AU  - Murray, Stuart J.
AU  - Newman, Lenore L.
AU  - Oosterveld, Valerie
AU  - Potvin, Patrice
AU  - Reimer-Kirkham, Sheryl
AU  - Rowsell, Jennifer
AU  - Stacey, Dawn
AU  - Tighe, Susan L.
AU  - Vocadlo, David J.
AU  - Wilson, Anne E.
AU  - Woolford, Andrew
AU  - Blais, Jules M.
JO  - FACETS
VL  - 5
IS  - 1
SP  - 138
EP  - 165
PY  - 2020
DA  - 2020/02/13/
SN  - 2371-1671
DO  - https://doi.org/10.1139/facets-2019-0044
UR  - https://www.sciencedirect.com/science/article/pii/S2371167120000551
KW  - interdisciplinarity
KW  - academic institutions
KW  - universities
KW  - funding
KW  - scholarly activity
KW  - boundary crossing
KW  - barriers
AB  - Various multiple-disciplinary terms and concepts (although most commonly “interdisciplinarity,” which is used herein) are used to frame education, scholarship, research, and interactions within and outside academia. In principle, the premise of interdisciplinarity may appear to have many strengths; yet, the extent to which interdisciplinarity is embraced by the current generation of academics, the benefits and risks for doing so, and the barriers and facilitators to achieving interdisciplinarity, represent inherent challenges. Much has been written on the topic of interdisciplinarity, but to our knowledge there have been few attempts to consider and present diverse perspectives from scholars, artists, and scientists in a cohesive manner. As a team of 57 members from the Canadian College of New Scholars, Artists, and Scientists of the Royal Society of Canada (the College) who self-identify as being engaged or interested in interdisciplinarity, we provide diverse intellectual, cultural, and social perspectives. The goal of this paper is to share our collective wisdom on this topic with the broader community and to stimulate discourse and debate on the merits and challenges associated with interdisciplinarity. Perhaps the clearest message emerging from this exercise is that working across established boundaries of scholarly communities is rewarding, necessary, and is more likely to result in impact. However, there are barriers that limit the ease with which this can occur (e.g., lack of institutional structures and funding to facilitate cross-disciplinary exploration). Occasionally, there can be significant risk associated with doing interdisciplinary work (e.g., lack of adequate measurement or recognition of work by disciplinary peers). Solving many of the world’s complex and pressing problems (e.g., climate change, sustainable agriculture, the burden of chronic disease, and aging populations) demands thinking and working across long-standing, but in some ways restrictive, academic boundaries. Academic institutions and key support structures, especially funding bodies, will play an important role in helping to realize what is readily apparent to all who contributed to this paper—that interdisciplinarity is essential for solving complex problems; it is the new norm. Failure to empower and encourage those doing this research will serve as a great impediment to training, knowledge, and addressing societal issues.
ER  - 

TY  - JOUR
T1  - When algebra makes you smile: Playful engagement with early algebraic practices
AU  - Brizuela, Bárbara M.
AU  - Strachota, Susanne
JO  - Learning and Instruction
VL  - 92
SP  - 101933
PY  - 2024
DA  - 2024/08/01/
SN  - 0959-4752
DO  - https://doi.org/10.1016/j.learninstruc.2024.101933
UR  - https://www.sciencedirect.com/science/article/pii/S0959475224000604
KW  - Play
KW  - Elementary school
KW  - Epistemic affect
KW  - Early algebraic practices
AB  - Background
The typical competitive and results-driven approach to school mathematics has traditionally been conceived as devoid of play, joy, and positive affect.
Aims
In this paper we address the following questions: What markers of positive affect are observed while students are doing early algebra? Specifically, how are students’ markers of joy related to early algebraic practices? What are the characteristics of playful stances to learning early algebra that are observed when children express positive epistemic affect?
Sample
We analyze three cases in which elementary school students engaged in tasks from an early algebra classroom teaching experiment.
Methods
Drawing from two theoretical frameworks, epistemic affect and early algebra, we conducted microgenetic analyses of lesson transcripts to identify markers of joy and early algebraic practices. We conducted frequency analyses to determine their co-occurrence.
Results
Our results indicate that children expressed joy while engaging in early algebraic practices, evidence of positive epistemic affect. We describe the aspects of each of the cases we present in terms of prior literature on playful stances to learning to further bolster our claims about the relationship between joy and engagement with the early algebraic practices.
Conclusions
We conclude that mathematical learning environments should include open opportunities for students to engage with mathematical content, with multiple entry points and ways to respond. We also conclude that early algebraic practices provide opportunities for playfully engagement and positive epistemic affect.
ER  - 

TY  - JOUR
T1  - A hierarchical alternative updated adaptive Volterra filter with pipelined architecture
AU  - Pang, Yanjie
AU  - Zhang, Jiashu
JO  - Digital Signal Processing
VL  - 56
SP  - 67
EP  - 78
PY  - 2016
DA  - 2016/09/01/
SN  - 1051-2004
DO  - https://doi.org/10.1016/j.dsp.2016.03.004
UR  - https://www.sciencedirect.com/science/article/pii/S1051200416000506
KW  - Nonlinear filter
KW  - Hierarchical pipelined structure
KW  - Alternative update mechanism
KW  - Volterra filter
AB  - The pipelined adaptive Volterra filters (PAVFs) with a two-layer structure constitute a class of good low-complexity filters. They can efficiently reduce the computational complexity of the conventional adaptive Volterra filter. Their major drawbacks are low convergence rate and high steady-state error caused by the coupling effect between the two layers. In order to remove the coupling effect and improve the performance of PAVFs, we present a novel hierarchical pipelined adaptive Volterra filter (HPAVF)-based alternative update mechanism. The HPAVFs with hierarchical decoupled normalized least mean square (HDNLMS) algorithms are derived to adaptively update weights of its nonlinear and linear subsections. The computational complexity of HPAVF is also analyzed. Simulations of nonlinear system adaptive identification, nonlinear channel equalization, and speech prediction show that the proposed HPAVF with different independent weight vectors in nonlinear subsection has superior performance to conventional Volterra filters, diagonally truncated Volterra filters, and PAVFs in terms of initial convergence, steady-state error, and computational complexity.
ER  - 

TY  - JOUR
T1  - Wired for sound: The effect of sound on the epileptic brain
AU  - Maguire, Melissa Jane
JO  - Seizure: European Journal of Epilepsy
VL  - 102
SP  - 22
EP  - 31
PY  - 2022
DA  - 2022/11/01/
SN  - 1059-1311
DO  - https://doi.org/10.1016/j.seizure.2022.09.016
UR  - https://www.sciencedirect.com/science/article/pii/S105913112200214X
KW  - Epilepsy
KW  - Music
KW  - Mozart
KW  - Auditory
KW  - Ultrasound
KW  - Infrasound
AB  - Sound waves are all around us resonating at audible and inaudible frequencies. Our ability to hear is crucial in providing information and enabling interaction with our environment. The human brain generates neural oscillations or brainwaves through synchronised electrical impulses. In epilepsy these brainwaves can change and form rhythmic bursts of abnormal activity outwardly appearing as seizures. When two waveforms meet, they can superimpose onto one another forming constructive, destructive or mixed interference. The effects of audible soundwaves on epileptic brainwaves has been largely explored with music. The Mozart Sonata for Two Pianos in D major, K. 448 has been examined in a number of studies where significant clinical and methodological heterogeneity exists. These studies report variable reductions in seizures and interictal epileptiform discharges. Treatment effects of Mozart Piano Sonata in C Major, K.545 and other composer interventions have been examined with some musical exposures, for example Hayden's Symphony No. 94 appearing pro-epileptic. The underlying anti-epileptic mechanism of Mozart music is currently unknown, but interesting research is moving away from dopamine reward system theories to computational analysis of specific auditory parameters. In the last decade several studies have examined inaudible low intensity focused ultrasound as a neuro-modulatory intervention in focal epilepsy. Whilst acute and chronic epilepsy rodent model studies have consistently demonstrated an anti-epileptic treatment effect this is yet to be reported within large scale human trials. Inaudible infrasound is of concern since at present there are no reported studies on the effects of exposure to infrasound on epilepsy. Understanding the impact of infrasound on epilepsy is critical in an era where sustainable energies are likely to increase exposure.
ER  - 

TY  - JOUR
T1  - Theoretical accounts to practical models: Grounding phenomenon for abstract words in cognitive robots
AU  - Rasheed, Nadia
AU  - Amin, Shamsudin H.M.
AU  - Sultana, U.
AU  - Shakoor, Rabia
AU  - Zareen, Naila
AU  - Bhatti, Abdul Rauf
JO  - Cognitive Systems Research
VL  - 40
SP  - 86
EP  - 98
PY  - 2016
DA  - 2016/12/01/
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2016.05.001
UR  - https://www.sciencedirect.com/science/article/pii/S1389041715300310
KW  - Grounded cognition
KW  - Symbol grounding problem
KW  - Cognitive robotics
KW  - Connectionist computation
AB  - This review concentrates on the issue of acquisition of abstract words in a cognitive robot with the grounding principle, from relevant theories to practical models of agents and robots. Most cognitive robotics models developed for grounding of language take inspiration from the findings of neuroscience and psychology to get the theoretical skeleton of these models. To better understand these modelling approaches, it is indispensable to work from the base (theoretical accounts) to the top (computational models). Therefore in this paper, succinct definition of abstract words is presented first, and then the symbol grounding issue and accounts of grounded cognition for abstract words are given. The next section discusses the computational modelling approaches for abstract words grounding phenomenon. Finally, important cognitive robotics models are reviewed. This paper also points out the strengths and weaknesses of relevant hypotheses and models for the representation of abstract words in the grounded cognition framework and helps the understanding of issues such as where and why modelling efforts stand to address this problem in comparison with theoretical findings.
ER  - 

TY  - JOUR
T1  - Interaction designers’ perceptions of using motion-based full-body features
AU  - Escamilla, Antonio
AU  - Melenchón, Javier
AU  - Monzo, Carlos
AU  - Morán, Jose Antonio
JO  - International Journal of Human-Computer Studies
VL  - 155
SP  - 102697
PY  - 2021
DA  - 2021/11/01/
SN  - 1071-5819
DO  - https://doi.org/10.1016/j.ijhcs.2021.102697
UR  - https://www.sciencedirect.com/science/article/pii/S1071581921001154
KW  - Motion-based feature extraction
KW  - Full-body interaction
KW  - Interaction designers' perception
KW  - Designer-interpretable feature
AB  - Movement-based full-body interactions are increasingly being used in the design of interactive spaces, computer-mediated environments, and virtual user experiences due to the development and availability of diverse sensing technologies. In this context, the role of interaction designers is to find systematic and predictable relationships between bodily actions and the corresponding responses from technology. Sensor-based interaction design relies on sensor data analysis and higher-level feature extraction to improve detection capabilities. However, understanding human movement to inform the design of motion-based interactions is not straightforward if the detection capabilities of interaction technologies are unknown. We aim at understanding the problems and opportunities that practitioners—regardless of their technical background—perceive in using different motion-based full-body features. To achieve this, we conducted four separate focus groups with experienced practitioners, with and without technical backgrounds. We used a framework for the analysis of focus group data in information systems research to identify content areas and draw conclusions. Our findings suggest that most interaction designers, regardless of their technical background, consider motion-based feature extraction to be challenging and time-consuming. However, participants acknowledge they might use designer-interpretable features as a potential tool to foster user behavior exploration. Understanding how practitioners link sensor-based interaction design with feature extraction technology is relevant to design computational tools and reduce the technical effort required from designers to characterize the user’s movement.
ER  - 

TY  - JOUR
T1  - A survey of GPT-3 family large language models including ChatGPT and GPT-4
AU  - Kalyan, Katikapalli Subramanyam
JO  - Natural Language Processing Journal
VL  - 6
SP  - 100048
PY  - 2024
DA  - 2024/03/01/
SN  - 2949-7191
DO  - https://doi.org/10.1016/j.nlp.2023.100048
UR  - https://www.sciencedirect.com/science/article/pii/S2949719123000456
KW  - Large language models
KW  - LLMs
KW  - GPT-3
KW  - ChatGPT
KW  - GPT-4
KW  - Transformers
KW  - LLM survey
AB  - Large language models (LLMs) are a special class of pretrained language models (PLMs) obtained by scaling model size, pretraining corpus and computation. LLMs, because of their large size and pretraining on large volumes of text data, exhibit special abilities which allow them to achieve remarkable performances without any task-specific training in many of the natural language processing tasks. The era of LLMs started with OpenAI’s GPT-3 model, and the popularity of LLMs has increased exponentially after the introduction of models like ChatGPT and GPT4. We refer to GPT-3 and its successor OpenAI models, including ChatGPT and GPT4, as GPT-3 family large language models (GLLMs). With the ever-rising popularity of GLLMs, especially in the research community, there is a strong need for a comprehensive survey which summarizes the recent research progress in multiple dimensions and can guide the research community with insightful future research directions. We start the survey paper with foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. We then present a brief overview of GLLMs and discuss the performances of GLLMs in various downstream tasks, specific domains and multiple languages. We also discuss the data labelling and data augmentation abilities of GLLMs, the robustness of GLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with multiple insightful future research directions. To summarize, this comprehensive survey paper will serve as a good resource for both academic and industry people to stay updated with the latest research related to GLLMs.
ER  - 

TY  - JOUR
T1  - Multimodal metaphor detection based on distinguishing concreteness
AU  - Su, Chang
AU  - Chen, Weijie
AU  - Fu, Ze
AU  - Chen, Yijiang
JO  - Neurocomputing
VL  - 429
SP  - 166
EP  - 173
PY  - 2021
DA  - 2021/03/14/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2020.11.051
UR  - https://www.sciencedirect.com/science/article/pii/S0925231220318440
KW  - Metaphor
KW  - Multiple modalities
KW  - Concreteness
KW  - Part of speech
AB  - Metaphors are a common linguistic phenomenon, and metaphor identification plays an essential role in metaphor processing. Most existing metaphor computing techniques use only texts to gain features, but we acquire additional knowledge from other modalities. At present, the multimodal model in the metaphor field is in the exploratory stage, and the few multimodal models available are still relatively crude. We propose a multimodal metaphor detection method according to the idea that different types of words are suitable for different modality calculations. First, our proposed framework uses a fine-grained concreteness calculation method based on part of speech to distinguish abstract and concrete words. We then choose a different appropriate modal feature and a different metaphor computational method for words with different concreteness. Additionally, we also improve the use of image features in the field of metaphor detection.
ER  - 

TY  - JOUR
T1  - A fast time-domain boundary element method for three-dimensional electromagnetic scattering problems
AU  - Takahashi, Toru
JO  - Journal of Computational Physics
VL  - 482
SP  - 112053
PY  - 2023
DA  - 2023/06/01/
SN  - 0021-9991
DO  - https://doi.org/10.1016/j.jcp.2023.112053
UR  - https://www.sciencedirect.com/science/article/pii/S0021999123001481
KW  - Electromagnetic scattering
KW  - Combined field integral equation
KW  - Marching-on-in-time scheme
KW  - Boundary element method
KW  - Fast multipole method
KW  - Interpolation
AB  - This paper proposes a fast time-domain boundary element method (TDBEM) to solve three-dimensional transient electromagnetic scattering problems regarding perfectly electric conductors in the classical marching-on-in-time manner. The algorithm of the fast TDBEM is a time-domain variant of the interpolation-based fast multipole method (IFMM), which is similar to the time-domain IFMM for acoustic scattering problems investigated in the author's previous studies. The principle of the present IFMM is to interpolate the kernel functions of the electric and magnetic field integral equations (EFIE and MFIE, respectively) so that every kernel function is expressed in a form of separation of variables in terms of both the spatial and temporal variables. Such an expression enables to construct a fast method to evaluate the scalar and vector potentials in the EFIE and MFIE with using so-called multipole-moments and local-coefficients associated with a space-time hierarchy. As opposed to O(Ns2Nt) of the conventional TDBEM, the computational complexity of the fast TDBEM is estimated as O(Ns1+δNt), where Ns and Nt stand for the spatial and temporal degrees of freedom, respectively, and δ is typically 1/2 or 1/3. The numerical examples presented the advantages of the proposed fast TDBEM over the conventional TDBEM when solving large-scale problems.
ER  - 

TY  - JOUR
T1  - Anonymous data collection scheme for cloud-aided mobile edge networks
AU  - Wang, Anxi
AU  - Shen, Jian
AU  - Wang, Chen
AU  - Yang, Huijie
AU  - Liu, Dengzhi
JO  - Digital Communications and Networks
VL  - 6
IS  - 2
SP  - 223
EP  - 228
PY  - 2020
DA  - 2020/05/01/
SN  - 2352-8648
DO  - https://doi.org/10.1016/j.dcan.2019.04.001
UR  - https://www.sciencedirect.com/science/article/pii/S2352864819300574
KW  - Cloud-aided mobile edge networks
KW  - Anonymous data collection
KW  - Communication model
KW  - Path selection
AB  - With the rapid spread of smart sensors, data collection is becoming more and more important in Mobile Edge Networks (MENs). The collected data can be used in many applications based on the analysis results of these data by cloud computing. Nowadays, data collection schemes have been widely studied by researchers. However, most of the researches take the amount of collected data into consideration without thinking about the problem of privacy leakage of the collected data. In this paper, we propose an energy-efficient and anonymous data collection scheme for MENs to keep a balance between energy consumption and data privacy, in which the privacy information of senors is hidden during data communication. In addition, the residual energy of nodes is taken into consideration in this scheme in particular when it comes to the selection of the relay node. The security analysis shows that no privacy information of the source node and relay node is leaked to attackers. Moreover, the simulation results demonstrate that the proposed scheme is better than other schemes in aspects of lifetime and energy consumption. At the end of the simulation part, we present a qualitative analysis for the proposed scheme and some conventional protocols. It is noteworthy that the proposed scheme outperforms the existing protocols in terms of the above indicators.
ER  - 

TY  - JOUR
T1  - Artificial intelligence for carbon emissions using system of systems theory
AU  - Gaur, Loveleen
AU  - Afaq, Anam
AU  - Arora, Gursimar Kaur
AU  - Khan, Nabeel
JO  - Ecological Informatics
VL  - 76
SP  - 102165
PY  - 2023
DA  - 2023/09/01/
SN  - 1574-9541
DO  - https://doi.org/10.1016/j.ecoinf.2023.102165
UR  - https://www.sciencedirect.com/science/article/pii/S1574954123001942
KW  - Artificial intelligence, machine learning
KW  - Carbon emission
KW  - System of systems theory
KW  - Sustainability
KW  - Carbon footprint
AB  - The impact of artificial intelligence (AI) on the environment is the subject of discourse, with arguments for both positive and negative effects. There is a fine line between AI for good and AI for environmental degradation. Today, companies want to seize the benefits of AI, which distinctively involves reducing the company's carbon footprint. However, AI's carbon emissions differ as per the techniques involved in training it. As the saying goes, a coin always has two sides. Therefore, it cannot be denied that AI can be an effective tool for combating climate change, but its role in contributing to carbon emissions cannot be ignored. Multiple studies indicate that AI could be the game-changer in staving off anthropogenic climatic changes due to the deterioration of the environment and global warming. This double-edged relationship and interdependency of AI and carbon emissions are represented through a system of systems (SoS) approach. SoS states that a plan is created through multiple smaller systems, creating complexity in the design and vice versa. A complex system can be assumed as the world in general, where two individual independent systems AI and carbon emissions, when in interaction, create a complex complementary and contradictory relation, adding to the convolution of the system. This connection is demonstrated by conducting a network analysis and calculating the carbon emissions of six machine learning (ML) algorithms and deep learning (DL) models with different datasets but the same hyperparameters on a carbon emission calculator created through AI algorithms. The primary idea of this study is to encourage the AI society to create efficient AI models that may be used without compromising environmental issues. The focus should be on practicing sustainable AI, that is, sustainability from data collection to model deployment, throughout the lifecycle of AI.
ER  - 

TY  - JOUR
T1  - Activation energy process in hybrid CNTs and induced magnetic slip flow with heat source/sink
AU  - Ramesh, G.K.
AU  - Madhukesh, J.K.
JO  - Chinese Journal of Physics
VL  - 73
SP  - 375
EP  - 390
PY  - 2021
DA  - 2021/10/01/
SN  - 0577-9073
DO  - https://doi.org/10.1016/j.cjph.2021.07.016
UR  - https://www.sciencedirect.com/science/article/pii/S0577907321001696
KW  - Carbon nanotubes
KW  - Slip flow
KW  - Induce magnetic flux
KW  - Activation energy
KW  - Chemical reaction
AB  - Effect of induced magnetic field is critical as a result of much controlled and focused on liquid flow is wanted in numerous modern and clinical procedures for example electromagnetic casting, drug delivery and cooling of nuclear reactors. Hence this investigation explains the behaviour of hybrid carbon nanotubes (CNTs) flow through slipped surface with induced magnetic field. Accumulation of SWCNTs (single wall) and MWCNTs (multi wall) nanomaterial with water base liquid is considered. Thermal performance is analyzed with regular heat source/sink effect. Chemical reaction and activation energy impacts are incorporated in mass equation. Solution of the similarity equations are obtained by adopting RKF45 method. Influence of flow variables are illustrated through graphs and computational values of drag force, Nusselt number and Sherwood number are presented in tables. It is noted that activation energy enhance the concentration field whereas opposite behaviour for reaction rate. Also induce magnetic field boosted with the larger values of magnetic Prandtl number. Furthermore it is observed that hybrid CNTs nanomaterial having higher rate of heating/cooling compare to singular CNTs nanomaterial.
ER  - 

TY  - CHAP
T1  - Chapter Twelve - Perceiving the level of depression from web text
AU  - Bisht, Sankalp Singh
AU  - Shandilya, Herumb
AU  - Gupta, Vaibhav
AU  - Agrawal, Shriyansh
AU  - Jain, Shikha
A2  - Jain, Shikha
A2  - Pandey, Kavita
A2  - Jain, Princi
A2  - Seng, Kah Phooi
BT  - Artificial Intelligence, Machine Learning, and Mental Health in Pandemics
PB  - Academic Press
SP  - 277
EP  - 298
PY  - 2022
DA  - 2022/01/01/
SN  - 978-0-323-91196-2
DO  - https://doi.org/10.1016/B978-0-323-91196-2.00008-9
UR  - https://www.sciencedirect.com/science/article/pii/B9780323911962000089
KW  - Depression
KW  - Loneliness
KW  - Mental disorder
KW  - Solitude
KW  - Suicide
AB  - Depression is one of the deadliest diseases found in today's world, and unfortunately, it is also one of the most ignored problems. Depression is a fact that is very hard to accept for any individual and is always a multistep process. The initial stage of Depression is Loneliness, and thus the information about these emotions can be leveraged and can help in the early detection of Depression, which in turn leads to suicidal thoughts. Tweet data analysis is one of the most popular ways to determine the presence of depression and suicidal thoughts, through the concepts of Machine Learning. Twitter proves to be a very rich source of data, as their user base is potentially large enough, but is also increasing in a fast manner. For the scope of this paper, we predicted from a user's specific tweet, which is categorized for loneliness. These tweets are analyzed to check the level of depression as moderate or severe when people start thinking of suicide. The simulation is carried out using four different models for one level of classification and eight models are used at the second level of classification. It is observed that Gated Recurrent Unit with BERT outperformed all the models and showed the accuracy of 99% and 97%. However, for class-1 recall with XLNet gave the best result with class-1 recall being 0.99. This application can help the individual in early detection of depression without any human intervention and seek medical help. Moreover, it also provides an insight about the feelings of the individual to the medical practitioners, which, in turn, can help them provide better decision-making.
ER  - 

TY  - JOUR
T1  - Clinical Applications of Stochastic Dynamic Models of the Brain, Part II: A Review
AU  - Roberts, James A.
AU  - Friston, Karl J.
AU  - Breakspear, Michael
JO  - Biological Psychiatry: Cognitive Neuroscience and Neuroimaging
VL  - 2
IS  - 3
SP  - 225
EP  - 234
PY  - 2017
DA  - 2017/04/01/
SN  - 2451-9022
DO  - https://doi.org/10.1016/j.bpsc.2016.12.009
UR  - https://www.sciencedirect.com/science/article/pii/S2451902217300149
KW  - Computational neuroscience
KW  - Computational psychiatry
KW  - Epilepsy
KW  - Mathematical modeling
KW  - Melancholia
KW  - Stochastic
AB  - Brain activity derives from intrinsic dynamics (due to neurophysiology and anatomical connectivity) in concert with stochastic effects that arise from sensory fluctuations, brainstem discharges, and random microscopic states such as thermal noise. The dynamic evolution of systems composed of both dynamic and random fluctuations can be studied with stochastic dynamic models (SDMs). This article, Part II of a two-part series, reviews applications of SDMs to large-scale neural systems in health and disease. Stochastic models have already elucidated a number of pathophysiological phenomena, such as epilepsy and hypoxic ischemic encephalopathy, although their use in biological psychiatry remains rather nascent. Emerging research in this field includes phenomenological models of mood fluctuations in bipolar disorder and biophysical models of functional imaging data in psychotic and affective disorders. Together with deeper theoretical considerations, this work suggests that SDMs will play a unique and influential role in computational psychiatry, unifying empirical observations with models of perception and behavior.
ER  - 

TY  - JOUR
T1  - Learning abstract visual concepts via probabilistic program induction in a Language of Thought
AU  - Overlan, Matthew C.
AU  - Jacobs, Robert A.
AU  - Piantadosi, Steven T.
JO  - Cognition
VL  - 168
SP  - 320
EP  - 334
PY  - 2017
DA  - 2017/11/01/
SN  - 0010-0277
DO  - https://doi.org/10.1016/j.cognition.2017.07.005
UR  - https://www.sciencedirect.com/science/article/pii/S0010027717302020
KW  - Concept learning
KW  - Visual learning
KW  - Language of Thought
KW  - Computational modeling
KW  - Behavioral experiment
AB  - The ability to learn abstract concepts is a powerful component of human cognition. It has been argued that variable binding is the key element enabling this ability, but the computational aspects of variable binding remain poorly understood. Here, we address this shortcoming by formalizing the Hierarchical Language of Thought (HLOT) model of rule learning. Given a set of data items, the model uses Bayesian inference to infer a probability distribution over stochastic programs that implement variable binding. Because the model makes use of symbolic variables as well as Bayesian inference and programs with stochastic primitives, it combines many of the advantages of both symbolic and statistical approaches to cognitive modeling. To evaluate the model, we conducted an experiment in which human subjects viewed training items and then judged which test items belong to the same concept as the training items. We found that the HLOT model provides a close match to human generalization patterns, significantly outperforming two variants of the Generalized Context Model, one variant based on string similarity and the other based on visual similarity using features from a deep convolutional neural network. Additional results suggest that variable binding happens automatically, implying that binding operations do not add complexity to peoples’ hypothesized rules. Overall, this work demonstrates that a cognitive model combining symbolic variables with Bayesian inference and stochastic program primitives provides a new perspective for understanding people’s patterns of generalization.
ER  - 

TY  - JOUR
T1  - Low-cost Electric Bus Stability Enhancement Scheme Based on Fuzzy Torque Vectoring Differentials: Design and Hardware-in-the-loop Test
AU  - Zhu, Shaopeng
AU  - Huang, Xiaoyan
AU  - Jiang, Dezhi
AU  - Wu, Zhiqiang
JO  - IFAC-PapersOnLine
VL  - 54
IS  - 10
SP  - 500
EP  - 507
PY  - 2021
DA  - 2021/01/01/
T2  - 6th IFAC Conference on Engine Powertrain Control, Simulation and Modeling E-COSM 2021
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2021.10.212
UR  - https://www.sciencedirect.com/science/article/pii/S2405896321016141
KW  - torque vectoring
KW  - lateral stability
KW  - electric bus
KW  - differential control
KW  - fuzzy logic;Kalman filte
AB  - In this paper, a fuzzy torque vectoring differential controller is proposed to improve the lateral stability for the two-motor-wheel drive electric buses with low sensor cost and computational cost. In order to know the unmeasured sideslip angle, unscented Kalman filter algorithm is used to accurately estimate the sideslip angle based on a nonlinear electric bus model and the measured yaw rate and lateral acceleration signals. Given the advantages of high computational efficiency and human’s heuristic knowledge, fuzzy rules are newly designed to control the torque vectoring differentials, and thereby to provide an extra yaw moment on the electric bus body to compensate the driver steering aiming at stability enhancement. To validate the effectiveness and efficiency of the proposed fuzzy torque vectoring differential controller, hardware-in-the-loop tests were carried out to evaluate the controller performance in real-time under different driving maneuvers and road conditions. The test results indicate that the fuzzy torque vectoring differential controller can significantly improve the handling and path-following accuracy for the two-motor-wheel drive electric buses.
ER  - 

TY  - JOUR
T1  - Coactivations of barrel and piriform cortices induce their mutual synapse innervations and recruit associative memory cells
AU  - Gao, Zilong
AU  - Wu, Ruixiang
AU  - Chen, Changfeng
AU  - Wen, Bo
AU  - Liu, Yahui
AU  - Lu, Wei
AU  - Chen, Na
AU  - Feng, Jing
AU  - Fan, Ruichen
AU  - Wang, Dangui
AU  - Cui, Shan
AU  - Wang, Jin-Hui
JO  - Brain Research
VL  - 1721
SP  - 146333
PY  - 2019
DA  - 2019/10/15/
SN  - 0006-8993
DO  - https://doi.org/10.1016/j.brainres.2019.146333
UR  - https://www.sciencedirect.com/science/article/pii/S0006899319303877
KW  - Associative learning
KW  - Memory cell
KW  - Neural circuit
KW  - Barrel cortex
KW  - Piriform cortex
AB  - After associative learning, a signal induces the recall of its associated signal, or the other way around. This reciprocal retrieval of associated signals is essential for associative thinking and logical reasoning. For the cellular mechanism underlying this associative memory, we hypothesized that the formation of synapse innervations among coactivated sensory cortices and the recruitment of associative memory cells were involved in the integrative storage and reciprocal retrieval of associated signals. Our study indicated that the paired whisker and olfaction stimulations led to an odorant-induced whisker motion and a whisker-induced olfaction response, a reciprocal form of associative memory retrieval. In mice that showed the reciprocal retrieval of associated signals, their barrel and piriform cortical neurons became mutually innervated through their axon projection and new synapse formation. These piriform and barrel cortical neurons gained the ability to encode both whisker and olfaction signals based on synapse innervations from the innate input and the newly formed input. Therefore, the associated activation of sensory cortices by pairing input signals initiates their mutual synapse innervations, and the neurons innervated by new and innate synapses are recruited to be associative memory cells that encode these associated signals. Mutual synapse innervations among sensory cortices to recruit associative memory cells may compose the primary foundation for the integrative storage and reciprocal retrieval of associated signals. Our study also reveals that new synapses onto the neurons enable these neurons to encode memories to new specific signals.
ER  - 

TY  - JOUR
T1  - A review of Agent-Based Modelling of technology diffusion with special reference to residential energy efficiency
AU  - Moglia, Magnus
AU  - Cook, Stephen
AU  - McGregor, James
JO  - Sustainable Cities and Society
VL  - 31
SP  - 173
EP  - 182
PY  - 2017
DA  - 2017/05/01/
SN  - 2210-6707
DO  - https://doi.org/10.1016/j.scs.2017.03.006
UR  - https://www.sciencedirect.com/science/article/pii/S2210670716306813
KW  - Agent-Based Modelling
KW  - Diffusion of innovation
KW  - HVAC
KW  - Lighting
KW  - Appliances
AB  - Residential energy efficiency is an important strategy for reducing greenhouse gas emissions. There are many technologies that help improve residential energy efficiency, and in fact, increased energy efficiency has already helped reduce global greenhouse gas emissions significantly in the past. However, with greater innovation, further improvements can be made and improving energy efficiency is an ongoing activity. Policymakers around the world are putting strategies in place to speed up the adoption of energy efficient technologies and practices, but ultimately this process is based on choice by residents themselves. Human decision making and choice however is a very complex issue, and complex computational tools are required in order to analyse and/or predict the impact of various policies. Traditionally, equation-based models such as Bass and Choice models have been used to describe the diffusion of technologies in a population, but certain limitations have been identified. This article explores what these limitations are in the context of energy efficient residential technologies and how an alternative computational and empirical paradigm, Agent-Based Modelling (ABM), can help resolve some of these limitations. As such, this is a review article into how ABM can support analysis of strategies to catalyse greater uptake of energy efficiency in the residential sector.
ER  - 

TY  - JOUR
T1  - Advancing the dialogue between inner and outer empiricism: A comment on O’Nualláin
AU  - Hogan, Michael J.
JO  - New Ideas in Psychology
VL  - 26
IS  - 1
SP  - 55
EP  - 68
PY  - 2008
DA  - 2008/03/01/
SN  - 0732-118X
DO  - https://doi.org/10.1016/j.newideapsych.2007.04.001
UR  - https://www.sciencedirect.com/science/article/pii/S0732118X07000293
KW  - Consciousness
KW  - Inner empiricism
KW  - Outer empiricism
KW  - Evolution
KW  - No-mind
KW  - Mythos
KW  - Logos
AB  - In a recent contribution to New Ideas in Psychology, Seán O’Nualláin draws out a distinction between inner and outer empiricism, and suggests that consciousness research can benefit from analysis in both directions, that is, via the exploration of facts and relations that facilitate a third-person understanding of consciousness (by reference to an analysis of the structures, processes, and functions of the brain) and via the direct exploration of conscious experience itself, both in terms of its computational (content filled) and non-computational (content empty) aspects. In positing a substrate of subjectivity independent of the contents of consciousness (and, more specifically, a state of “nothingness”), Ò’Nualláin follows a long tradition deeply rooted in mythical, religious, and esoteric schools of belief and practice. Although there is considerable debate amongst philosophers, psychologists, and neuroscientists as to whether or not a non-computational view of consciousness is viable, O’Nualláin accepts that such a possibility does exist. Further, he suggests that a dialogue between the inner and outer empiricists will be fruitful. In this comment I, critique Ò’Nualláin's initial thoughts on the subject and draw out a series of useful distinctions that will help to advance the dialogue between inner and outer empiricism. Critical amongst these distinctions is explicit reference to (1) ontological and epistemological interdependencies in consciousness research, and (2) states of consciousness that describe the transition from “mindfulness” through “nothingness” to “no-mind”.
ER  - 

TY  - JOUR
T1  - Heavy metals detection at chemometrics-powered electrochemical (bio)sensors
AU  - Tarapoulouzi, Maria
AU  - Ortone, Vincenzo
AU  - Cinti, Stefano
JO  - Talanta
VL  - 244
SP  - 123410
PY  - 2022
DA  - 2022/07/01/
SN  - 0039-9140
DO  - https://doi.org/10.1016/j.talanta.2022.123410
UR  - https://www.sciencedirect.com/science/article/pii/S0039914022002065
KW  - Multivariate analysis
KW  - Design of experiment
KW  - Artificial intelligence
KW  - Electroanalysis
KW  - Sensors
KW  - Heavy metals
AB  - Heavy metals represent a serious issue regarding both environmental and health status. Their monitoring is necessary and it is necessary the development of decentralized approaches that are able to enforce the risk assessment. Electrochemical sensors and biosensors, with the various architectures, represent a solid reality often involved for this type of analytical determination. Although these approaches offer easy-to-use and portable tools, some limitations are often highlighted in presence of multi-targets and/or real matrices. However, chemometrics- and artificial intelligence-based tools, both for designing and for data analyzing, display the capability in producing novel functionality towards the management of complex matrices which often contain more information than those that are visualized with sensor detection. Design of experiment, exploratory, predictive and regression analysis can push the world of electrochemical (bio)sensors beyond the state of the art, because is still too large the number of analytical chemists that do not deal with multivariate thinking. In this paper, the use of multivariate methods applied to electrochemical sensing of heavy metals is showed, and each approach is described in terms of efficacy and outputs.
ER  - 

TY  - JOUR
T1  - Future research recommendations for transforming higher education with generative AI
AU  - Chiu, Thomas K.F.
JO  - Computers and Education: Artificial Intelligence
VL  - 6
SP  - 100197
PY  - 2024
DA  - 2024/06/01/
SN  - 2666-920X
DO  - https://doi.org/10.1016/j.caeai.2023.100197
UR  - https://www.sciencedirect.com/science/article/pii/S2666920X23000760
KW  - Generative artificial intelligence
KW  - ChatGPT
KW  - Learning outcomes
KW  - AI literacy
KW  - Assessment
AB  - Higher education is crucial for producing ethical citizens and professionals globally. The introduction of generative AI (GenAI), such as ChatGPT, has posed opportunities and challenges to the traditional model of education. However, the current conversations primarily focus on policy development and assessment, with limited research on the future of higher education. GenAI's impact on learning outcomes, pedagogy, and assessment is crucial for reforming and advancing the workforce. This qualitative study aims to investigate student perspectives on GenAI's impact on higher education. The study uses an initial conceptual framework driven by a systematic literature review to investigate the opportunities and challenges of AI in education. This framework serves as an initial data collection and analysis framework. A sample of 51 students from three research-intensive universities was selected for this study. Thematic analysis identified three themes and 10 subthemes. The findings suggest that future higher education should be transformed to train students to be future-ready for employment in a society powered by GenAI. They suggest new learning outcomes—skills in learning and teaching with GenAI, AI literacy—and emphasize the significance of interdisciplinarity and maker learning, with assessment focusing on in-class and hands-on activities. They recommend six future research directions – competence for future workforce and its self-assessment measures, AI literacy or competency measures, new literacies and their relationships, interdisciplinary teaching, Innovative pedagogies and their evaluation, new assessment and its acceptance.
ER  - 

TY  - JOUR
T1  - Mesoscopic Simulation Models for Logistics Planning Tasks in the Automotive Industry
AU  - Lang, Sebastian
AU  - Reggelin, Tobias
AU  - Wunder, Toralf
JO  - Procedia Engineering
VL  - 178
SP  - 298
EP  - 307
PY  - 2017
DA  - 2017/01/01/
T2  - RelStat-2016: Proceedings of the 16th International Scientific Conference Reliability and Statistics in Transportation and Communication October 19-22, 2016. Transport and Telecommunication Institute, Riga, Latvia
SN  - 1877-7058
DO  - https://doi.org/10.1016/j.proeng.2017.01.118
UR  - https://www.sciencedirect.com/science/article/pii/S1877705817301182
KW  - automotive industry
KW  - logistics planning
KW  - production planning
KW  - mesoscopic simulation
KW  - discrete-rate simulation
AB  - The paper evaluates mesoscopic simulation models applied to logistics planning tasks in the automotive industry. In terms of level of detail, mesoscopic simulation models fall between object based discrete-event simulation models and flow based continuous simulation models. Mesoscopic models represent logistics flow processes on an aggregated level through piecewise constant flow rates instead of modeling individual flow objects. The results are not obtained by counting individual objects but by using mathematical formulas to calculate the results as continuous quantities in every modeling time step. This leads to a fast model creation and computation. The authors expect that mesoscopic simulation models can help to support decisions on the operational, tactical and strategic level of planning. The paper describes a mesoscopic simulation model of the goods receiving of an assembly plant and compares the simulation results and computation time with a discrete-event model.
ER  - 

TY  - JOUR
T1  - Estimating effective rates of protection in Nigeria's protected cement industry
AU  - Alayande, Folarin
JO  - Scientific African
VL  - 8
SP  - e00436
PY  - 2020
DA  - 2020/07/01/
SN  - 2468-2276
DO  - https://doi.org/10.1016/j.sciaf.2020.e00436
UR  - https://www.sciencedirect.com/science/article/pii/S2468227620301745
KW  - Trade protection
KW  - Effective rate of protection
KW  - Trade policy
KW  - Nigerian cement
AB  - Trade protection for selected products is a key element of smart industrial policy in many developing countries. Understanding quantitative measures of trade protection for industrial and consumer commodities is therefore a key requisite to determining the effectiveness of export-led growth in particular, and overall industrial policy. However, accurate estimates for trade policy incentives provided to industrial products are few and comparable datasets are sparse, with the most recent published country datasets dated as far back as 2012, yet with limited sector indices. This study estimates the effective rate of protection (ERP), a key index of trade protection and industrial policy, for the cement industry, one of the largest manufacturing industries in Nigeria. Time series data for 16 years, on the actual cost of trade protection, including tariff barriers and import prohibition bans, from 2000 to 2015 is used. With the ERP, the true cost of protection of domestic manufactures from imported goods, is computed using input shares and tariff data from the United Nations COMTRADE database. The data show the basis for computation and provides a re-useable template for central planners in the computation of effective rate of protection for similar manufacturing industries and other African countries. The computed ERP for the cement industry in Nigeria show a relatively high protection rate, and the overwhelming impact of trade prohibition on the ERP after the implementation of the Federal Government's incentive-led Backward Integration Programme. The evidence is compared with earlier data on Africa. Preliminary findings and trend analysis indicate a high correlation between the ERP and value added to gross domestic product (GDP).
ER  - 

TY  - JOUR
T1  - The inferior parietal lobule and temporoparietal junction: A network perspective
AU  - Igelström, Kajsa M.
AU  - Graziano, Michael S.A.
JO  - Neuropsychologia
VL  - 105
SP  - 70
EP  - 83
PY  - 2017
DA  - 2017/10/01/
T2  - Special Issue: Concepts, Actions and Objects: Functional and Neural Perspectives
SN  - 0028-3932
DO  - https://doi.org/10.1016/j.neuropsychologia.2017.01.001
UR  - https://www.sciencedirect.com/science/article/pii/S0028393217300015
KW  - Angular gyrus
KW  - Supramarginal gyrus
KW  - Ventral parietal cortex
KW  - Posterior superior temporal sulcus
KW  - Internal cognition
KW  - Frontoparietal executive control network
AB  - Information processing in specialized, spatially distributed brain networks underlies the diversity and complexity of our cognitive and behavioral repertoire. Networks converge at a small number of hubs – highly connected regions that are central for multimodal integration and higher-order cognition. We review one major network hub of the human brain: the inferior parietal lobule and the overlapping temporoparietal junction (IPL/TPJ). The IPL is greatly expanded in humans compared to other primates and matures late in human development, consistent with its importance in higher-order functions. Evidence from neuroimaging studies suggests that the IPL/TPJ participates in a broad range of behaviors and functions, from bottom-up perception to cognitive capacities that are uniquely human. The organization of the IPL/TPJ is challenging to study due to the complex anatomy and high inter-individual variability of this cortical region. In this review we aimed to synthesize findings from anatomical and functional studies of the IPL/TPJ that used neuroimaging at rest and during a wide range of tasks. The first half of the review describes subdivisions of the IPL/TPJ identified using cytoarchitectonics, resting-state functional connectivity analysis and structural connectivity methods. The second half of the article reviews IPL/TPJ activations and network participation in bottom-up attention, lower-order self-perception, undirected thinking, episodic memory and social cognition. The central theme of this review is to discuss how network nodes within the IPL/TPJ are organized and how they participate in human perception and cognition.
ER  - 

TY  - JOUR
T1  - Integrating fourth industrial revolution (4IR) technologies into the water, energy & food nexus for sustainable security: A bibliometric analysis
AU  - David, Love O.
AU  - Nwulu, Nnamdi I.
AU  - Aigbavboa, Clinton O.
AU  - Adepoju, Omoseni O.
JO  - Journal of Cleaner Production
VL  - 363
SP  - 132522
PY  - 2022
DA  - 2022/08/20/
SN  - 0959-6526
DO  - https://doi.org/10.1016/j.jclepro.2022.132522
UR  - https://www.sciencedirect.com/science/article/pii/S0959652622021230
KW  - WEF Nexus
KW  - Fourth industrial revolution
KW  - Industry 4.0
KW  - Cleaner production
KW  - Internet of things (IoT)
AB  - The technologies of the fourth Industrial Revolution (4IR/Industry 4.0) have been a technological catalyst for all fields of human endeavor, permeating the water, energy, and food (WEF) nexus. However, there is no empirical evidence of the extent of applications and the permeability level in ensuring the three resources’ security. This study explored the relationship of the fourth industrial revolution technologies and the water, energy, and food nexus by evaluating the applications of the various technologies of 4IR on WEF nexus and examined the effect of 4IR on WEF nexus. The objectives were achieved using the qualitative methodology and bibliometric analysis of content analysis. The result showed that most fourth industrial revolution technologies had not been integrated with the WEF nexus. The result showed that only the Internet of Things (IoT) and Big Data analytics had permeated the nexus, which shows that data of the resources will be the foundation of the nexus. The systematic collection, accuracy of data, and empirical analysis of data will determine the level of security of WEF nexus. The qualitative results show that there are applications of the fourth industrial revolution technologies to the individual sectors of the nexus, birthing Water 4.0, Energy 4.0, and Food 4.0. The Bibliometric analysis result shows that the integration of the fourth industrial revolution with the WEF nexus will lead to cleaner production practices relating to the technological processes of water, energy, and food resources. These practices will ensure the environment's safety from WEF wastes and the water, energy, and food security in production processes. The empirical research and bibliometric analysis result, rooted in the concept of cleaner production, shows that the fourth industrial revolution affected the WEF nexus. The effects are; the birth of clean technologies & industrial applications, the catalyst for sustainability security of WEF nexus leveraging on life cycle thinking, enablement of technological transfer, enhancement of economic growth, and urban planning. The study concludes that the fourth industrial revolution technologies affect WEF nexus, ensuring the popularization of cleaner production strategies and processes of the resources during trade-offs and synergies. The study recommends the integration of a cleaner production concept in WEF processing. It should follow the innovation diffusion theory (IDT) and Technology acceptance theory (TAM) when applying 4IR technologies to the nexus of water, energy, and food resources, for their sustainable security.
ER  - 

TY  - JOUR
T1  - Contributions of modularity to the circular economy: A systematic review of literature
AU  - Machado, Natália
AU  - Morioka, Sandra Naomi
JO  - Journal of Building Engineering
VL  - 44
SP  - 103322
PY  - 2021
DA  - 2021/12/01/
SN  - 2352-7102
DO  - https://doi.org/10.1016/j.jobe.2021.103322
UR  - https://www.sciencedirect.com/science/article/pii/S2352710221011803
KW  - Modularity
KW  - Circular economy
KW  - Product modular design
KW  - Module optimization
KW  - Product lifecycle
AB  - In the creation of practices to foster the thinking of the circular economy (CE), modularity can be a facilitator. There are many studies that address modularity and the circular economy individualized, but the integration between the two is still little addressed. This study conducts a systematic review of the literature and aims to identify how modularity can contribute to the circular economy. The data analysis begins with the identification of the main characteristics of the literature that address modularity and circular economy, bringing the evolution of studies over the years, main journals, co-citation of references, co-occurrence of keywords and shows four research clusters linked to modularity and CE, being: conceptualization of modularization, modular design of products, module optimization and product lifecycle. In addition, identifies fifteen benefits of modularity that can contribute to the implementation of strategies for the circular economy and five barriers from the perspective of the circular economy that can inhibit the contribution process. So, it was possible to create an integrative conceptual framework that shows how modularity can contribute to the circular economy. From the results, future research is identified in order to contribute to the transition from a linear economy to a circular economy.
ER  - 

TY  - JOUR
T1  - On fast and accurate block-based motion estimation algorithms using particle swarm optimization
AU  - Cai, Jing
AU  - David Pan, W.
JO  - Information Sciences
VL  - 197
SP  - 53
EP  - 64
PY  - 2012
DA  - 2012/08/15/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2012.02.014
UR  - https://www.sciencedirect.com/science/article/pii/S002002551200117X
KW  - Particle swarm optimization
KW  - Motion estimation
KW  - Fast block-matching methods
KW  - Video sequences
KW  - Computational complexity
AB  - Both fast and accurate block-matching algorithms are critical to efficient compression of video frames using motion estimation and compensation. While the particle swarm optimization approach holds the promise of alleviating the local optima problem suffered typically by existing very fast block matching methods, motion estimation algorithms based on particle swarm optimization in the literature appear to be either much slower than some leading fast block-matching methods for a given accuracy of motion estimation, or less accurate for a given computational complexity. In this paper, we show that the conventional particle swarm optimization approach, which was originally designed to solve general optimization problems where fast convergence of the algorithm might not be a primary concern, could be modified appropriately so that it could provide accurate motion estimation with very low computational cost in the specific context of video motion estimation. To this end, we proposed a new block matching algorithm based on a set of strategies adapted from the standard particle swarm optimization approach. Extensive simulations showed that the proposed method could achieve significant improvements over leading fast block matching methods including the diamond search and the cross-diamond search methods, in terms of both estimation accuracy and computational cost. In particular, the proposed method based on particle swarm optimization is not only much faster, but also remarkably more accurate (about 2dB higher in terms of the Peak Signal-to-Noise-Ratio) than the competing methods on video sequences with large motion.
ER  - 

TY  - JOUR
T1  - Hemispheric asymmetries in processing numerical meaning in arithmetic
AU  - Jang, Selim
AU  - Hyde, Daniel C.
JO  - Neuropsychologia
VL  - 146
SP  - 107524
PY  - 2020
DA  - 2020/09/01/
SN  - 0028-3932
DO  - https://doi.org/10.1016/j.neuropsychologia.2020.107524
UR  - https://www.sciencedirect.com/science/article/pii/S0028393220301974
KW  - Arithmetic
KW  - Numerical cognition
KW  - Cerebral hemispheres
KW  - Late positivity
KW  - Distance effect
AB  - Hemispheric asymmetries in arithmetic have been hypothesized based on neuropsychological, developmental, and neuroimaging work. However, it has been challenging to separate asymmetries related to arithmetic specifically, from those associated general cognitive or linguistic processes. Here we attempt to experimentally isolate the processing of numerical meaning in arithmetic problems from language and memory retrieval by employing novel non-symbolic addition problems, where participants estimated the sum of two dot arrays and judged whether a probe dot array was the correct sum of the first two arrays. Furthermore, we experimentally manipulated which hemisphere receive the probe array first using a visual half-field paradigm while recording event-related potentials (ERP). We find that neural sensitivity to numerical meaning in arithmetic arises under left but not right visual field presentation during early and middle portions of the late positive complex (LPC, 400-800 ms). Furthermore, we find that subsequent accuracy for judgements of whether the probe is the correct sum is better under right visual field presentation than left, suggesting a left hemisphere advantage for integrating information for categorization or decision making related to arithmetic. Finally, neural signatures of operational momentum, or differential sensitivity to whether the probe was greater or less than the sum, occurred at a later portion of the LPC (800-1000 ms) and regardless of visual field of presentation, suggesting a temporal and functional dissociation between magnitude and ordinal processing in arithmetic. Together these results provide novel evidence for differences in timing and hemispheric lateralization for several cognitive processes involved in arithmetic thinking.
ER  - 

TY  - JOUR
T1  - Dynamic hybrid modelling: Switching between AB and SD designs of a predator-prey model
AU  - Wallentin, Gudrun
AU  - Neuwirth, Christian
JO  - Ecological Modelling
VL  - 345
SP  - 165
EP  - 175
PY  - 2017
DA  - 2017/02/10/
SN  - 0304-3800
DO  - https://doi.org/10.1016/j.ecolmodel.2016.11.007
UR  - https://www.sciencedirect.com/science/article/pii/S0304380016303714
KW  - Hybrid model
KW  - Multi-paradigmatic modelling
KW  - Agent-based model
KW  - System-dynamics model
KW  - Predator-prey system
AB  - Entities and processes in complex systems are of diverse nature and operate at various spatial and temporal scales. Hybrid agent-based (AB) and system dynamics (SD) models have been suggested to capture the essence of these systems in a natural and computationally efficient way. However, the integration of the equation-based SD and individual-based AB models is not least challenged by considerable conceptual differences between these models. Examples of tightly integrated and dynamically switching hybrid models are rare. The aim of this paper is to expand on theoretical frameworks of hybrid agent-based and system dynamics models in ecology to support the model design process of dynamically switching hybrid models. We suggested six alternative model designs that switched between the two modelling paradigms. By the example of a fish-plankton lake ecosystem we demonstrated that a well-designed switching hybrid model can be a performant modelling approach that retains relevant spatial and attributive information. Important findings with respect to optimising computational versus predictive performance were (1) the most plausible results were produced by a spatially explicit design based on spatial plankton stocks and fish switching between individual agents and aggregate school-agents, (2) higher levels of aggregation did not necessarily result in higher computational performance, and (3) adaptive, emergence-based triggers for the paradigm switches minimised information loss and could connect hierarchical and spatial scales. In conclusion, we argue to reach beyond efficiency-oriented considerations and use emergent super-individuals as structural elements of dynamically switching hybrid models.
ER  - 

TY  - JOUR
T1  - Functional neuroanatomical correlates of contingency judgement
AU  - Saylik, Rahmi
AU  - Szameitat, Andre J.
AU  - Williams, Adrian L.
AU  - Murphy, Robin A.
JO  - Neuroscience Letters
VL  - 791
SP  - 136915
PY  - 2022
DA  - 2022/11/20/
SN  - 0304-3940
DO  - https://doi.org/10.1016/j.neulet.2022.136915
UR  - https://www.sciencedirect.com/science/article/pii/S0304394022004761
KW  - Contingency learning
KW  - Associative relations
KW  - Shared and diverse areas
KW  - Lateral prefrontal lobe
KW  - Parietal lobe
KW  - fMRI
AB  - Contingency judgement is an ability to detect relationships between events and is crucial in the allocation of attentional resources for reasoning, categorization, and decision making to control behaviour in our environment. Research has suggested that the allocation of attention is sensitive to the frequency of contingency information whether it constitutes a negative, zero or positive relationship. The aim of the present study was to explore the functional neuroanatomical correlates of contingency judgement with different frequencies and whether these are distinct from each other or whether they rely on a common mechanism. Using three contingency tasks within a streaming paradigm (one each for negative, zero, and positive contingency frequencies), we assessed brain activity by means of functional magnetic resonance imaging (fMRI) in 20 participants. Contingency frequency was manipulated between blocks which allowed us to determine the neural correlates of each of the three contingency tasks as well as the common areas of activation. The conjunction of task activation showed activity in left parietal cortices (BA 23, 40) and superior temporal gyrus (BA42). Further, the interaction analysis revealed distinct areas that mainly involve lateral (BA 45) and medial (BA 9) prefrontal cortices in the judgment of negative contingencies compared with positive and zero contingencies. We interpret the finding as evidence that the shared regions may be involved in coding, integration, and updating of associative relations and distinct regions may be involved in the investment of attentional resources to varied degrees in the computation of contingencies to make a judgment.
ER  - 

TY  - JOUR
T1  - Fisher’s pioneering work on discriminant analysis and its impact on Artificial Intelligence
AU  - Mardia, Kanti V.
JO  - Journal of Multivariate Analysis
VL  - 203
SP  - 105341
PY  - 2024
DA  - 2024/09/01/
SN  - 0047-259X
DO  - https://doi.org/10.1016/j.jmva.2024.105341
UR  - https://www.sciencedirect.com/science/article/pii/S0047259X24000484
KW  - Canonical variates
KW  - Classification
KW  - Genetic discriminant
KW  - Iris data
KW  - Linear discriminant function
KW  - Machine learning
KW  - Mardia’s measures of skewness and kurtosis
KW  - Visualising multivariate data
AB  - Sir Ronald Aylmer Fisher opened many new areas in Multivariate Analysis, and the one which we will consider is discriminant analysis. Several papers by Fisher and others followed from his seminal paper in 1936 where he coined the name discrimination function. Historically, his four papers on discriminant analysis during 1936–1940 connect to the contemporaneous pioneering work of Hotelling and Mahalanobis. We revisit the famous iris data which Fisher used in his 1936 paper and in particular, test the hypothesis of multivariate normality for the data which he assumed. Fisher constructed his genetic discriminant motivated by this application and we provide a deeper insight into this construction; however, this construction has not been well understood as far as we know. We also indicate how the subject has developed along with the computer revolution, noting newer methods to carry out discriminant analysis, such as kernel classifiers, classification trees, support vector machines, neural networks, and deep learning. Overall, with computational power, the whole subject of Multivariate Analysis has changed its emphasis but the impact of this Fisher’s pioneering work continues as an integral part of supervised learning in Artificial Intelligence (AI).
ER  - 

TY  - JOUR
T1  - An approach to quantitatively measuring collaborative performance in online conversations
AU  - Dwyer, Paul
JO  - Computers in Human Behavior
VL  - 27
IS  - 2
SP  - 1021
EP  - 1032
PY  - 2011
DA  - 2011/03/01/
T2  - Web 2.0 in Travel and Tourism: Empowering and Changing the Role of Travelers
SN  - 0747-5632
DO  - https://doi.org/10.1016/j.chb.2010.12.006
UR  - https://www.sciencedirect.com/science/article/pii/S0747563210003730
KW  - Collaboration
KW  - Cognitive modeling
KW  - Collective thinking
AB  - Interpersonal dynamics often hinder people from optimizing collaboration. Researchers who monitor the intellectual activity of people as they converse online receive less value when such collaboration is impaired. How can they detect suboptimal collaboration? This study builds on a new metric for measuring collaborative value from the information content of participant contributions to propose a measure of collaborative efficiency, and demonstrates its utility by assessing collaboration around a sample of weblogs. The new collaborative value metric can augment qualitative research by highlighting for deeper investigation conversational themes that triggered elevated collaborative production. Identifying these themes may also define the cognitive box people have built within a collaborative venue. Challenging people to consider fresh ideas by deliberately introducing them into collaborative venues is recommended as the key to overcoming collaborative dysfunction.
ER  - 

TY  - JOUR
T1  - Lumping the States of a Finite Markov Chain Through Stochastic Factorization
AU  - Barreto, André M.S.
AU  - Fragoso, Marcelo D.
JO  - IFAC Proceedings Volumes
VL  - 44
IS  - 1
SP  - 4206
EP  - 4211
PY  - 2011
DA  - 2011/01/01/
T2  - 18th IFAC World Congress
SN  - 1474-6670
DO  - https://doi.org/10.3182/20110828-6-IT-1002.00073
UR  - https://www.sciencedirect.com/science/article/pii/S1474667016442680
AB  - Abstract
In this work we show how the lumping of states of a finite Markov chain can be regarded as a special decomposition of its transition matrix called stochastic factorization. The idea is simple: when a transition matrix is factored into the product of two stochastic matrices, one can swap the factors of the multiplication to obtain another model, potentially much smaller than the original one. We prove in the paper that the smaller Markov chain has the same reducibility and the same number of closed sets as the original model. Additionally, the stationary distributions of both chains are related through a linear transformation. By interpreting the lumping of states as a particular case of stochastic factorization, we discuss in which circumstances the lumped transition matrix can be used in place of the original one to compute its stationary distribution. To illustrate our ideas we use the computation of Google's PageRank as an example.
ER  - 

TY  - JOUR
T1  - Between on-site and the clouds: Socio-cyber-physical assemblages in on-farm diversification
AU  - Metta, Matteo
AU  - Dessein, Joost
AU  - Brunori, Gianluca
JO  - Journal of Rural Studies
VL  - 105
SP  - 103193
PY  - 2024
DA  - 2024/01/01/
SN  - 0743-0167
DO  - https://doi.org/10.1016/j.jrurstud.2023.103193
UR  - https://www.sciencedirect.com/science/article/pii/S0743016723002590
KW  - Socio-cyber-physical assemblages
KW  - On-farm diversification
KW  - Digital agriculture
KW  - Responsible digitalisation
AB  - This paper sheds light on the integration of digitalisation in multifunctional and diversified agriculture. In this empirical work based on socio-cyber-physical assemblage thinking, first we found that on-site material and immaterial conditions like living on the farm, farm settings, and creative human work still matter and deserve more attention in responsible digital agriculture. Second, in our small sample we found that internet and cloud-computing are the main digital technologies used in on-farm diversification, particularly infrastructures-as-a-service and software-as-a-service. Third, when farmers introduce digital technologies in their diversification, three tentative configurations of socio-cyber-physical assemblages are outlined and can be further assessed in future research: punctiform, horizontal, and vertical configurations, or a combination thereof. For each configuration, we illustrate key features and examples. Nine clusters of factors were identified as affecting these assemblages. These factors could help researchers and practitioners to understand why the digitalisation of diversified farms can be so diverse and needs to be carefully adapted. For policymakers, these factors can also serve to qualify the setting up of conditions to steer integrated agri-food-rural policies towards on-farm diversification, including responsible digitalisation. The paper argues that digitalisation in agriculture can unfold through different strategies (minimising, mutualising, grounding, enlarging digitalisation) and requires holistic and ambitious policy commitments for sustainability. For example, the paper suggests the setting up of a new EU-wide target for increasing the share of farmers engaged in on-farm diversification through the Common Agricultural Policy or European Farm-to-Fork Strategy.
ER  - 

TY  - JOUR
T1  - Metaphors of knowing, doing and being: Capturing experience in teaching and teacher education
AU  - Craig, Cheryl J.
JO  - Teaching and Teacher Education
VL  - 69
SP  - 300
EP  - 311
PY  - 2018
DA  - 2018/01/01/
SN  - 0742-051X
DO  - https://doi.org/10.1016/j.tate.2017.09.011
UR  - https://www.sciencedirect.com/science/article/pii/S0742051X17301841
KW  - Metaphors
KW  - Teachers' experiences
KW  - Narrative inquiry
KW  - School reform
AB  - In this article, Bateson's idea of human beings thinking with metaphors and learning through stories is examined as it played out within accumulated educational research studies. Five storied metaphors illuminating knowing, doing and being are highlighted from five investigations involving different research teams. In the cross-case analysis, the importance of narrative exemplars emerges, along with the significance of metaphors serving as proxies for teachers' experiences. The plotlines of the metaphors, the morals of the metaphors and the truths of the metaphors are also discussed. In the end result, the value of metaphors in surfacing teachers' embedded, embodied knowledge of experience is affirmed as well as the deftness of the narrative inquiry research method in metaphorically capturing pre-service and inservice teachers' storied experiences.
ER  - 

TY  - JOUR
T1  - Hierarchical community structure preserving approach for network embedding
AU  - Duan, Zhen
AU  - Sun, Xian
AU  - Zhao, Shu
AU  - Chen, Jie
AU  - Zhang, Yanping
AU  - Tang, Jie
JO  - Information Sciences
VL  - 546
SP  - 1084
EP  - 1096
PY  - 2021
DA  - 2021/02/06/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2020.09.053
UR  - https://www.sciencedirect.com/science/article/pii/S0020025520309622
KW  - Network embedding
KW  - Representation learning
KW  - Granulation
KW  - Hierarchical community
AB  - Network embedding aims to map the topological proximities of all nodes in a network into a low-dimensional representation space. Previous studies mainly focus on preserving the within-layer structure of the network (such as first-order proximities, second-order proximities, and community structure). However, many complex networks present a hierarchical organization, often in the form of a hierarchy community structure. How to effectively preserve the within-layer structure and the hierarchical community structure under multi-granularity is a meaningful and still tough task. Inspired by Granular Computing, which is a problem-solving concept deeply rooted in human thinking ability to perceive the real world under multi-granularity, we propose a unified network embedding framework by preserving both the within-layer structure and the hierarchical community structure of the network under multi-granularity, named as Hierarchical Community structure preserving approach for Network Embedding (HCNE). Firstly, different granular networks from fine to coarse are constructed by network granulation which reveals the hierarchical community structure of the original network. Secondly, from coarse to fine, finer networks inherit the embedding of coarse-grained networks as good initialization embedding in the refinement process so that the embedding preserved both the within-layer structure and the hierarchical community structure of the network under multi-granularity. Finally, the learned embedding of each node fed into downstream tasks, including multi-label classification and network visualization. Experimental results demonstrate that HCNE significantly outperforms other state-of-the-art methods. Meanwhile, we intuitively show the effectiveness of HCNE on network visualization which can preserve both the within-layer structure and the hierarchical community structure of the network under multi-granularity.
ER  - 

TY  - JOUR
T1  - Towards next generation digital twin in robotics: Trends, scopes, challenges, and future
AU  - Mazumder, A.
AU  - Sahed, M.F.
AU  - Tasneem, Z.
AU  - Das, P.
AU  - Badal, F.R.
AU  - Ali, M.F.
AU  - Ahamed, M.H.
AU  - Abhi, S.H.
AU  - Sarker, S.K.
AU  - Das, S.K.
AU  - Hasan, M.M.
AU  - Islam, M.M.
AU  - Islam, M.R.
JO  - Heliyon
VL  - 9
IS  - 2
SP  - e13359
PY  - 2023
DA  - 2023/02/01/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2023.e13359
UR  - https://www.sciencedirect.com/science/article/pii/S2405844023005662
KW  - Digital twin
KW  - Cyber-physical system
KW  - Robotics
KW  - Industry 4.0
KW  - Smart manufacturing
KW  - Human-robot interaction
AB  - With the advent of Industry 4.0, several cutting-edge technologies such as cyber-physical systems, digital twins, IoT, robots, big data, cloud computation have emerged. However, how these technologies are interconnected or fused for collaborative and increased functionality is what elevates 4.0 to a grand scale. Among these fusions, the digital twin (DT) in robotics is relatively new but has unrivaled possibilities. In order to move forward with DT-integrated robotics research, a complete evaluation of the literature and the creation of a framework are now required. Given the importance of this research, the paper seeks to explore the trends of DT incorporated robotics in both high and low research saturated robotic domains in order to discover the gap, rising and dying trends, potential scopes, challenges, and viable solutions. Finally, considering the findings, the study proposes a framework based on a hypothesis for the future paradigm of DT incorporated robotics.
ER  - 

TY  - JOUR
T1  - Provably secured lightweight authenticated key agreement protocol for modern health industry
AU  - Abdussami, Mohammad
AU  - Amin, Ruhul
AU  - Vollala, Satyanarayana
JO  - Ad Hoc Networks
VL  - 141
SP  - 103094
PY  - 2023
DA  - 2023/03/15/
SN  - 1570-8705
DO  - https://doi.org/10.1016/j.adhoc.2023.103094
UR  - https://www.sciencedirect.com/science/article/pii/S1570870523000148
KW  - Health care industry
KW  - Authentication
KW  - Key agreement
KW  - Scyther simulation
AB  - Internet of Medical Things (IoMT) has facilitated the healthcare industry by providing ease of communication among doctors and patients living in remote areas for accomplishing diagnosis, real-time monitoring, and treatment procedure efficiently. The patient’s health-related data must be secured from various attacks of adversary since the data is sensitive and highly prone to attacks. This paper proposes an architecture that suits both localized and emergency scenarios. This architecture utilizes cloud server and edge computing technology. Provably secured lightweight authenticated key agreement protocol for modern health industry (PSLA2P) provides a lightweight authentication and key agreement protocol that can be deployed in the proposed network architecture. It protects the privacy of the patient’s health-related data by providing anonymity and untraceability. Real-Or-Random (ROR) model is used for the formal analysis of PSLA2P. We have verified the security weaknesses of PSLA2P using the Scyther simulator. Moreover, the informal analysis ensures high-level mitigation against known possible attacks. PSLA2P achieves better performance in terms of computation and communication overhead.
ER  - 

TY  - JOUR
T1  - Makerspace activities in a school setting: Top-down and bottom-up approaches for teachers to leverage pupils' making in science education
AU  - Mørch, Anders I.
AU  - Flø, Ellen E.
AU  - Litherland, Kristina T.
AU  - Andersen, Renate
JO  - Learning, Culture and Social Interaction
VL  - 39
SP  - 100697
PY  - 2023
DA  - 2023/04/01/
SN  - 2210-6561
DO  - https://doi.org/10.1016/j.lcsi.2023.100697
UR  - https://www.sciencedirect.com/science/article/pii/S2210656123000132
KW  - K-12
KW  - Makerspace
KW  - Programming
KW  - Rising-to-the-concrete
KW  - Sociocultural perspective
KW  - STEM
AB  - This article addresses the opportunities and challenges of turning a science, technology, engineering, and mathematics (STEM) classroom into a makerspace for hands-on experimentation with digital tools and materials in science education. In this qualitative case study, over a period of 16 weeks, video data were collected during making activities in an advanced placement science course with 19 pupils aged 12–16 years, and interviews were conducted. We combined thematic and interaction analyses of empirical data and identified three themes: 1) engagement and spontaneous concepts, 2) programming and making physical objects, and 3) subject integration. Our conceptual framework for the analyses integrated two features of the Vygotskian sociocultural theory of learning: concept development as a dialectical process of scientific and everyday concepts and the “tool and symbol” duality. Our findings show that both top-down and bottom-up approaches to integrating school subjects into a makerspace were effective but underused. We illustrate this by mapping pupils' shared understanding in a sociotechnical space, visualized as a process of “rising to the concrete”, which may require teacher's scaffolding at different levels of abstraction and use of instructional materials in different modalities.
ER  - 

TY  - JOUR
T1  - Detecting leadership in peer-moderated online collaborative learning through text mining and social network analysis
AU  - Xie, Kui
AU  - Di Tosto, Gennaro
AU  - Lu, Lin
AU  - Cho, Young Suk
JO  - The Internet and Higher Education
VL  - 38
SP  - 9
EP  - 17
PY  - 2018
DA  - 2018/07/01/
SN  - 1096-7516
DO  - https://doi.org/10.1016/j.iheduc.2018.04.002
UR  - https://www.sciencedirect.com/science/article/pii/S1096751618300332
KW  - Leadership
KW  - Computer-supported collaborative learning
KW  - Text mining
KW  - Social network analysis
KW  - Learning analytics
KW  - Online learning
AB  - Structured tasks and peer-moderated discussions are pedagogical models that have shown unique benefits for online collaborative learning. Students appointed with leadership roles are able to positively affect the dynamics in their groups by engaging with participants, raising questions, and advancing problem solving. To help monitoring and controlling the latent social dynamics associated with leadership behavior, we propose a methodological approach that makes use of computational techniques to mine the content of online communications and analyze group structure to identify students who behave as leaders. Through text mining and social network analysis, we systematically process the discussion posts made by students from four sections of an online course in an American university. The results allow us to quantify each individual's contribution and summarize their engagement in the form of a leadership index. The proposed methodology, when compared to judgements made by experts who manually coded samples of the data, is shown to have comparable performances, but, being fully automated, has the potential to be easily replicable. The summary offered by the leadership index is intended as actionable information that can guide just-in-time interventions together with other tools based on learning analytics.
ER  - 

TY  - JOUR
T1  - A rapid review on current and potential uses of large language models in nursing
AU  - Hobensack, Mollie
AU  - von Gerich, Hanna
AU  - Vyas, Pankaj
AU  - Withall, Jennifer
AU  - Peltonen, Laura-Maria
AU  - Block, Lorraine J.
AU  - Davies, Shauna
AU  - Chan, Ryan
AU  - Van Bulck, Liesbet
AU  - Cho, Hwayoung
AU  - Paquin, Robert
AU  - Mitchell, James
AU  - Topaz, Maxim
AU  - Song, Jiyoun
JO  - International Journal of Nursing Studies
VL  - 154
SP  - 104753
PY  - 2024
DA  - 2024/06/01/
SN  - 0020-7489
DO  - https://doi.org/10.1016/j.ijnurstu.2024.104753
UR  - https://www.sciencedirect.com/science/article/pii/S0020748924000658
KW  - Rapid review
KW  - Nursing informatics
KW  - Large language models
KW  - Generative AI
KW  - ChatGPT
AB  - Background
The application of large language models across commercial and consumer contexts has grown exponentially in recent years. However, a gap exists in the literature on how large language models can support nursing practice, education, and research. This study aimed to synthesize the existing literature on current and potential uses of large language models across the nursing profession.
Methods
A rapid review of the literature, guided by Cochrane rapid review methodology and PRISMA reporting standards, was conducted. An expert health librarian assisted in developing broad inclusion criteria to account for the emerging nature of literature related to large language models. Three electronic databases (i.e., PubMed, CINAHL, and Embase) were searched to identify relevant literature in August 2023. Articles that discussed the development, use, and application of large language models within nursing were included for analysis.
Results
The literature search identified a total of 2028 articles that met the inclusion criteria. After systematically reviewing abstracts, titles, and full texts, 30 articles were included in the final analysis. Nearly all (93 %; n = 28) of the included articles used ChatGPT as an example, and subsequently discussed the use and value of large language models in nursing education (47 %; n = 14), clinical practice (40 %; n = 12), and research (10 %; n = 3). While the most common assessment of large language models was conducted by human evaluation (26.7 %; n = 8), this analysis also identified common limitations of large language models in nursing, including lack of systematic evaluation, as well as other ethical and legal considerations.
Discussion
This is the first review to summarize contemporary literature on current and potential uses of large language models in nursing practice, education, and research. Although there are significant opportunities to apply large language models, the use and adoption of these models within nursing have elicited a series of challenges, such as ethical issues related to bias, misuse, and plagiarism.
Conclusion
Given the relative novelty of large language models, ongoing efforts to develop and implement meaningful assessments, evaluations, standards, and guidelines for applying large language models in nursing are recommended to ensure appropriate, accurate, and safe use. Future research along with clinical and educational partnerships is needed to enhance understanding and application of large language models in nursing and healthcare.
ER  - 

TY  - JOUR
T1  - Dynamic response analysis of a typical time-varying mass system: A moving-interface pipe model, the WKB-recursive solution and experimental validation
AU  - Chen, Weiting
AU  - Chen, Guoping
AU  - Chen, Tengfei
AU  - Tan, Xing
AU  - Shao, Hanbo
AU  - He, Huan
JO  - Applied Mathematical Modelling
VL  - 125
SP  - 147
EP  - 166
PY  - 2024
DA  - 2024/01/01/
SN  - 0307-904X
DO  - https://doi.org/10.1016/j.apm.2023.08.044
UR  - https://www.sciencedirect.com/science/article/pii/S0307904X23003979
KW  - Time-varying system
KW  - Moving-interface model
KW  - The WKB-recursive method
KW  - Experimental validation
AB  - This research aims to seek a suitable way for analyzing the time-varying characteristics of some engineering phenomena such as the fuel consumption of flying rockets, the movement process of control rods used to regulate the reaction rate in nuclear reactors, etc. To address this problem, a simulated procedure containing modeling and response solving is proposed. A common variable cross-section pipeline with time-varying mass is designed as a practical time-varying system. A simplified segmented beam model with a moving interface is proposed to simulate the pipe's time-varying behavior. Then the Wentzel-Kramers-Brillouin (WKB)-recursive method is proposed to solve this time-varying problem. A two-segmented beam example is used to verify its computability. The computational efficiency is greatly improved in comparison with the conventional numerical integration methods. To validate this proposed procedure, numerical simulation is carried out and an experiment is specially designed and implemented. In the experiment, many cases of different rates of mass variation and excitation forces are carried out. Overall, the numerical dynamic responses match well with the experimental ones, which indicates that the proposed procedure is suitable for analyzing the system's time-varying characteristics.
ER  - 

TY  - JOUR
T1  - Approach of artificial intelligence for analysing properties of concrete
AU  - Mohit, 
AU  - Lallotra, Balwinder
JO  - Materials Today: Proceedings
VL  - 48
SP  - 1713
EP  - 1717
PY  - 2022
DA  - 2022/01/01/
T2  - SCPINM-2021
SN  - 2214-7853
DO  - https://doi.org/10.1016/j.matpr.2021.10.028
UR  - https://www.sciencedirect.com/science/article/pii/S221478532106507X
KW  - Concrete
KW  - Artificial intelligence
KW  - Artificial neural network
KW  - Workability
KW  - Compressive strength
AB  - Technological progress is often measured by computation power. At the moment we are in the golden age where we are blessed with a perfect trio, machine learning algorithms, huge datasets across disciplines, and processing hardware. The constant desire to understand the human brain has led us to try mimicking it, thus forming the basis of neural networks creating a way for deep learning algorithms. Such algorithms have proven to work on non-linear data sets effectively, generating results that could find patterns just like our brains. In this paper, we explore a recently rising application for Neural Network frameworks; in particular, concrete in basic designing. We design and implement tests to analyze various properties of concrete of different concrete mixes. Customarily, the ability of concrete to perform is influenced by numerous non-straight factors, and testing its quality includes the destructive procedure of concrete samples.
ER  - 

TY  - JOUR
T1  - On choosing the resolution of normative models
AU  - Merrick, James H.
AU  - Weyant, John P.
JO  - European Journal of Operational Research
VL  - 279
IS  - 2
SP  - 511
EP  - 523
PY  - 2019
DA  - 2019/12/01/
SN  - 0377-2217
DO  - https://doi.org/10.1016/j.ejor.2019.06.017
UR  - https://www.sciencedirect.com/science/article/pii/S0377221719304928
KW  - Problem structuring
KW  - Validation of OR computations
KW  - Information theory
KW  - Strategic planning
KW  - OR in environment and climate change
AB  - Long time horizon normative models are frequently used for policy analysis, strategic planning, and system analysis. Choosing the granularity of the temporal or spatial resolution of such models is an important modeling decision, often having a first order impact on model results. This type of decision is frequently made by modeler judgment, particularly when the predictive power of alternative choices cannot be tested. In this paper, we show how the implicit tradeoffs modelers make in these formulation decisions, in particular in the tradeoff between the accuracy of representation enabled by the available data and model parsimony, may be addressed with established information theoretic ideas. The paper provides guidance for modelers making these tradeoffs or, in certain cases, enables explicit tests for assessing appropriate levels of resolution. We will mainly focus on optimization based normative models in the discussion here, and draw our examples from the energy and climate domain.
ER  - 

TY  - JOUR
T1  - The price of discretizing time: a study in service network design
AU  - Boland, Natashia
AU  - Hewitt, Mike
AU  - Marshall, Luke
AU  - Savelsbergh, Martin
JO  - EURO Journal on Transportation and Logistics
VL  - 8
IS  - 2
SP  - 195
EP  - 216
PY  - 2019
DA  - 2019/06/01/
T2  - Special Issue: Advances in vehicle routing and logistics optimization: exact methods
SN  - 2192-4376
DO  - https://doi.org/10.1007/s13676-018-0119-x
UR  - https://www.sciencedirect.com/science/article/pii/S2192437620300327
KW  - Service network design
KW  - Time-space network
KW  - Time expanded network
KW  - Approximation
AB  - Researchers and practitioners have long recognized that many transportation problems can be naturally and conveniently modeled using time-expanded networks. In such models, nodes represent locations at distinct points in time and arcs represent possible actions, e.g., moving from one location to another at a particular point of time, or staying in the same location for a period of time. To use a time-expanded network, time must be discretized, i.e., the planning horizon is partitioned into discrete time intervals. The length of these intervals, therefore, must be chosen, and the parameters involving time, e.g., travel duration and due times, need to be mapped to these discrete intervals. Short intervals yield a high-quality approximation to the continuous-time problem, but typically induce a computationally intractable model; whereas long intervals can yield a computationally tractable, but low-quality model. The loss of quality is due to the approximation introduced by the mapping of parameters involving time. To guide researchers and practitioners in their use of time-expanded networks, we explore the choice of time discretization and its impact, by means of an extensive computational study on the service network design problem. The empirical results show that in some cases the loss of quality, i.e., the relative gap between the discretized and continuous-time optimal values, can be greater than 20%. We also investigate metrics that characterize and help identify instances that are likely to be sensitive to discretization and could incur a large loss of solution quality.
ER  - 

TY  - JOUR
T1  - Shaping the future of advanced automation and control systems for society strategic directions and multidisciplinary collaborations of IFAC's social systems coordinating committee
AU  - Stapleton, Larry
AU  - Wang, Fei-Yue
AU  - Netto, Mariana
AU  - Jia, Qing-Shan
AU  - Visioli, Antonio
AU  - Kopacek, Peter
JO  - Annual Reviews in Control
VL  - 58
SP  - 100967
PY  - 2024
DA  - 2024/01/01/
SN  - 1367-5788
DO  - https://doi.org/10.1016/j.arcontrol.2024.100967
UR  - https://www.sciencedirect.com/science/article/pii/S1367578824000361
KW  - Social Systems
KW  - Finance Systems
KW  - Business
KW  - Economics
KW  - Control for Societal impact
KW  - Cyber-Physical and Human Systems (CPHS)
KW  - responsible design of CPHS
KW  - Control Education
KW  - Engineering Ethics and Control
KW  - Smart Cities
KW  - Cost Oriented Automation
KW  - Systemic and Structural Effects of Technologies
KW  - Intelligent Systems
KW  - Diversity and Inclusion
KW  - International Affairs
KW  - Developing Regions
KW  - Culture
AB  - In an era of rapid advancements in highly intelligent digital systems, blockchain, and other transformative technologies, the role of control and automation in shaping human civilization is of paramount, even critical, importance. This paper examines the strategic significance of IFAC's Social Systems Coordinating Committee (CC), a unique multidisciplinary global community of researchers and practitioners comprising leading universities, research centers, industry partners and international agencies at the forefront of integrating technological and societal progress. This paper reports the results of a strategic "milestone" review, including an extensive meta-analysis of the Social Systems CC's five Technical Committees (TCs) and their activities. It uncovers key themes emphasizing this CC's contributions to models, systems, infrastructures, and operations. Using content analysis and word clouds, 272 keywords were refined to elucidate the main themes of the CC, revealing significant current and future collaborations with other IFAC communities and external organizations. The paper identifies high-potential new cooperation opportunities between this CC and the other IFAC CCs and their TCs, suggesting ways to achieve these collaborations. The findings highlight the Social Systems CC's unique position at the heart of the global automation and control community, where it offers practical applications in planning, management, and sustainability as well as fostering cross-sector cooperation crucial for human progress and effective humanitarian and environmental responses. This paper underscores the Social Systems CC's role in advancing control science and automation systems engineering to tackle pressing societal challenges, advocating for a future where technology and human systems synergize for the global well-being of all living systems.
ER  - 

TY  - JOUR
T1  - Towards self-explainable graph convolutional neural network with frequency adaptive inception
AU  - Wei, Feifei
AU  - Mei, Kuizhi
JO  - Pattern Recognition
VL  - 146
SP  - 109991
PY  - 2024
DA  - 2024/02/01/
SN  - 0031-3203
DO  - https://doi.org/10.1016/j.patcog.2023.109991
UR  - https://www.sciencedirect.com/science/article/pii/S0031320323006891
KW  - Self-explainable neural network
KW  - Frequency adaptive filter
KW  - Graph convolutional neural networks (GCN)
AB  - Graph convolutional neural networks (GCNs) have demonstrated powerful representing ability of irregular data, e.g., skeletal data and graph-structured data, providing the effective mechanism to fuse the neighbor nodes. However, inheriting from the deep learning, GCN also lacks interpretability, which hinders its application to scenarios that have high demand for transparency. Although, there have been many efforts on the interpretability of deep learning, they mainly concentrate on i.i.d data that is hard to be deployed to GCNs, which involve not only the node feature, but also the graph structure. There are few works that attempt to explain it with post-hoc manner, which can be biased, resulting in mis-representation of the true explanation. Therefore, in this paper, we propose a framework, namely ExpFiGCN, that reveals explainability of the GCNs from the perspective of graph structure and mathematical analysis. Specifically, ExpFiGCN can find the most intrinsically relevant node to the central node and obtain the informative and discriminative signals while performing denoising. For the graph structure, we find K-nearest nodes; for the mathematical analysis, every channel of a node and its neighborhoods contribute dynamically to the final channel signal, which can capture the inherent difference of different channels and neighbor nodes. Meanwhile, it can enhance the representation ability of nodes and ameliorate the over-smoothing problem. On the other hand, our model can dynamically adjust the importance of neighborhoods to the central vertex. We empirically validate the effectiveness of the proposed framework ExpFiGCN on various benchmark datasets. Experimental results show that our method achieves substantial improvements and outperforms the state-of-the-art performance strikingly.
ER  - 

TY  - JOUR
T1  - Probabilistic reporting and algorithms in forensic science: Stakeholder perspectives within the American criminal justice system
AU  - Swofford, H.
AU  - Champod, C.
JO  - Forensic Science International: Synergy
VL  - 4
SP  - 100220
PY  - 2022
DA  - 2022/01/01/
SN  - 2589-871X
DO  - https://doi.org/10.1016/j.fsisyn.2022.100220
UR  - https://www.sciencedirect.com/science/article/pii/S2589871X22000055
KW  - Forensic science
KW  - Pattern evidence
KW  - Probabilities
KW  - Statistics
KW  - Algorithms
AB  - In recent years, there have been efforts to promote probabilistic reporting and the use of computational algorithms across several forensic science disciplines. Reactions to these efforts have been mixed—some stakeholders argue they promote greater scientific rigor whereas others argue that the opacity of algorithmic tools makes it challenging to meaningfully scrutinize the evidence presented against a defendant resulting from these systems. Consequently, the forensic community has been left with no clear path to navigate these concerns as each proposed approach has countervailing benefits and risks. To explore these issues further and provide a foundation for a path forward, this study draws on semi-structured interviews with fifteen participants to elicit the perspectives of key criminal justice stakeholders, including laboratory managers, prosecutors, defense attorneys, judges, and other academic scholars, on issues related to interpretation and reporting practices and the use of computational algorithms in forensic science within the American legal system.
ER  - 

TY  - JOUR
T1  - Modelling industrial dynamics with “History-friendly” simulations
AU  - Garavaglia, Christian
JO  - Structural Change and Economic Dynamics
VL  - 21
IS  - 4
SP  - 258
EP  - 275
PY  - 2010
DA  - 2010/11/01/
SN  - 0954-349X
DO  - https://doi.org/10.1016/j.strueco.2010.07.001
UR  - https://www.sciencedirect.com/science/article/pii/S0954349X10000573
KW  - Simulation
KW  - Industrial dynamics
KW  - Evolutionary economics
KW  - “History-Friendly” models
KW  - Complexity
AB  - The use of simulation techniques has increased greatly in recent years. In economics the industrial dynamics approach makes use of simulation techniques to understand the complexity of the industrial process of continuous change. Among these models, a new branch of studies known as “History-friendly” models aims at establishing a close link between formal theory, developing stand-alone theoretical simulation models, and empirical evidence. In this paper, we study “History-friendly” analyses and counterfactuals. Some examples of “History-friendly” models are widely examined. Finally, the paper makes a critical contribution to “History-friendly” methodology and defines the role of “History-friendly” models in the debate on the empirical validation of simulations.
ER  - 

TY  - JOUR
T1  - The performance comparison problem: Universal task access for cross-framework evaluation, Turing tests, grand challenges, and cognitive decathlons
AU  - Veksler, Vladislav D.
AU  - Buchler, Norbou
AU  - Lebiere, Christian
AU  - Morrison, Don
AU  - Kelley, Troy
JO  - Biologically Inspired Cognitive Architectures
VL  - 18
SP  - 9
EP  - 22
PY  - 2016
DA  - 2016/10/01/
SN  - 2212-683X
DO  - https://doi.org/10.1016/j.bica.2016.10.003
UR  - https://www.sciencedirect.com/science/article/pii/S2212683X16300810
KW  - Grand challenge
KW  - Cognitive decathlon
KW  - Turing test
KW  - Performance comparison
KW  - Simulation
KW  - API
KW  - Standards
AB  - A driver for achieving human-level AI and high-fidelity cognitive architectures is the ability to easily test and compare the performance and behavior of computational agents/models to humans and to one another. One major difficulty in setting up and getting participation in large-scale cognitive decathlon and grand challenge competitions, or even smaller scale cross-framework evaluation and Turing testing, is that there is no standard interface protocol that enables and facilitates human and computational agent “plug-and-play” participation across various tasks. We identify three major issues. First, human-readable task interfaces aren’t often translated into machine-readable form. Second, in the cases where a task interface is made available in a machine-readable protocol, the protocol is often task-specific, and differs from other task protocols. Finally, where both human and machine-readable versions of the task interface exist, the two versions often differ in content. This makes the bar of entry extremely high for comparison of humans and multiple computational frameworks across multiple tasks. This paper proposes a standard approach to task design where all task interactions adhere to a standard API. We provide examples of how this method can be employed to gather human and computational simulation data in text-and-button tasks, visual and animated tasks, and in real-time robotics tasks.
ER  - 

TY  - JOUR
T1  - Improving vessel connectivity in retinal vessel segmentation via adversarial learning
AU  - Yuan, Yuchen
AU  - Wang, Lituan
AU  - Zhang, Lei
JO  - Knowledge-Based Systems
VL  - 262
SP  - 110243
PY  - 2023
DA  - 2023/02/28/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2022.110243
UR  - https://www.sciencedirect.com/science/article/pii/S0950705122013399
KW  - Retinal vessel segmentation
KW  - Vessel connectivity
KW  - Structural priors
KW  - Adversarial learning
AB  - Despite having achieved human-level performance in retinal vessel segmentation, deep learning based methods still suffer from poor connectivity of vessels in the generated segmentation maps. Since most methods operate as pixelwise classifiers, the vessel structure is ignored during the optimization of the segmentation network. To address this problem, a novel framework is proposed to enhance the vessel connectivity by incorporating the vessel structure into the segmentation network. First, to obtain the structural priors, the vessel structural priors extraction module (VSPEM) is proposed; VSPEM employs the powerful feature extraction ability of the convolutional autoencoder. After being pretrained, the proposed VSPEM can be used to extract useful latent features from the ground truths, which perform as the structural priors in segmentation. Then, the segmentation network is enforced to generate results that follow the distribution of the learned priors via adversarial learning. We have validated our method on three publicly available datasets, i.e., the DRIVE, CHASE_DB1 and STARE, and the state-of-the-art experimental results achieved on the above datasets demonstrate the efficacy of the proposed framework. Moreover, we show that the proposed framework is independent of segmentation models and can further improve model performance on vessel connectivity without introducing extra memory or a computational burden.
ER  - 

TY  - JOUR
T1  - Evolution in Mind: Evolutionary Dynamics, Cognitive Processes, and Bayesian Inference
AU  - Suchow, Jordan W.
AU  - Bourgin, David D.
AU  - Griffiths, Thomas L.
JO  - Trends in Cognitive Sciences
VL  - 21
IS  - 7
SP  - 522
EP  - 530
PY  - 2017
DA  - 2017/07/01/
SN  - 1364-6613
DO  - https://doi.org/10.1016/j.tics.2017.04.005
UR  - https://www.sciencedirect.com/science/article/pii/S1364661317300773
KW  - Bayesian inference
KW  - cognitive processes
KW  - creativity
KW  - evolution
KW  - learning
KW  - memory
AB  - Evolutionary theory describes the dynamics of population change in settings affected by reproduction, selection, mutation, and drift. In the context of human cognition, evolutionary theory is most often invoked to explain the origins of capacities such as language, metacognition, and spatial reasoning, framing them as functional adaptations to an ancestral environment. However, evolutionary theory is useful for understanding the mind in a second way: as a mathematical framework for describing evolving populations of thoughts, ideas, and memories within a single mind. In fact, deep correspondences exist between the mathematics of evolution and of learning, with perhaps the deepest being an equivalence between certain evolutionary dynamics and Bayesian inference. This equivalence permits reinterpretation of evolutionary processes as algorithms for Bayesian inference and has relevance for understanding diverse cognitive capacities, including memory and creativity.
ER  - 

TY  - JOUR
T1  - Factors associated with annual-interval mammography for women in their 40s
AU  - Gierisch, Jennifer M.
AU  - O’Neill, Suzanne C.
AU  - Rimer, Barbara K.
AU  - DeFrank, Jessica T.
AU  - Bowling, J. Michael
AU  - Skinner, Celette Sugg
JO  - Cancer Epidemiology
VL  - 33
IS  - 1
SP  - 72
EP  - 78
PY  - 2009
DA  - 2009/07/01/
SN  - 1877-7821
DO  - https://doi.org/10.1016/j.cdp.2009.03.001
UR  - https://www.sciencedirect.com/science/article/pii/S0361090X0900021X
KW  - Breast neoplasms
KW  - Guideline adherence
KW  - Health behavior
KW  - Middle aged
KW  - Attitude to health
KW  - Patient compliance
KW  - Mass screening
KW  - Female
KW  - Risk factor
KW  - Health knowledge
AB  - Background: Evidence is mounting that annual mammography for women in their 40s may be the optimal schedule to reduce morbidity and mortality from breast cancer. Few studies have assessed predictors of repeat mammography on an annual interval among these women. Methods: We assessed mammography screening status among 596 insured Black and Non-Hispanic white women ages 43–49. Adherence was defined as having a second mammogram 10–14 months after a previous mammogram. We examined socio-demographic, medical and healthcare-related variables on receipt of annual-interval repeat mammograms. We also assessed barriers associated with screening. Results: 44.8% of the sample were adherent to annual-interval mammography. A history of self-reported abnormal mammograms, family history of breast cancer and never having smoked were associated with adherence. Saying they had not received mammography reminders and reporting barriers to mammography were associated with non-adherence. Four barrier categories were associated with women's non-adherence: lack of knowledge/not thinking mammograms are needed, cost, being too busy, and forgetting to make/keep appointments. Conclusions: Barriers we identified are similar to those found in other studies. Health professionals may need to take extra care in discussing mammography screening risk and benefits due to ambiguity about screening guidelines for women in their 40s, especially for women without family histories of breast cancer or histories of abnormal mammograms. Reminders are important in promoting mammography and should be coupled with other strategies to help women maintain adherence to regular mammography.
ER  - 

TY  - CHAP
T1  - Towards Outcomes-Based Education of Computer-Aided Chemical Engineering
AU  - Pintarič, Zorka Novak
AU  - Kravanja, Zdravko
A2  - Kravanja, Zdravko
A2  - Bogataj, Miloš
BT  - Computer Aided Chemical Engineering
PB  - Elsevier
VL  - 38
SP  - 2367
EP  - 2372
PY  - 2016
DA  - 2016/01/01/
T2  - 26 European Symposium on Computer Aided Process Engineering
SN  - 1570-7946
DO  - https://doi.org/10.1016/B978-0-444-63428-3.50399-4
UR  - https://www.sciencedirect.com/science/article/pii/B9780444634283503994
KW  - Computer-Aided
KW  - Chemical Engineering
KW  - Education
KW  - Bologna process
KW  - Learning Outcomes
AB  - Chemical engineering education is nowadays increasingly supported by the use of various computational tools as the employers’ requirements for computing skills of graduates are growing too. However, students often acquire computational skills in an unsystematic manner due to a lack of defining and applying computer-based outcomes within the syllabuses suitable for the particular level of the Bologna three-cycle system. This paper bridges this gap by providing the review of the essential learning outcomes in the computer-aided chemical engineering education during all three cycles. The identified outcomes gradually progress from application-based competencies up to more advanced process modeling ones based on knowledge synthesis and creation. Accordingly, the educational strategies and curricula can be redesigned in order to integrate courses more efficiently both horizontally and vertically, and upgrade the use of computational tools.
ER  - 

TY  - JOUR
T1  - Using a new approach for revealing the spatiotemporal patterns of functional urban polycentricity: A case study in the Tokyo metropolitan area
AU  - Liu, Kai
AU  - Murayama, Yuji
AU  - Ichinose, Toshiaki
JO  - Sustainable Cities and Society
VL  - 59
SP  - 102176
PY  - 2020
DA  - 2020/08/01/
SN  - 2210-6707
DO  - https://doi.org/10.1016/j.scs.2020.102176
UR  - https://www.sciencedirect.com/science/article/pii/S2210670720301633
KW  - Functional urban area detection
KW  - Functional urban polycentricity
KW  - Multi-step Decision-making Newman algorithm
KW  - Tokyo Master Plan
KW  - Tokyo metropolitan area
AB  - This research designs a new approach by modifying the Fast-Newman algorithm for better implementing the process of detecting functional urban areas (FUAs) and further revealing the spatiotemporal patterns of functional urban polycentricity through 20 view-windows of each FUA in the Tokyo metropolitan area (TMA) by using geo-tagged big data. Through the 20 view-windows of our GIS microscope, it is possible to uncover patterns of functional connections and daily urban rhythms under the same layout of the functional urban structure in the TMA. Furthermore, our findings can elucidate the double-sided thinking by combining the explanations of functional urban polycentricity with the policy effects of the Tokyo Master Plan (TMP) from the perspective of area-byarea analysis across the entire TMA. Our results imply that the functional urban structure of the TMA is a four-level, annular pattern. The TMP still has room for the improvement toward sustainable urban planning in the TMA. Based on the investigation on the patterns of functional urban polycentricity, this research has obtained many hints and clues for improving the TMP. Rethinking the effectiveness of the TMP can also provide trustworthy academic verification and provide suggestions about concrete amendments that can enlighten future urban planning.
ER  - 
