TY  - JOUR
T1  - Cultural mapping and SARS-CoV-2 vaccination: An ethnic perspective
AU  - Guha, Soumya Kanti
AU  - Niyogi, Sougata
JO  - Societal Impacts
VL  - 1
IS  - 1
SP  - 100014
PY  - 2023
DA  - 2023/12/01/
SN  - 2949-6977
DO  - https://doi.org/10.1016/j.socimp.2023.100014
UR  - https://www.sciencedirect.com/science/article/pii/S2949697723000140
KW  - COVID-19
KW  - Culture
KW  - Vaccination
KW  - Immunization
KW  - Global
AB  - The COVID-19 pandemic has forced a comprehensive vaccination program that spans across social, geographical, and political boundaries. Our study aims to evaluate the program's effectiveness and explore the social factors that can influence its success globally. By analyzing data on immunization coverage and COVID-19 vaccination status for 196 and 187 countries, respectively, and taking into account the cultural values of 110 countries, we identified a correlation between vaccination success and societal openness to change. Our findings suggest that a history of good immunization coverage alone may not guarantee successful vaccine rollout; an optimistic ecosystem is also necessary. People must be willing to accept and apply the solution, and the rollout must address their psychological need for 360-degree success. Our study thus highlights the importance of understanding the social outlook to calibrate the attainment scale of global vaccination programs.
ER  - 

TY  - JOUR
T1  - Considering information-sharing motives to reduce misinformation
AU  - Globig, Laura K.
AU  - Sharot, Tali
JO  - Current Opinion in Psychology
VL  - 59
SP  - 101852
PY  - 2024
DA  - 2024/10/01/
SN  - 2352-250X
DO  - https://doi.org/10.1016/j.copsyc.2024.101852
UR  - https://www.sciencedirect.com/science/article/pii/S2352250X24000654
KW  - Social media
KW  - Misinformation
KW  - Social incentives
KW  - Reward-learning
KW  - Nudges
AB  - Misinformation has risen in recent years, negatively affecting domains ranging from politics to health. To curb the spread of misinformation it is useful to consider why, how, and when people decide to share information. Here we suggest that information-sharing decisions are value-based choices, in which sharers strive to maximize rewards and minimize losses to themselves and/or others. These outcomes can be tangible, in the form of monetary rewards or losses, or intangible, in the form of social feedback. On social media platforms these rewards and losses are not clearly tied to the accuracy of information shared. Thus, sharers have little incentive to avoid disseminating misinformation. Based on this framework, we propose ways to nudge sharers to prioritize accuracy during information-sharing.
ER  - 

TY  - JOUR
T1  - Physical measurement of brain perception abilities. Foundations of a working methodology for the design of “intelligent” beings
AU  - Panetsos, F.
AU  - Gonzalez, S.L. Andino
AU  - Marijuan, P.C.
AU  - Herrera-Rincon, C.
JO  - Procedia Computer Science
VL  - 7
SP  - 314
EP  - 316
PY  - 2011
DA  - 2011/01/01/
T2  - Proceedings of the 2nd European Future Technologies Conference and Exhibition 2011 (FET 11)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2011.09.052
UR  - https://www.sciencedirect.com/science/article/pii/S1877050911006120
KW  - Emergent properties
KW  - complexity
KW  - artificial brain
KW  - synthetic approach
AB  - Most of the important properties of the brain (thinking, consciousness, music, etc.) are severely ill-defined. They are not the direct output of biological sensors or their combinations but emerge from complex computations at the network level and are not necessarily represented in the sensory input or the activity of individual cells. They are emergent properties arising from dynamic interactions between neurons in the different relay stations of the sensory pathways where recognition of basic physical properties of incoming stimuli take place. Emergent properties and interactions between them range from physical properties of stimuli to cognitive operations as emotions or consciousness and gradually involve interactions between sensory pathways, associative cortexes, hippocampus, or the amygdala. Here we propose to build neural tissues from embryonic stem cells in “in vitro” controlled environments to determine the way physical inputs are transformed into what humans perceive and measure. We will start with “low complexity” tissues able to perform low level recognition of physical properties, to gradually increase the complexity of the tissue to investigate how the physical characteristics of the incoming stimuli correspond at higher levels to the emergent properties of the system. Mathematical methods based on networks theory, nonlinear dynamics, fractal theory and chaos among other will be used to determine and measure the emergent properties of the nervous tissue at different complexity levels. We expected to provide criteria and methodologies to measure human-like perception variables and use them for the design of future living artifacts (autonomous robots, intelligent sensors, hybrid systems, etc.).
ER  - 

TY  - JOUR
T1  - Managing the plot structure of character-based interactive narratives in games
AU  - de Lima, Edirlei Soares
AU  - Feijó, Bruno
AU  - Furtado, Antonio L.
JO  - Entertainment Computing
VL  - 47
SP  - 100590
PY  - 2023
DA  - 2023/08/01/
SN  - 1875-9521
DO  - https://doi.org/10.1016/j.entcom.2023.100590
UR  - https://www.sciencedirect.com/science/article/pii/S1875952123000459
KW  - Interactive storytelling
KW  - Narrative generation
KW  - Drama management
KW  - Plot structure
KW  - Automated planning
AB  - The use of narrative generation methods in games is a complex challenge that involves multiple problems of plot-based processes integrated with character-based methods. Examples of these problems are the high computational complexity of many story generation algorithms, the difficulties associated with the generation of interactive narratives that are compelling and emotionally impactful, the complex interactions among characters, and the need for tools and methods to support story writers in the process of creating and managing the narrative structure of interactive stories. In this work, we present and evaluate a new approach to generate and manage the plot structure of character-based interactive narratives in games, which combines multi-agent planning with a drama management strategy based on narrative structures. The proposed method is supported by an authoring tool that allows authors to create and test interactive narratives using graphical interfaces and intuitive diagrams. The results of our study suggest the effectiveness of our approach in generating interactive narratives for highly interactive game environments. In addition, a user study of the proposed authoring tool indicates that it can successfully support the development of character-based interactive narratives without requiring programming knowledge.
ER  - 

TY  - JOUR
T1  - Human divergent exploration capacity for material design: A comparison with artificial intelligence
AU  - Sakai, Hiroyuki
AU  - Matsuda, Kenroh
AU  - Kikkawa, Nobuaki
AU  - Kajita, Seiji
JO  - Computers in Human Behavior: Artificial Humans
VL  - 2
IS  - 1
SP  - 100064
PY  - 2024
DA  - 2024/01/01/
SN  - 2949-8821
DO  - https://doi.org/10.1016/j.chbah.2024.100064
UR  - https://www.sciencedirect.com/science/article/pii/S2949882124000240
KW  - Creativity
KW  - Divergent thinking
KW  - Lubricant molecule
KW  - Collaborative intelligence
AB  - Applications of artificial intelligence (AI) to material design have attracted increasing attention in recent years. Although AI-aided material design holds great promise for some applications, whether it has surpassed human creativity remains uncertain. The aim of the current study was to compare the divergent exploration capacity of AI with that of humans on a material design task. Human participants were asked to find a high-performance lubricant molecule under searching conditions comparable to a state-of-the-art AI system. Results indicated that, on average, AI was able to find significantly better lubricant molecules. However, the best molecule found by AI fell short of the best molecule found by a human participant. Furthermore, the structural characteristics of the molecules found by AI and human participants differed significantly. These findings suggest that a state-of-the-art AI system is capable of surpassing human divergent exploration capacity in material design, as in other fields in which AI has advanced. Nevertheless, our results also demonstrate that human intelligence and AI can play complementary roles in covering a broader search space. This investigation opens up new possibilities for collaborative systems involving both AI agents and humans in material design.
ER  - 

TY  - JOUR
T1  - Design and Development a Virtual Planetarium Learning Media Using Augmented Reality
AU  - Latif, Jazlyn Jan Keyla
AU  - Triputra, Augustinus Adrian
AU  - Kesuma, Michael Awarsa
AU  - Maulana, Fairuz Iqbal
JO  - Procedia Computer Science
VL  - 227
SP  - 726
EP  - 733
PY  - 2023
DA  - 2023/01/01/
T2  - 8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2023.10.577
UR  - https://www.sciencedirect.com/science/article/pii/S1877050923017441
KW  - Augmented Reality
KW  - Planetarium
KW  - Virtual
KW  - Virtual Planetarium
KW  - Application
AB  - The solar system has always been a mystery to many. If not for the advanced technologies, most humans would not have the opportunity to gain knowledge about the planets. Although Earth is a part of the solar system, the solar system is simply too dangerous and expensive for humans to explore casually. Humans do not interact with the Sun or planets actively. This is especially concerning for children who often require visual aids in studying. An Augmented Reality (AR) based application can solve that problem. Through Virtual Planetarium, children may interact with the Sun or the planets and gain information. This will help aid children's guardians in studying the solar system. The application is made by Systems Development Life Cycle (SDLC) method. Through the making of this application, it is expected that children will have a better understanding of the solar system.
ER  - 

TY  - JOUR
T1  - Model falsifiability and climate slow modes
AU  - Essex, Christopher
AU  - Tsonis, Anastasios A.
JO  - Physica A: Statistical Mechanics and its Applications
VL  - 502
SP  - 554
EP  - 562
PY  - 2018
DA  - 2018/07/15/
SN  - 0378-4371
DO  - https://doi.org/10.1016/j.physa.2018.02.090
UR  - https://www.sciencedirect.com/science/article/pii/S0378437118301766
KW  - Climate complexity
KW  - Computer errors
KW  - Computational over-stabilization
KW  - Dynamical and thermodynamical sensitivity
KW  - Slow climate modes
AB  - The most advanced climate models are actually modified meteorological models attempting to capture climate in meteorological terms. This seems a straightforward matter of raw computing power applied to large enough sources of current data. Some believe that models have succeeded in capturing climate in this manner. But have they? This paper outlines difficulties with this picture that derive from the finite representation of our computers, and the fundamental unavailability of future data instead. It suggests that alternative windows onto the multi-decadal timescales are necessary in order to overcome the issues raised for practical problems of prediction.
ER  - 

TY  - JOUR
T1  - Laplacians on flat line bundles over 3-manifolds
AU  - Vais, Alexander
AU  - Brandes, Daniel
AU  - Thielhelm, Hannes
AU  - Wolter, Franz-Erich
JO  - Computers & Graphics
VL  - 37
IS  - 6
SP  - 718
EP  - 729
PY  - 2013
DA  - 2013/10/01/
T2  - Shape Modeling International (SMI) Conference 2013
SN  - 0097-8493
DO  - https://doi.org/10.1016/j.cag.2013.05.013
UR  - https://www.sciencedirect.com/science/article/pii/S0097849313000873
KW  - Spectral geometry
KW  - Vector bundles
KW  - Computational topology
KW  - Laplace operator
KW  - Knots
KW  - Seifert surfaces
KW  - FEM
AB  - The well-known Laplace–Beltrami operator, established as a basic tool in shape processing, builds on a long history of mathematical investigations that have induced several numerical models for computational purposes. However, the Laplace–Beltrami operator is only one special case of many possible generalizations that have been researched theoretically. Thereby it is natural to supplement some of those extensions with concrete computational frameworks. In this work we study a particularly interesting class of extended Laplacians acting on sections of flat line bundles over compact Riemannian manifolds. Numerical computations for these operators have recently been accomplished on two-dimensional surfaces. Using the notions of line bundles and differential forms, we follow up on that work giving a more general theoretical and computational account of the underlying ideas and their relationships. Building on this we describe how the modified Laplacians and the corresponding computations can be extended to three-dimensional Riemannian manifolds, yielding a method that is able to deal robustly with volumetric objects of intricate shape and topology. We investigate and visualize the two-dimensional zero sets of the first eigenfunctions of the modified Laplacians, yielding an approach for constructing characteristic well-behaving, particularly robust homology generators invariant under isometric deformation. The latter include nicely embedded Seifert surfaces and their non-orientable counterparts for knot complements.
ER  - 

TY  - JOUR
T1  - Fast ranking nodes importance in complex networks based on LS-SVM method
AU  - Wen, Xiangxi
AU  - Tu, Congliang
AU  - Wu, Minggong
AU  - Jiang, Xurui
JO  - Physica A: Statistical Mechanics and its Applications
VL  - 506
SP  - 11
EP  - 23
PY  - 2018
DA  - 2018/09/15/
SN  - 0378-4371
DO  - https://doi.org/10.1016/j.physa.2018.03.076
UR  - https://www.sciencedirect.com/science/article/pii/S0378437118303947
KW  - Complex network
KW  - Node importance
KW  - AHP
KW  - LS-SVM
AB  - Achieving high accuracy and comprehensiveness in node importance evaluation of complex networks is time-consuming. To solve this problem, a method based on Least Square Support Vector Machine (LS-SVM) was proposed. Firstly, four complicated importance indicators which reflect the node importance globally and comprehensively were selected. Then analytic hierarchy process (AHP) method was applied to obtain the node’s importance evaluation. On this basis, three simple indicators with low computational complexity were proposed, and LS-SVM was adopted to find the mapping rules between simple indicators and AHP evaluation. The experiments on artificial network and actual network show the validity of proposed method: the evaluation based on complicated indicators is consistent with reality and reflects node importance accurately; simple indicators evaluation by LS-SVM saved a lot of computational time and improved the evaluating efficiency. Our method can provide guidance on influential node identification in large scale complex networks.
ER  - 

TY  - JOUR
T1  - Investigation of structural, electronic, and optical properties of zintl phase of Ba3In2As4: A DFT study for optoelectronic application
AU  - Akbar, Seher
AU  - Usman, Muhammad
AU  - Ur Rehman, Jalil
AU  - Bilal Tahir, M.
AU  - Hussain, Altaf
JO  - Computational and Theoretical Chemistry
VL  - 1228
SP  - 114290
PY  - 2023
DA  - 2023/10/01/
SN  - 2210-271X
DO  - https://doi.org/10.1016/j.comptc.2023.114290
UR  - https://www.sciencedirect.com/science/article/pii/S2210271X23002724
KW  - Zintl phase
KW  - CASTEP code
KW  - BaInAs
KW  - Narrow band gap
AB  - The physical properties of Zintl phase of Ba3In2As4 are investigated by employing first-principles calculation. The optimized lattice parameters are found as, a = 13.79 Å, b = 11.09 Å, and c = 7.20 Å. The material possesses a band gap of 0.66 and 1.58 eV as investigated by using GGA-PBE and HSE06 functional, respectively. Both functional show that the material possesses the direct band gap nature. The density of states was investigated to identify the orbital participation in the valence and conduction band. The PDOS shows that the contribution of the p-orbital is greater than s and d-orbitals. The optical properties of the material are also investigated in detail. The reflectivity and the refractive index have been observed to have a static value of 0.36 and 4.03, respectively. The material can be utilized in optoelectronic devices due to the direct band gap nature.
ER  - 

TY  - JOUR
T1  - Constructive and computable Hahn–Banach theorems for the (second) fundamental theorem of welfare economics
AU  - Vela Velupillai, K.
JO  - Journal of Mathematical Economics
VL  - 54
SP  - 36
EP  - 39
PY  - 2014
DA  - 2014/10/01/
SN  - 0304-4068
DO  - https://doi.org/10.1016/j.jmateco.2014.08.004
UR  - https://www.sciencedirect.com/science/article/pii/S0304406814001062
KW  - Fundamental theorems of welfare economics
KW  - Hahn–Banach theorem
KW  - Constructive analysis
KW  - Computable analysis
AB  - The Hahn–Banach Theorem plays a crucial role in the second fundamental theorem of welfare economics. To date, all mathematical economics and advanced general equilibrium textbooks concentrate on using non-constructive or incomputable versions of this celebrated theorem. In this paper we argue for the introduction of constructive or computable Hahn–Banach theorems in mathematical economics and advanced general equilibrium theory. The suggested modification would make applied and policy-oriented economics intrinsically computational.
ER  - 

TY  - JOUR
T1  - Making use: Attitudes to human-artifact engagements
AU  - Vardouli, Theodora
JO  - Design Studies
VL  - 41
SP  - 137
EP  - 161
PY  - 2015
DA  - 2015/11/01/
T2  - Special Issue: Computational Making
SN  - 0142-694X
DO  - https://doi.org/10.1016/j.destud.2015.08.002
UR  - https://www.sciencedirect.com/science/article/pii/S0142694X15000563
KW  - design theory
KW  - philosophy of design
KW  - user behavior
KW  - function theory
KW  - computational models
AB  - ‘Function’ and ‘use’ are keywords that design researchers customarily employ when referring to human-artifact engagements. However, there is little consensus about how the concepts of function and use relate to each other, to the intentions of ‘designers’ and ‘users’, or to their actions and encompassing contexts. In this paper, I synthesize literature from design research, material culture studies, design anthropology, and function theory in order to critically compare different attitudes to human-artifact engagements, implicit in characterizations of function and use. I identify design-centric, communicative, and use-centric attitudes, and discuss their assumptions and implications for design theory. I conclude by outlining principles for theoretically and computationally approaching use as an embodied and temporally contingent process – as a form of ‘making’.
ER  - 

TY  - JOUR
T1  - Human–machine hybrid intelligence for the generation of car frontal forms
AU  - Wu, Yu
AU  - Ma, Lisha
AU  - Yuan, Xiaofang
AU  - Li, Qingnan
JO  - Advanced Engineering Informatics
VL  - 55
SP  - 101906
PY  - 2023
DA  - 2023/01/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2023.101906
UR  - https://www.sciencedirect.com/science/article/pii/S1474034623000344
KW  - Car frontal form
KW  - Creative generation
KW  - Human–machine hybrid intelligence
KW  - Human–machine shared knowledge base
KW  - generative adversarial network (GAN)
AB  - With the acceleration of the upgrading of the automobile consumption market, artificial intelligence has become an increasingly effective means of enhancing the creative design of automobile appearance modeling. However, when artificial intelligence processes specific design tasks, creativity is primarily based on data drive, resulting in machine-generated design schemes that do not match human-specific psychological intentions. Due to the absence of design knowledge in the process of machine design, there is a data gap between human cognitive thought and machine information processing. This paper aims to structure the human's complex cognitive knowledge of car frontal form, establish the consistency between human and machine cognitive structures, and reduce communication barriers in the process of human–machine hybrid creative design. To achieve this objective, a human–machine hybrid intelligence methodology – a combination of human cognitive mental model, human–machine shared knowledge base, and Generative Adversarial Networks (GAN) – was developed to generate a large number of car frontal forms that are consistent with the design intent. First, we constructeda mental model of human cognition based on three dimensions: design intent, drawing behavior, and functional structure. Second, we created a shared human–machine knowledge base with design Knowledge. This knowledge base contains 12,560 images of car frontal form designs with corresponding morphological semantic labels and 3,140 sketches of car frontal forms drawn by hand. Human–machine shared knowledge base datawasutilized in a machine learning training network. In addition, a conditional cross-domain generative adversarial network was developed to investigate the implicit relationship between sketch characteristics, morphological semantics, and image visual effects. Using the suggested method, a large number of images with the specified morphological semantic category and resembling the hand-drawn sketch of a car frontal form can be generated rapidly. In terms of the quality of car frontal form generation, our research is superior to the baseline model according to qualitative and quantitative assessments. In comparison to the designer's output, the human–machine hybrid intelligent generation also demonstrates excellent creative performance.
ER  - 

TY  - JOUR
T1  - Spatial goal coding in the hippocampal formation
AU  - Nyberg, Nils
AU  - Duvelle, Éléonore
AU  - Barry, Caswell
AU  - Spiers, Hugo J.
JO  - Neuron
VL  - 110
IS  - 3
SP  - 394
EP  - 422
PY  - 2022
DA  - 2022/02/02/
SN  - 0896-6273
DO  - https://doi.org/10.1016/j.neuron.2021.12.012
UR  - https://www.sciencedirect.com/science/article/pii/S0896627321010291
KW  - hippocampus
KW  - entorhinal cortex
KW  - navigation
KW  - goal
KW  - wayfinding
KW  - spatial memory
KW  - reinforcement learning
KW  - rodent
KW  - human
AB  - Summary
The mammalian hippocampal formation contains several distinct populations of neurons involved in representing self-position and orientation. These neurons, which include place, grid, head direction, and boundary cells, are thought to collectively instantiate cognitive maps supporting flexible navigation. However, to flexibly navigate, it is necessary to also maintain internal representations of goal locations, such that goal-directed routes can be planned and executed. Although it has remained unclear how the mammalian brain represents goal locations, multiple neural candidates have recently been uncovered during different phases of navigation. For example, during planning, sequential activation of spatial cells may enable simulation of future routes toward the goal. During travel, modulation of spatial cells by the prospective route, or by distance and direction to the goal, may allow maintenance of route and goal-location information, supporting navigation on an ongoing basis. As the goal is approached, an increased activation of spatial cells may enable the goal location to become distinctly represented within cognitive maps, aiding goal localization. Lastly, after arrival at the goal, sequential activation of spatial cells may represent the just-taken route, enabling route learning and evaluation. Here, we review and synthesize these and other evidence for goal coding in mammalian brains, relate the experimental findings to predictions from computational models, and discuss outstanding questions and future challenges.
ER  - 

TY  - JOUR
T1  - Digital technologies can enhance climate resilience of critical infrastructure
AU  - Argyroudis, Sotirios A.
AU  - Mitoulis, Stergios Aristoteles
AU  - Chatzi, Eleni
AU  - Baker, Jack W.
AU  - Brilakis, Ioannis
AU  - Gkoumas, Konstantinos
AU  - Vousdoukas, Michalis
AU  - Hynes, William
AU  - Carluccio, Savina
AU  - Keou, Oceane
AU  - Frangopol, Dan M.
AU  - Linkov, Igor
JO  - Climate Risk Management
VL  - 35
SP  - 100387
PY  - 2022
DA  - 2022/01/01/
SN  - 2212-0963
DO  - https://doi.org/10.1016/j.crm.2021.100387
UR  - https://www.sciencedirect.com/science/article/pii/S2212096321001169
KW  - Emerging digital technologies
KW  - Data-driven
KW  - Critical infrastructure
KW  - Climate change
KW  - Sustainable development goals (SDGs)
AB  - Delivering infrastructure, resilient to multiple natural hazards and climate change, is fundamental to continued economic prosperity and social coherence. This is a strategic priority of the United Nations Sustainable Development Goals (SDGs), the World Bank, the Organisation for Economic Co-operation and Development (OECD), public policies and global initiatives. The operability and functionality of critical infrastructure are continuously challenged by multiple stressors, increasing demands and ageing, whilst their interconnectedness and dependencies pose additional challenges. Emerging and disruptive digital technologies have the potential to enhance climate resilience of critical infrastructure, by providing rapid and accurate assessment of asset condition and support decision-making and adaptation. In this pursuit, it is imperative to adopt multidisciplinary roadmaps and deploy computational, communication and other digital technologies, tools and monitoring systems. Nevertheless, the potential of these emerging technologies remains largely unexploited, as there is a lack of consensus, integrated approaches and legislation in support of their use. In this perspective paper, we discuss the main challenges and enablers of climate-resilient infrastructure and we identify how available roadmaps, tools and emerging digital technologies, e.g. Internet of Things, digital twins, point clouds, Artificial Intelligence, Building Information Modelling, can be placed at the service of a safer world. We show how digital technologies will lead to infrastructure of enhanced resilience, by delivering efficient and reliable decision-making, in a proactive and/or reactive manner, prior, during and after hazard occurrences. In this respect, we discuss how emerging technologies significantly reduce the uncertainties in all phases of infrastructure resilience evaluations. Thus, building climate-resilient infrastructure, aided by digital technologies, will underpin critical activities globally, contribute to Net Zero target and hence safeguard our societies and economies. To achieve this we set an agenda, which is aligned with the relevant SDGs and highlights the urgent need to deliver holistic and inclusive standards and legislation, supported by coordinated alliances, to fully utilise emerging digital technologies.
ER  - 

TY  - JOUR
T1  - VLSI implementation of transcendental function hyperbolic tangent for deep neural network accelerators
AU  - Rajput, Gunjan
AU  - Raut, Gopal
AU  - Chandra, Mahesh
AU  - Vishvakarma, Santosh Kumar
JO  - Microprocessors and Microsystems
VL  - 84
SP  - 104270
PY  - 2021
DA  - 2021/07/01/
SN  - 0141-9331
DO  - https://doi.org/10.1016/j.micpro.2021.104270
UR  - https://www.sciencedirect.com/science/article/pii/S014193312100435X
KW  - Activation function
KW  - Artificial neural network
KW  - Hyperbolic tangent (tanh)
KW  - Digital implementation
KW  - Combinational logic
AB  - Extensive use of neural network applications prompted researchers to customize a design to speed up their computation based on ASIC implementation. The choice of activation function (AF) in a neural network is an essential requirement. Accurate design architecture of an AF in a digital network faces various challenges as these AF require more hardware resources because of its non-linear nature. This paper proposed an efficient approximation scheme for hyperbolic tangent (tanh) function which purely based on combinational design architecture. The approximation is based on mathematical analysis by considering maximum allowable error in a neural network. The results prove that the proposed combinational design of an AF is efficient in terms of area, power and delay with negligible accuracy loss on MNIST and CIFAR-10 benchmark datasets. Post synthesis results show that the proposed design area is reduced by 66% and delay is reduced by nearly 16% compared to state-of-the-art.
ER  - 

TY  - JOUR
T1  - Modafinil for cognitive neuroenhancement in healthy non-sleep-deprived subjects: A systematic review
AU  - Battleday, R.M.
AU  - Brem, A.-K.
JO  - European Neuropsychopharmacology
VL  - 25
IS  - 11
SP  - 1865
EP  - 1881
PY  - 2015
DA  - 2015/11/01/
SN  - 0924-977X
DO  - https://doi.org/10.1016/j.euroneuro.2015.07.028
UR  - https://www.sciencedirect.com/science/article/pii/S0924977X15002497
KW  - Neuroenhancement
KW  - Modafinil
KW  - Cognitive
KW  - Psychometric
KW  - Enhancement
KW  - Nootropic
AB  - Modafinil is an FDA-approved eugeroic that directly increases cortical catecholamine levels, indirectly upregulates cerebral serotonin, glutamate, orexin, and histamine levels, and indirectly decreases cerebral gamma-amino-butrytic acid levels. In addition to its approved use treating excessive somnolence, modafinil is thought to be used widely off-prescription for cognitive enhancement. However, despite this popularity, there has been little consensus on the extent and nature of the cognitive effects of modafinil in healthy, non-sleep-deprived humans. This problem is compounded by methodological discrepancies within the literature, and reliance on psychometric tests designed to detect cognitive effects in ill rather than healthy populations. In order to provide an up-to-date systematic evaluation that addresses these concerns, we searched MEDLINE with the terms “modafinil” and “cognitive”, and reviewed all resultant primary studies in English from January 1990 until December 2014 investigating the cognitive actions of modafinil in healthy non-sleep-deprived humans. We found that whilst most studies employing basic testing paradigms show that modafinil intake enhances executive function, only half show improvements in attention and learning and memory, and a few even report impairments in divergent creative thinking. In contrast, when more complex assessments are used, modafinil appears to consistently engender enhancement of attention, executive functions, and learning. Importantly, we did not observe any preponderances for side effects or mood changes. Finally, in light of the methodological discrepancies encountered within this literature, we conclude with a series of recommendations on how to optimally detect valid, robust, and consistent effects in healthy populations that should aid future assessment of neuroenhancement.
ER  - 

TY  - JOUR
T1  - Graph orientation with splits
AU  - Asahiro, Yuichi
AU  - Jansson, Jesper
AU  - Miyano, Eiji
AU  - Nikpey, Hesam
AU  - Ono, Hirotaka
JO  - Theoretical Computer Science
VL  - 844
SP  - 16
EP  - 25
PY  - 2020
DA  - 2020/12/06/
SN  - 0304-3975
DO  - https://doi.org/10.1016/j.tcs.2020.07.013
UR  - https://www.sciencedirect.com/science/article/pii/S030439752030387X
KW  - Graph orientation
KW  - Maximum flow
KW  - Vertex cover
KW  - Partition
KW  - Algorithm
KW  - Computational complexity
AB  - The Minimum Maximum Outdegree Problem (MMO) is to assign a direction to every edge in an input undirected, edge-weighted graph so that the maximum weighted outdegree taken over all vertices becomes as small as possible. In this paper, we introduce a new variant of MMO called the p-Split Minimum Maximum Outdegree Problem (p-Split-MMO) in which one is allowed to perform a sequence of p split operations on the vertices before orienting the edges, for some specified non-negative integer p, and study its computational complexity.
ER  - 

TY  - CHAP
T1  - Chapter 2 - Cerebral: surface
AU  - Canavero, Sergio
A2  - Arle, Jeffrey E.
A2  - Shils, Jay L.
BT  - Essential Neuromodulation (Second Edition)
PB  - Academic Press
SP  - 21
EP  - 48
PY  - 2022
DA  - 2022/01/01/
SN  - 978-0-12-817000-7
DO  - https://doi.org/10.1016/B978-0-12-817000-7.00002-8
UR  - https://www.sciencedirect.com/science/article/pii/B9780128170007000028
KW  - Cortical Stimulation
KW  - Functional Neurosurgery
KW  - Pain
KW  - Psychiatry
KW  - TDCS
KW  - TMS
AB  - Cortical stimulation (CS) is a recent addition to electrical stimulation of the nervous system for therapeutic purposes. It can be administered both invasively (functional neurosurgery) or noninvasively mainly via transcranial magnetic stimulation or transcranial direct current stimulation. The primary indications for CS include neuropathic pain, and psychiatric disorders such as depression, but movement disorders, tinnitus, epilepsy, and coma rehabilitation are part of its purview. Neurosurgically implanted stimulators appear to achieve better results on a larger number of patients, but noninvasive stimulation has clear advantages in terms of safety and cost. Mixed results can be chalked up to individual anatomical and connectomic variations: the cortex is by far more complex than other neural, deeper targets, and current computational modeling efforts are underway to improve results. The next generation of CS will come with closed-loop capability and newer electrodes, in addition to refinements in personalized neuroimaging-guided targeting.
ER  - 

TY  - JOUR
T1  - Do we really understand how drug eluted from stents modulates arterial healing?
AU  - McQueen, Alistair
AU  - Escuer, Javier
AU  - Aggarwal, Ankush
AU  - Kennedy, Simon
AU  - McCormick, Christopher
AU  - Oldroyd, Keith
AU  - McGinty, Sean
JO  - International Journal of Pharmaceutics
VL  - 601
SP  - 120575
PY  - 2021
DA  - 2021/05/15/
SN  - 0378-5173
DO  - https://doi.org/10.1016/j.ijpharm.2021.120575
UR  - https://www.sciencedirect.com/science/article/pii/S037851732100380X
KW  - Pharmacodynamics
KW  - Ligand-receptor interactions
KW  - Drug-eluting stents
KW  - Smooth Muscle Cells
KW  - Cell proliferation
KW  - Mathematical Modelling
AB  - The advent of drug-eluting stents (DES) has revolutionised the treatment of coronary artery disease. These devices, coated with anti-proliferative drugs, are deployed into stenosed or occluded vessels, compressing the plaque to restore natural blood flow, whilst simultaneously combating the evolution of restenotic tissue. Since the development of the first stent, extensive research has investigated how further advancements in stent technology can improve patient outcome. Mathematical and computational modelling has featured heavily, with models focussing on structural mechanics, computational fluid dynamics, drug elution kinetics and subsequent binding within the arterial wall; often considered separately. Smooth Muscle Cell (SMC) proliferation and neointimal growth are key features of the healing process following stent deployment. However, models which depict the action of drug on these processes are lacking. In this article, we start by reviewing current models of cell growth, which predominantly emanate from cancer research, and available published data on SMC proliferation, before presenting a series of mathematical models of varying complexity to detail the action of drug on SMC growth in vitro. Our results highlight that, at least for Sodium Salicylate and Paclitaxel, the current state-of-the-art nonlinear saturable binding model is incapable of capturing the proliferative response of SMCs across a range of drug doses and exposure times. Our findings potentially have important implications on the interpretation of current computational models and their future use to optimise and control drug release from DES and drug-coated balloons.
ER  - 

TY  - JOUR
T1  - Is there a need for fuzzy logic?
AU  - Zadeh, Lotfi A.
JO  - Information Sciences
VL  - 178
IS  - 13
SP  - 2751
EP  - 2779
PY  - 2008
DA  - 2008/07/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2008.02.012
UR  - https://www.sciencedirect.com/science/article/pii/S0020025508000716
KW  - Fuzzy logic
KW  - Fuzzy sets
KW  - Approximate reasoning
KW  - Computing with words
KW  - Computing with perceptions
KW  - Generalized theory of uncertainty
AB  - “Is there a need for fuzzy logic?” is an issue which is associated with a long history of spirited discussions and debate. There are many misconceptions about fuzzy logic. Fuzzy logic is not fuzzy. Basically, fuzzy logic is a precise logic of imprecision and approximate reasoning. More specifically, fuzzy logic may be viewed as an attempt at formalization/mechanization of two remarkable human capabilities. First, the capability to converse, reason and make rational decisions in an environment of imprecision, uncertainty, incompleteness of information, conflicting information, partiality of truth and partiality of possibility – in short, in an environment of imperfect information. And second, the capability to perform a wide variety of physical and mental tasks without any measurements and any computations [L.A. Zadeh, From computing with numbers to computing with words – from manipulation of measurements to manipulation of perceptions, IEEE Transactions on Circuits and Systems 45 (1999) 105–119; L.A. Zadeh, A new direction in AI – toward a computational theory of perceptions, AI Magazine 22 (1) (2001) 73–84]. In fact, one of the principal contributions of fuzzy logic – a contribution which is widely unrecognized – is its high power of precisiation. Fuzzy logic is much more than a logical system. It has many facets. The principal facets are: logical, fuzzy-set-theoretic, epistemic and relational. Most of the practical applications of fuzzy logic are associated with its relational facet. In this paper, fuzzy logic is viewed in a nonstandard perspective. In this perspective, the cornerstones of fuzzy logic – and its principal distinguishing features – are: graduation, granulation, precisiation and the concept of a generalized constraint. A concept which has a position of centrality in the nontraditional view of fuzzy logic is that of precisiation. Informally, precisiation is an operation which transforms an object, p, into an object, p∗, which in some specified sense is defined more precisely than p. The object of precisiation and the result of precisiation are referred to as precisiend and precisiand, respectively. In fuzzy logic, a differentiation is made between two meanings of precision – precision of value, v-precision, and precision of meaning, m-precision. Furthermore, in the case of m-precisiation a differentiation is made between mh-precisiation, which is human-oriented (nonmathematical), and mm-precisiation, which is machine-oriented (mathematical). A dictionary definition is a form of mh-precisiation, with the definiens and definiendum playing the roles of precisiend and precisiand, respectively. Cointension is a qualitative measure of the proximity of meanings of the precisiend and precisiand. A precisiand is cointensive if its meaning is close to the meaning of the precisiend. A concept which plays a key role in the nontraditional view of fuzzy logic is that of a generalized constraint. If X is a variable then a generalized constraint on X, GC(X), is expressed as X isr R, where R is the constraining relation and r is an indexical variable which defines the modality of the constraint, that is, its semantics. The primary constraints are: possibilistic, (r=blank), probabilistic (r=p) and veristic (r=v). The standard constraints are: bivalent possibilistic, probabilistic and bivalent veristic. In large measure, science is based on standard constraints. Generalized constraints may be combined, qualified, projected, propagated and counterpropagated. The set of all generalized constraints, together with the rules which govern generation of generalized constraints, is referred to as the generalized constraint language, GCL. The standard constraint language, SCL, is a subset of GCL. In fuzzy logic, propositions, predicates and other semantic entities are precisiated through translation into GCL. Equivalently, a semantic entity, p, may be precisiated by representing its meaning as a generalized constraint. By construction, fuzzy logic has a much higher level of generality than bivalent logic. It is the generality of fuzzy logic that underlies much of what fuzzy logic has to offer. Among the important contributions of fuzzy logic are the following: 1.FL-generalization. Any bivalent-logic-based theory, T, may be FL-generalized, and hence upgraded, through addition to T of concepts and techniques drawn from fuzzy logic. Examples: fuzzy control, fuzzy linear programming, fuzzy probability theory and fuzzy topology.2.Linguistic variables and fuzzy if–then rules. The formalism of linguistic variables and fuzzy if–then rules is, in effect, a powerful modeling language which is widely used in applications of fuzzy logic. Basically, the formalism serves as a means of summarization and information compression through the use of granulation.3.Cointensive precisiation. Fuzzy logic has a high power of cointensive precisiation. This power is needed for a formulation of cointensive definitions of scientific concepts and cointensive formalization of human-centric fields such as economics, linguistics, law, conflict resolution, psychology and medicine.4.NL-Computation (computing with words). Fuzzy logic serves as a basis for NL-Computation, that is, computation with information described in natural language. NL-Computation is of direct relevance to mechanization of natural language understanding and computation with imprecise probabilities. More generally, NL-Computation is needed for dealing with second-order uncertainty, that is, uncertainty about uncertainty, or uncertainty2 for short. In summary, progression from bivalent logic to fuzzy logic is a significant positive step in the evolution of science. In large measure, the real-world is a fuzzy world. To deal with fuzzy reality what is needed is fuzzy logic. In coming years, fuzzy logic is likely to grow in visibility, importance and acceptance.
ER  - 

TY  - JOUR
T1  - Midfrontal Theta Activity in Psychiatric Illness: An Index of Cognitive Vulnerabilities Across Disorders
AU  - McLoughlin, Gráinne
AU  - Gyurkovics, Máté
AU  - Palmer, Jason
AU  - Makeig, Scott
JO  - Biological Psychiatry
VL  - 91
IS  - 2
SP  - 173
EP  - 182
PY  - 2022
DA  - 2022/01/15/
T2  - Biomarkers of Psychosis
SN  - 0006-3223
DO  - https://doi.org/10.1016/j.biopsych.2021.08.020
UR  - https://www.sciencedirect.com/science/article/pii/S0006322321015651
KW  - Biomarker
KW  - Cognitive control
KW  - EEG
KW  - ERP
KW  - Oscillations
KW  - Theta
AB  - There is an urgent need to identify the mechanisms that contribute to atypical thinking and behavior associated with psychiatric illness. Behavioral and brain measures of cognitive control are associated with a variety of psychiatric disorders and conditions as well as daily life functioning. Recognition of the importance of cognitive control in human behavior has led to intensive research into behavioral and neurobiological correlates. Oscillations in the theta band (4–8 Hz) over medial frontal recording sites are becoming increasingly established as a direct neural index of certain aspects of cognitive control. In this review, we point toward evidence that theta acts to coordinate multiple neural processes in disparate brain regions during task processing to optimize behavior. Theta-related signals in human electroencephalography include the N2, the error-related negativity, and measures of theta power in the (time-)frequency domain. We investigate how these theta signals are affected in a wide range of psychiatric conditions with known deficiencies in cognitive control: anxiety, obsessive-compulsive disorder, attention-deficit/hyperactivity disorder, and substance abuse. Theta-related control signals and their temporal consistency were found to differ in most patient groups compared with healthy control subjects, suggesting fundamental deficits in reactive and proactive control. Notably, however, clinical studies directly investigating the role of theta in the coordination of goal-directed processes across different brain regions are uncommon and are encouraged in future research. A finer-grained analysis of flexible, subsecond-scale functional networks in psychiatric disorders could contribute to a dimensional understanding of psychopathology.
ER  - 

TY  - JOUR
T1  - MERRA Analytic Services: Meeting the Big Data challenges of climate science through cloud-enabled Climate Analytics-as-a-Service
AU  - Schnase, John L.
AU  - Duffy, Daniel Q.
AU  - Tamkin, Glenn S.
AU  - Nadeau, Denis
AU  - Thompson, John H.
AU  - Grieg, Cristina M.
AU  - McInerney, Mark A.
AU  - Webster, William P.
JO  - Computers, Environment and Urban Systems
VL  - 61
SP  - 198
EP  - 211
PY  - 2017
DA  - 2017/01/01/
T2  - Geospatial Cloud Computing and Big Data
SN  - 0198-9715
DO  - https://doi.org/10.1016/j.compenvurbsys.2013.12.003
UR  - https://www.sciencedirect.com/science/article/pii/S019897151300118X
KW  - MapReduce
KW  - Hadoop
KW  - Data analytics
KW  - Data services
KW  - Cloud Computing
KW  - Generativity
KW  - iRODS
KW  - MERRA
KW  - ESGF
KW  - BAER
AB  - Climate science is a Big Data domain that is experiencing unprecedented growth. In our efforts to address the Big Data challenges of climate science, we are moving toward a notion of Climate Analytics-as-a-Service (CAaaS). We focus on analytics, because it is the knowledge gained from our interactions with Big Data that ultimately produce societal benefits. We focus on CAaaS because we believe it provides a useful way of thinking about the problem: a specialization of the concept of business process-as-a-service, which is an evolving extension of IaaS, PaaS, and SaaS enabled by Cloud Computing. Within this framework, Cloud Computing plays an important role; however, we see it as only one element in a constellation of capabilities that are essential to delivering climate analytics as a service. These elements are essential because in the aggregate they lead to generativity, a capacity for self-assembly that we feel is the key to solving many of the Big Data challenges in this domain. MERRA Analytic Services (MERRA/AS) is an example of cloud-enabled CAaaS built on this principle. MERRA/AS enables MapReduce analytics over NASA’s Modern-Era Retrospective Analysis for Research and Applications (MERRA) data collection. The MERRA reanalysis integrates observational data with numerical models to produce a global temporally and spatially consistent synthesis of 26 key climate variables. It represents a type of data product that is of growing importance to scientists doing climate change research and a wide range of decision support applications. MERRA/AS brings together the following generative elements in a full, end-to-end demonstration of CAaaS capabilities: (1) high-performance, data proximal analytics, (2) scalable data management, (3) software appliance virtualization, (4) adaptive analytics, and (5) a domain-harmonized API. The effectiveness of MERRA/AS has been demonstrated in several applications. In our experience, Cloud Computing lowers the barriers and risk to organizational change, fosters innovation and experimentation, facilitates technology transfer, and provides the agility required to meet our customers’ increasing and changing needs. Cloud Computing is providing a new tier in the data services stack that helps connect earthbound, enterprise-level data and computational resources to new customers and new mobility-driven applications and modes of work. For climate science, Cloud Computing’s capacity to engage communities in the construction of new capabilities is perhaps the most important link between Cloud Computing and Big Data.
ER  - 

TY  - JOUR
T1  - EMA: A process model of appraisal dynamics
AU  - Marsella, Stacy C.
AU  - Gratch, Jonathan
JO  - Cognitive Systems Research
VL  - 10
IS  - 1
SP  - 70
EP  - 90
PY  - 2009
DA  - 2009/03/01/
T2  - Modeling the Cognitive Antecedents and Consequences of Emotion
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2008.03.005
UR  - https://www.sciencedirect.com/science/article/pii/S1389041708000314
KW  - Emotion
KW  - Cognitive models
KW  - Appraisal theory
KW  - Coping
AB  - A computational model of emotion must explain both the rapid dynamics of some emotional reactions as well as the slower responses that follow deliberation. This is often addressed by positing multiple levels of appraisal processes such as fast pattern directed vs. slower deliberative appraisals. In our view, this confuses appraisal with inference. Rather, we argue for a single and automatic appraisal process that operates over a person’s interpretation of their relationship to the environment. Dynamics arise from perceptual and inferential processes operating on this interpretation (including deliberative and reactive processes). This article discusses current developments in a computational model of emotion processes and illustrates how a single-level model of appraisal obviates a multi-level approach within the context of modeling a naturalistic emotional situation.
ER  - 

TY  - JOUR
T1  - Self-similarity of parallel machines
AU  - Numrich, Robert W.
AU  - Heroux, Michael A.
JO  - Parallel Computing
VL  - 37
IS  - 2
SP  - 69
EP  - 84
PY  - 2011
DA  - 2011/02/01/
SN  - 0167-8191
DO  - https://doi.org/10.1016/j.parco.2010.11.003
UR  - https://www.sciencedirect.com/science/article/pii/S0167819110001444
KW  - Parallel algorithms
KW  - Benchmark analysis
KW  - Computational intensity
KW  - Computational force
KW  - Dimensional analysis
KW  - Equivalence class
KW  - Self-similarity
KW  - Scaling
KW  - Mixing coefficient
AB  - Self-similarity is a property of physical systems that describes how to scale parameters such that dissimilar systems appear to be similar. Computer systems are self-similar if certain ratios of computational forces, also known as computational intensities, are equal. Two machines with different computational power, different network bandwidth and different inter-processor latency behave the same way if they have the same ratios of forces. For the parallel conjugate gradient algorithm studied in this paper, two machines are self-similar if and only if the ratio of one force describing latency effects to another force describing bandwidth effects is the same for both machines. For the two machines studied in this paper, this ratio, which we call the mixing coefficient, is invariant as problem size and processor count change. The two machines have the same mixing coefficient and belong to the same equivalence class.
ER  - 

TY  - JOUR
T1  - Integrating artificial intelligence: A step forward in orthodontic education
AU  - Krishnan, Vinod
JO  - Journal of the World Federation of Orthodontists
VL  - 13
IS  - 4
SP  - 153
EP  - 154
PY  - 2024
DA  - 2024/08/01/
SN  - 2212-4438
DO  - https://doi.org/10.1016/j.ejwf.2024.07.002
UR  - https://www.sciencedirect.com/science/article/pii/S221244382400050X
ER  - 

TY  - JOUR
T1  - Equilibrium Conditions In Service Supply Chain
AU  - Cheng, Fei
AU  - Yang, Shanlin
AU  - Ma, Xijun
JO  - Procedia Engineering
VL  - 15
SP  - 5100
EP  - 5104
PY  - 2011
DA  - 2011/01/01/
T2  - CEIS 2011
SN  - 1877-7058
DO  - https://doi.org/10.1016/j.proeng.2011.08.946
UR  - https://www.sciencedirect.com/science/article/pii/S1877705811024477
KW  - service supply chain
KW  - service volume
KW  - equilibrium
AB  - Service supply chain features human players as service vendor, service integrator, customer and service resource. It tends to be digitally connected, such as consulting, e-business and integrated enterprises. Our study uses a formal model and simulations to develop the effect of a service supply chain on equilibrium computation. Two insights arise on how a network can obtain equilibrium computation: forming the network structure of service supply chain; exploring entities behavior and equilibrium conditions. These results highlight the importance for service supply chain of adapting its network structure to equilibrium and application.
ER  - 

TY  - JOUR
T1  - An experimental and numerical study of the solid particle erosion damage in an industrial cement large-sized fan
AU  - Fortini, Annalisa
AU  - Suman, Alessio
AU  - Zanini, Nicola
JO  - Engineering Failure Analysis
VL  - 146
SP  - 107058
PY  - 2023
DA  - 2023/04/01/
SN  - 1350-6307
DO  - https://doi.org/10.1016/j.engfailanal.2023.107058
UR  - https://www.sciencedirect.com/science/article/pii/S1350630723000122
KW  - Wear damage
KW  - Hardfacing
KW  - Centrifugal fan
KW  - Computational fluid dynamics
KW  - Solid particle erosion
KW  - Metallographic analysis
AB  - The present paper addresses the wear failure analysis of a large-sized centrifugal fan operating in a cement clinker grinding plant. Within cement production, the calcination at middle and high-temperature values (from 120 °C to 400 °C depending on the process parameters) of the raw material requires such a process fan, which also ensures the draft and feed of the flue gases and combustion air needed for the operation of the main equipment of the cement factory. To detect and analyze the impact conditions within the heavy-duty fan, Computational Fluid Dynamics (CFD) analyses were performed. The analysis of the numerical results shows that the relevant fan surfaces are affected by different impact velocities and angles, generating non-uniform erosion patterns similar to the on-field detections. Besides, the obtained comprehensive description of the flow and contaminants behaviors through the entire flow path enables setting up the subsequent experimental investigation. The erosive wear behavior of a Fe-Cr-C hardfacing cast iron and wear-resistant steel was tested through a test rig constructed for the purpose of being in accordance with the ASTM G76 standard. The test bench was adapted to manage the raw meal powder used in the cement factory to reproduce the actual operating conditions. The results show a greater capability of Fe-Cr-C hardfacing cast iron to face the erosion phenomenon in terms of lower values of material loss over the exposure time. These findings, coupled with the metallographic analysis to detect the erosion mechanisms (ductile and/or brittle), help a better prediction of the fan operating life. The investigation showed the reliability of the numerical/experimental coupled approach in assessing the actual erosion magnitude and the influence of the impact angle on the erosion phenomena. This coupled approach gains a further understanding of the proper design of manufacturing and maintenance activities, covering several project steps from material selections to the scheduled and overhaul operations. A reliable operating-life prediction allows manufacturers and operators to obtain production and economic goals.
ER  - 

TY  - JOUR
T1  - Spatiotemporal characteristics and influencing factors of airport service quality in China
AU  - Ran, Xinyue
AU  - Li, Lingling
AU  - Han, Ruiling
JO  - Journal of Air Transport Management
VL  - 117
SP  - 102578
PY  - 2024
DA  - 2024/05/01/
SN  - 0969-6997
DO  - https://doi.org/10.1016/j.jairtraman.2024.102578
UR  - https://www.sciencedirect.com/science/article/pii/S0969699724000437
KW  - Airport
KW  - Aviation complaint
KW  - Service quality
KW  - Influencing factors
KW  - Spatiotemporal differentiation characteristic
AB  - Airport service quality (ASQ) is essential for determining the quality of ground civil aviation services. In this study, ASQ was assessed using the monthly airport aviation complaint data from 2015 to 2019 of 196 airports in mainland China (except for airports in Hong Kong, Macao, and Taiwan, which are not included in the statistics). First, we constructed a seasonal index of aviation complaints to evaluate and compare the overall temporal characteristics of ASQ in China. Second, the spatial distribution pattern of ASQ in China was determined using the aviation complaint concentration index and hot spot analysis model. Finally, the major influencing factors and categories of ASQ in China were analyzed considering spatiotemporal dimensions using the correspondence analysis method. The results revealed that there were clear seasonal differences among ASQ in China, with a high–low–low–high distribution during all four seasons. The regional agglomeration trend of airport aviation complaints was obvious, and the spatial difference in ASQ was large. Northern and western China performed better than southern China. Spatiotemporal and influencing factors of ASQ were the most strongly correlated factors in each quarter and region. The predominant source of aviation complaints across all types of airports is related to fundamental services, with check-in services identified as the most impactful category affecting ASQ. This study, based on 60 months of statistical data, offers a comprehensive evaluation of ASQ throughout the entire airport network in mainland China, from the perspective of aviation complaints. Additionally, a systematic ASQ evaluation method and research system encompassing time, space, and elements were established. This framework not only stimulates the improvement and enhancement of ASQ but also provides a theoretical foundation for differentially enhancing ASQ in regional airports. Overall, our results contribute to breaking through the qualitative research thinking system in ASQ research from a theoretical perspective, paving the way for exploring broader research in enhancing the quality of ground civil aviation services.
ER  - 

TY  - JOUR
T1  - Embodied sequential sampling models and dynamic neural fields for decision-making: Why hesitate between two when a continuum is the answer
AU  - Quinton, Jean-Charles
AU  - Gautheron, Flora
AU  - Smeding, Annique
JO  - Neural Networks
VL  - 179
SP  - 106526
PY  - 2024
DA  - 2024/11/01/
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2024.106526
UR  - https://www.sciencedirect.com/science/article/pii/S0893608024004507
KW  - Decision-making
KW  - Sequential sampling model
KW  - Leaky competing accumulator
KW  - Dynamic neural field
KW  - Embodied decision
KW  - Mouse-tracking
AB  - As two alternative options in a forced choice task are separated by design, two classes of computational models of decision-making have thrived independently in the literature for nearly five decades. While sequential sampling models (SSM) focus on response times and keypresses in binary decisions in experimental paradigms, dynamic neural fields (DNF) focus on continuous sensorimotor dimensions and tasks found in perception and robotics. Recent attempts have been made to address limitations in their application to other domains, but strong similarities and compatibility between prominent models from both classes were hardly considered. This article is an attempt at bridging the gap between these classes of models, and simultaneously between disciplines and paradigms relying on binary or continuous responses. A unifying formulation of representative SSM and DNF equations is proposed, varying the number of units which interact and compete to reach a decision. The embodiment of decisions is also considered by coupling cognitive and sensorimotor processes, enabling the model to generate decision trajectories at trial level. The resulting mechanistic model is therefore able to target different paradigms (forced choices or continuous response scales) and measures (final responses or dynamics). The validity of the model is assessed statistically by fitting empirical distributions obtained from human participants in moral decision-making mouse-tracking tasks, for which both dichotomous and nuanced responses are meaningful. Comparing equations at the theoretical level, and model parametrizations at the empirical level, the implications for psychological decision-making processes, as well as the fundamental assumptions and limitations of models and paradigms are discussed.
ER  - 

TY  - JOUR
T1  - Role of pedagogical approaches in fostering innovation among K-12 students in STEM education
AU  - Ammar, Mohammad
AU  - Al-Thani, Noora J.
AU  - Ahmad, Zubair
JO  - Social Sciences & Humanities Open
VL  - 9
SP  - 100839
PY  - 2024
DA  - 2024/01/01/
SN  - 2590-2911
DO  - https://doi.org/10.1016/j.ssaho.2024.100839
UR  - https://www.sciencedirect.com/science/article/pii/S2590291124000366
KW  - Educational reform
KW  - STEM
KW  - Pedagogy
KW  - K-12
KW  - Early education
KW  - Innovation
KW  - Technology
AB  - The intricate challenges of the modern world demand students to be equipped with advanced skills and knowledge to thrive in an increasingly competitive global landscape. Science, technology, engineering, and mathematics (STEM) practices can help develop these capabilities in students from an early age. However, as technology continues to advance rapidly, STEM education has experienced a rapid transformation with seamless integration of various technologies. Students in the K-12 education is required to keep up with the growing innovation and to bridge this gap, pedagogical approaches play a crucial role. Therefore, this review presents the current landscape, developmental trends, and future directions of the various pedagogical practices used to integrate innovation in K-12 STEM. The characteristics and environmental perceptions that influence the development of innovation in students using such approaches are examined. Results from 42 systematically shortlisted studies indicate positive correlations of personalized pedagogical approaches in promoting innovation in students, thereby increasing STEM literacy in K-12 education. However, limitations that remain with teacher competencies and school facilities to cope with various pedagogical approaches are also discussed. Finally, we conclude with our recommendations on effective and efficient approaches that can be implemented in K-12 STEM education to develop the skills and mindset in students necessary to become innovative thinkers and prepare them for a technology-driven society.
ER  - 

TY  - JOUR
T1  - Interbody Fusion Cage Design Driven by Topology Optimization
AU  - Wang, Zuowei
AU  - Jiang, Jun
AU  - Jian, Fengzeng
AU  - Chen, Zan
AU  - Wang, Xingwen
AU  - Duan, Wanru
AU  - Zhang, Weisheng
JO  - World Neurosurgery
VL  - 174
SP  - e131
EP  - e143
PY  - 2023
DA  - 2023/06/01/
SN  - 1878-8750
DO  - https://doi.org/10.1016/j.wneu.2023.03.010
UR  - https://www.sciencedirect.com/science/article/pii/S1878875023003042
KW  - Fusion cage design
KW  - Interbody fusion
KW  - Moving morphable void approach
KW  - Topology optimization
AB  - Objective
We used topology optimization technology to explore the new theory and method of interbody fusion cage design and realized an innovative design of interbody cages.
Methods
The lumbar spine of a normal healthy volunteer was scanned to perform reverse modeling. Based on the scan data for the L1-L2 segments of the lumbar spine, a three dimensional model was reconstructed to obtain the complete simulation model of the L1-L2 segment. The boundary inversion method was used to obtain approximately isotropic material parameters that can effectively characterize the mechanical behavior of vertebrae, thereby reducing the computational complexity. The topology description function was used to model the clinically used traditional fusion cage to obtain Cage A. The moving morphable void-based topology optimization method was used for the integrated design of size, shape, and topology to obtain the optimized fusion cage, Cage B.
Results
The volume fraction of the bone graft window in Cage B was 74.02%, which was 60.67% higher than that (46.07%) in Cage A. Additionally, the structural strain energy in the design domain of Cage B was 1.48 mJ, which was lower than that of Cage A (satisfying the constraints). The maximum stress in the design domain of Cage B was 5.336 Mpa, which was 35.6% lower than that (8.286 Mpa) of Cage A. In addition, the surface stress distribution of Cage B was more uniform than that of Cage A.
Conclusions
This study proposed a new innovative design method for interbody fusion cages, which not only provides new insights into the innovative design of interbody fusion cages but may also guide the customized design of interbody fusion cages in different pathological environments.
ER  - 

TY  - JOUR
T1  - The role of mathematical vocabulary in the development of mathematical skills for Spanish-speaking students
AU  - Susperreguy, María Inés
AU  - Di Lonardo Burr, Sabrina M.
AU  - Xu, Chang
AU  - Douglas, Heather P.
AU  - Bourque, Taeko
AU  - del Río, M. Francisca
AU  - Salinas, Viviana
AU  - LeFevre, Jo-Anne
JO  - Cognitive Development
VL  - 70
SP  - 101441
PY  - 2024
DA  - 2024/04/01/
SN  - 0885-2014
DO  - https://doi.org/10.1016/j.cogdev.2024.101441
UR  - https://www.sciencedirect.com/science/article/pii/S0885201424000261
KW  - Mathematical language
KW  - Mathematical vocabulary
KW  - Mathematics
KW  - Math growth
KW  - Chile
AB  - Does mathematical vocabulary predict the change in students’ performance on mathematical tasks from one academic year to the next? Chilean Spanish-speaking students (N = 87) completed measures of mathematical vocabulary, mathematical skills (i.e., arithmetic fluency, calculation, and applied problems), receptive vocabulary, and working memory in Grade 2 (T1, Mage = 7:11 years:months, SD = 0:5, 46% girls). One year later (T2) they completed the same mathematical measures. Concurrent relations were found between mathematical vocabulary and the three mathematical skills at both time points. Together, general and mathematical vocabulary at T1 explained significant unique variance in the change in applied problems and calculation from T1 to T2. For calculation however, only mathematical vocabulary predicted significant unique variance in the change from T1 to T2. Change in arithmetic fluency was only predicted by working memory. These results address the roles of general and mathematical vocabulary in students’ mathematical development in elementary school.
ER  - 

TY  - JOUR
T1  - Advances in evolution and genetics: Implications for technology strategy
AU  - Phillips, Fred
AU  - Su, Yu-Shan
JO  - Technological Forecasting and Social Change
VL  - 76
IS  - 5
SP  - 597
EP  - 607
PY  - 2009
DA  - 2009/06/01/
T2  - Two Special Sections: Advances in Evolution and Genetics: Implications for Technology Strategy The Digital Economy in Asia
SN  - 0040-1625
DO  - https://doi.org/10.1016/j.techfore.2008.08.006
UR  - https://www.sciencedirect.com/science/article/pii/S0040162508001522
KW  - Evolution
KW  - Selection
KW  - Genetics
KW  - Technology strategy
KW  - Technology forecasting
AB  - Genetic and evolutionary principles are of great importance to technology strategists, both directly (as in the forecasting of genetic engineering technologies) and as a source of metaphor and perspective on socio-technical change. Recent rapid progress in the molecular sciences have revealed new genetic mechanisms of evolution, and introduced new controversies of interpretation. How do these recent developments affect technology forecasting and our view of technological evolution? This paper provides a quick primer for TFSC readers on several new developments in evolution and genetics, comments upon a number of common misconceptions and pitfalls in evolutionary thinking, and critically describes some controversies and open questions, introducing key readings and sources. It relates genetic and evolutionary knowledge, analogies and metaphors to areas of interest to researchers in technology forecasting and assessment, noting possible future directions. The paper concludes with an overview of the other papers in this special section.
ER  - 

TY  - JOUR
T1  - Inexpensive fusion methods for enhancing feature detection
AU  - Wilkins, Peter
AU  - Adamek, Tomasz
AU  - O’Connor, Noel E.
AU  - Smeaton, Alan F.
JO  - Signal Processing: Image Communication
VL  - 22
IS  - 7
SP  - 635
EP  - 650
PY  - 2007
DA  - 2007/08/01/
T2  - "Special Issue on Content-Based Multimedia Indexing and Retrieval"
SN  - 0923-5965
DO  - https://doi.org/10.1016/j.image.2007.05.012
UR  - https://www.sciencedirect.com/science/article/pii/S0923596507000732
KW  - Feature detection
KW  - Data fusion
KW  - TRECVID
AB  - Recent successful approaches to high-level feature detection in image and video data have treated the problem as a pattern classification task. These typically leverage the techniques learned from statistical machine learning, coupled with ensemble architectures that create multiple feature detection models. Once created, co-occurrence between learned features can be captured to further boost performance. At multiple stages throughout these frameworks, various pieces of evidence can be fused together in order to boost performance. These approaches whilst very successful are computationally expensive, and depending on the task, require the use of significant computational resources. In this paper we propose two fusion methods that aim to combine the output of an initial basic statistical machine learning approach with a lower-quality information source, in order to gain diversity in the classified results whilst requiring only modest computing resources. Our approaches, validated experimentally on TRECVid data, are designed to be complementary to existing frameworks and can be regarded as possible replacements for the more computationally expensive combination strategies used elsewhere.
ER  - 

TY  - JOUR
T1  - A 2D-SWEs framework for efficient catchment-scale simulations: Hydrodynamic scaling properties of river networks and implications for non-uniform grids generation
AU  - Costabile, Pierfranco
AU  - Costanzo, Carmelina
JO  - Journal of Hydrology
VL  - 599
SP  - 126306
PY  - 2021
DA  - 2021/08/01/
SN  - 0022-1694
DO  - https://doi.org/10.1016/j.jhydrol.2021.126306
UR  - https://www.sciencedirect.com/science/article/pii/S002216942100353X
KW  - 2D shallow water equations
KW  - Surface runoff
KW  - River networks
KW  - Non-uniform grids
KW  - Channel heads
KW  - Scaling laws
AB  - The application of two-dimensional shallow-water equations models (2D-SWEs) for the description of hydrodynamic-based surface runoff computations is becoming a reference approach in rainfall-runoff simulations at the catchment scale. Due to their ability in generation of flow patterns throughout the basin, they can be used not only as an advanced method for flood mapping studies and hazard assessment but also as an innovative tool for the analysis of river drainage networks, opening new perspectives for several environmental processes. In particular, in this work we put the river networks in a 2D-SWEs framework, meaning that the traditional tree-like fluvial structure, represented by a skeleton composed of a set of lines, is replaced by a collection of points discretizing the 2-D geometry of the river structure itself, for which the values of the hydrodynamic values are provided by the numerical simulations. This approach is used here to derive a new scaling property that relates the specific discharge threshold, used to identify the river network cells, to the total areas of the network cells themselves. The hydrodynamic and geomorphological interpretation of this power law function and the influence of grid resolution, on some relevant parameters of this curve, have inspired the development of a heuristic procedure for non-uniform grid generation, able to detect the most hydrodynamically active areas of the basins for which the grid refinement process makes sense. Moreover, information related to how much grid refinement is needed is provided as well. The performances of this procedure are very promising in terms of accuracy of simulated discharges, hydrodynamic behaviour of the river network and flooded areas, reducing significantly the computational times in respect to the use of fine uniform grids.
ER  - 

TY  - JOUR
T1  - Brain morphometry predicts individual creative potential and the ability to combine remote ideas
AU  - Bendetowicz, David
AU  - Urbanski, Marika
AU  - Aichelburg, Clarisse
AU  - Levy, Richard
AU  - Volle, Emmanuelle
JO  - Cortex
VL  - 86
SP  - 216
EP  - 229
PY  - 2017
DA  - 2017/01/01/
T2  - Is a "single" brain model sufficient?
SN  - 0010-9452
DO  - https://doi.org/10.1016/j.cortex.2016.10.021
UR  - https://www.sciencedirect.com/science/article/pii/S0010945216303161
KW  - Creativity
KW  - Semantic associations
KW  - Rostral prefrontal
KW  - Frontal pole
KW  - Morphometry
AB  - For complex mental functions such as creative thinking, inter-individual variability is useful to better understand the underlying cognitive components and brain anatomy. Associative theories propose that creative individuals have flexible semantic associations, which allows remote elements to be formed into new combinations. However, the structural brain variability associated with the ability to combine remote associates has not been explored. To address this question, we performed a voxel-based morphometry (VBM) study and explored the anatomical connectivity of significant regions. We developed a Remote Combination Association Task adapted from Mednick's test, in which subjects had to find a solution word related to three cue words presented to them. In our adaptation of the task, we used free association norms to quantify the associative distance between the cue words and solution words, and we varied this distance. The tendency to solve the task with insight and the ability to evaluate the appropriateness of a proposed solution were also analysed. Fifty-four healthy volunteers performed this task and underwent a structural MRI. Structure–function relationships were analysed using regression models between grey matter (GM) volume and task performance. Significant clusters were mapped onto an atlas of white matter (WM) tracts. The ability to solve the task, which depended on the associative distance of the solution word, was associated with structural variation in the left rostrolateral prefrontal and posterior parietal regions; the left rostral prefrontal region was connected to distant regions through long-range pathways. By using a creative combination task in which the semantic distance between words varied, we revealed a brain network centred on the left frontal pole that appears to support the ability to combine information in new ways by bridging the semantic distance between pieces of information.
ER  - 

TY  - JOUR
T1  - Performance enhancement of artificial intelligence: A survey
AU  - Krichen, Moez
AU  - Abdalzaher, Mohamed S.
JO  - Journal of Network and Computer Applications
VL  - 232
SP  - 104034
PY  - 2024
DA  - 2024/12/01/
SN  - 1084-8045
DO  - https://doi.org/10.1016/j.jnca.2024.104034
UR  - https://www.sciencedirect.com/science/article/pii/S108480452400211X
KW  - Performance evaluation
KW  - Optimization techniques
KW  - Machine learning
KW  - Artificial intelligence
KW  - Data processing approaches
AB  - The advent of machine learning (ML) and Artificial intelligence (AI) has brought about a significant transformation across multiple industries, as it has facilitated the automation of jobs, extraction of valuable insights from extensive datasets, and facilitation of sophisticated decision-making processes. Nevertheless, optimizing efficiency has become a critical research field due to AI systems’ increasing complexity and resource requirements. This paper provides an extensive examination of several techniques and methodologies aimed at improving the efficiency of ML and artificial intelligence. In this study, we investigate many areas of research about AI. These areas include algorithmic improvements, hardware acceleration techniques, data pretreatment methods, model compression approaches, distributed computing frameworks, energy-efficient strategies, fundamental concepts related to AI, AI efficiency evaluation, and formal methodologies. Furthermore, we engage in an examination of the obstacles and prospective avenues in this particular domain. This paper offers a deep analysis of many subjects to equip researchers and practitioners with sufficient strategies to enhance efficiency within ML and AI systems. More particularly, the paper provides an extensive analysis of efficiency-enhancing techniques across multiple dimensions: algorithmic advancements, hardware acceleration, data processing, model compression, distributed computing, and energy consumption.
ER  - 

TY  - JOUR
T1  - Exact satisfiability of linear CNF formulas
AU  - Schuh, Bernd R.
JO  - Discrete Applied Mathematics
VL  - 251
SP  - 1
EP  - 4
PY  - 2018
DA  - 2018/12/31/
SN  - 0166-218X
DO  - https://doi.org/10.1016/j.dam.2018.05.018
UR  - https://www.sciencedirect.com/science/article/pii/S0166218X18302762
KW  - Complexity
KW  - XSAT
KW  - Exact linear formula
KW  - l-regularity
KW  - k-uniformity
KW  - NP-completeness
AB  - Open questions with respect to the computational complexity of linear CNF (LCNF) formulas are addressed. Focus lies on exact linear CNF formulas (XLCNF), in which any two clauses have exactly one variable in common. It is shown that l-regularity, i.e. each variable occurs exactly l times in the formula, imposes severe restrictions on the structure of XLCNF formulas. In particular it is proven that l-regularity in XLCNF implies k-uniformity, i.e. all clauses have the same number k of literals. Allowed k- values obey k (k−1)=0 (mod l), and the number of clauses m is given by m =kl-(k−1). Then the computational complexity of monotone l-regular XLCNF formulas with respect to exact satisfiability (XSAT) is determined. XSAT turns out to be either trivial, if m is not a multiple of l, or it can be decided in sub-exponential time, namely O(nn).
ER  - 

TY  - JOUR
T1  - TRIZ and the Paradigms of Social Sustainability in Product Development Endeavors
AU  - Hede, Shantesh
AU  - Ferreira, Paula Verandas
AU  - Lopes, Manuel Nunes
AU  - Rocha, Luis Alexandre
JO  - Procedia Engineering
VL  - 131
SP  - 522
EP  - 538
PY  - 2015
DA  - 2015/01/01/
T2  - TRIZ and Knowledge-Based Innovation in Science and Industry
SN  - 1877-7058
DO  - https://doi.org/10.1016/j.proeng.2015.12.447
UR  - https://www.sciencedirect.com/science/article/pii/S1877705815043398
KW  - Sustainability
KW  - Decision Modeling
KW  - TRIZ
KW  - Product Development ;
AB  - The Business practices of an industrialized civilization are responsible for intensifying the dynamics of the interdependent environmental, social and economic domains of our ecosystem. The worldwide objective to accomplish Sustainability is invariably addressed by Policy makers and Institutions by means of moderately disparate co-relations between Environmental and Social considerations. The dimension of Social Sustainability has a direct co-relation towards the extended continuation of a globalized Enterprise. The stated co-relation is an interconnected and interdependent network comprising of growth in Innovation and Sustainability at the Environmental and Economic frontiers. From the standpoint of Innovation, the 20th century has been dominated by both TRIZ with OTSM and Kurzweil's Law of Accelerating Returns to steer the future of revolutionary innovations. Moreover, TRIZ and its evolved counterpart OTSM have been extensively utilized for macro-scale problem solving scenarios, while Kurzweil's Law has reached up to quantum scale whereby matter as we know exhibits an entire range of unique properties with a potential to dramatically transform our human civilization. Accordingly, the perceived limitations and vague applicability of TRIZ in sub-macro scale innovations has been discussed. The contemporary tools for project evaluation (e.g.: cost benefit analysis) and product development (e.g.: linear stage-gate process) quintessential for commercializing innovations are identified to be limited, both in scope and accuracy for delivering a long term ‘sustainable’ competitive advantage to an Enterprise. Consequently, the proposed conceptual Multifaceted Framework addresses the issue of social sustainability in Product Development. The underpinnings of Systems Thinking, TRIZ and OTSM, Complex Adaptive Systems, Socio-Economics & Human Behavior forms the fundamental basis of the proposed Multifaceted Framework. The novel perspective offered by the proposed Framework enables product development teams to overcome the inherent myopia and other limitations associated with the contemporary Environmental Life Cycle Analysis and Sustainability related Decision Models. An Expert opinion based evaluation technique in conjugation with a Multilayered Decision Modeling Method have been incorporated as a salient features in the proposed framework. The evaluation technique is utilized for assigning numerical values to the pertinent sustainability related criteria of the Multilayered Decision Model. The proposed Framework plays a crucial role in product development and decision modeling across the Idea Screening Phase (Stage 2) up to the Feasibility Analysis Phase (Stage 4). In addition, a modified version Taguchi Loss Function is included to exemplify a tangible relation between Product Quality parameters and Sustainability. The objective of the proposed framework is to provide an efficient, yet comprehensive evaluation as well as an effective product development strategy with a distinct and a holistic outlook on Social Sustainability.
ER  - 

TY  - JOUR
T1  - Induction approach via P-Graph to rank clean technologies
AU  - Low, C.X.
AU  - Ng, W.Y.
AU  - Putra, Z.A.
AU  - Aviso, K.B.
AU  - Promentilla, M.A.B.
AU  - Tan, R.R.
JO  - Heliyon
VL  - 6
IS  - 1
SP  - e03083
PY  - 2020
DA  - 2020/01/01/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2019.e03083
UR  - https://www.sciencedirect.com/science/article/pii/S2405844019367428
KW  - Chemical engineering
KW  - Optimal selection
KW  - Simple additive weighting
KW  - Clean technologies
KW  - Induction
KW  - Decision analysis
KW  - P-Graph
AB  - Identification of appropriate clean technologies for industrial implementation requires systematic evaluation based on a set of criteria that normally reflect economic, technical, environmental and other aspects. Such multiple attribute decision-making (MADM) problems involve rating a finite set of alternatives with respect to multiple potentially conflicting criteria. Conventional MADM approaches often involve explicit trade-offs in between criteria based on the expert's or decision maker's priorities. In practice, many experts arrive at decisions based on their tacit knowledge. This paper presents a new induction approach, wherein the implicit preference rules that estimate the expert's thinking pathways can be induced. P-graph framework is applied to the induction approach as it adds the advantage of being able to determine both optimal and near-optimal solutions that best approximate the decision structure of an expert. The method elicits the knowledge of experts from their ranking of a small set of sample alternatives. Then, the information is processed to induce implicit rules which are subsequently used to rank new alternatives. Hence, the expert's preferences are approximated by the new rankings. The proposed induction approach is demonstrated in the case study on the ranking of Negative Emission Technologies (NETs) viability for industry implementation.
ER  - 

TY  - JOUR
T1  - High energy capacity or high power rating: Which is the more important performance metric for battery energy storage systems at different penetrations of variable renewables?
AU  - Li, Mingquan
AU  - Shan, Rui
AU  - Abdulla, Ahmed
AU  - Tian, Jialin
AU  - Gao, Shuo
JO  - Journal of Energy Storage
VL  - 59
SP  - 106560
PY  - 2023
DA  - 2023/03/01/
SN  - 2352-152X
DO  - https://doi.org/10.1016/j.est.2022.106560
UR  - https://www.sciencedirect.com/science/article/pii/S2352152X2202549X
KW  - Energy storage
KW  - Energy-to-power ratio (EPR)
KW  - Decarbonization
KW  - Carbon emissions
KW  - Renewable integration
KW  - Low-carbon transition
AB  - Studies exploring the role and value of energy storage in deep decarbonization often overlook the balance between the energy capacity and the power rating of storage systems—a key performance parameter that can affect every part of storage operation. Here, we quantitatively evaluate the system-wide impacts of battery storage systems with various energy-to-power ratios (EPRs) and at different levels of renewable penetration. We take Jiangsu province in China as our case study, due to its high electricity consumption and aggressive renewable energy targets. Our results show the evolving role of storage: as renewable penetration increases, higher EPRs are favored, as they lead to system-wide cost reductions, lower GHG emissions, and higher power system reliability. Whereas existing studies make exogenous assumptions about the lifetime of storage, we show that lifetimes across EPRs and renewable scenarios span 10 to 20 years. Existing research can thus send false signals to investors and grid planners, delaying the deployment of storage and retarding the energy transition. By showing how different EPRs yield different benefits at different stages of the energy transition, our results help investors, policy makers, and system planners design forward-thinking and dynamic policies that encourage prudent storage uptake.
ER  - 

TY  - JOUR
T1  - Thermomechanical contact homogenization with random rough surfaces and microscopic contact resistance
AU  - Temizer, İ.
JO  - Tribology International
VL  - 44
IS  - 2
SP  - 114
EP  - 124
PY  - 2011
DA  - 2011/02/01/
SN  - 0301-679X
DO  - https://doi.org/10.1016/j.triboint.2010.09.011
UR  - https://www.sciencedirect.com/science/article/pii/S0301679X10002318
KW  - Contact mechanics
KW  - Homogenization
KW  - Thermal contact resistance
KW  - Randomness
AB  - We extend an earlier computational thermomechanical contact homogenization framework [Temizer İ, Wriggers P. International Journal for Numerical Methods in Engineering 2010; 83:27–58] to random rough surfaces generated through the random-field model based on the concepts of ensemble averaging and sample enlargement towards the effective limit. Additionally, the homogenization theory is revisited in order to incorporate thermal dissipation at the microscopic contact interface within a thermodynamically consistent approach that preserves dissipation across the scales. Large-scale three-dimensional computations were performed to demonstrate the effectiveness and feasibility of the computational framework for an accurate characterization of the macroscopic thermomechanical response of rough surfaces in contact.
ER  - 

TY  - JOUR
T1  - Model for deep learning-based skill transfer in an assembly process
AU  - Wang, Kung-Jeng
AU  - Juni Asrini, Luh
AU  - Sanjaya, Lucy
AU  - Nguyen, Hong-Phuc
JO  - Advanced Engineering Informatics
VL  - 52
SP  - 101643
PY  - 2022
DA  - 2022/04/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2022.101643
UR  - https://www.sciencedirect.com/science/article/pii/S1474034622001070
KW  - Convolutional neural network
KW  - Deep learning
KW  - Faster region-based convolutional neural network
KW  - Human machine interaction
KW  - Skill transfer
AB  - As the variety of products and manufacturing processes increases, the expansion of flexible training approaches is crucial to support the development of human skills. This study presents a model for skill transfer support that extracts experts’ relevant skills as actions and objects relevant to the action into a computational model for transferring skills. This model engages two modes of deep learning as the groundwork, namely, convolutional neural network (CNN) for action recognition and faster region-based convolutional neural network (R-CNN) for object detection. To evaluate the performance of the proposed model, a case study of the final assembly of a GPU card is conducted. The accuracy of CNN and faster R-CNN are 95.4% and 96.8%, respectively. The goal of this model is to guide junior operators during the assembly by providing step-by-step instructions in performing complex tasks. The present study facilitates flexible training in terms of adapting new skills from skilled operators to naïve operators by deep learning.
ER  - 

TY  - JOUR
T1  - Progressive Circuit Changes during Learning and Disease
AU  - Barth, Alison L.
AU  - Ray, Ajit
JO  - Neuron
VL  - 104
IS  - 1
SP  - 37
EP  - 46
PY  - 2019
DA  - 2019/10/09/
SN  - 0896-6273
DO  - https://doi.org/10.1016/j.neuron.2019.09.032
UR  - https://www.sciencedirect.com/science/article/pii/S0896627319308347
AB  - A critical step toward understanding cognition, learning, and brain dysfunction will be identification of the underlying cellular computations that occur in and across discrete brain areas, as well as how they are progressively altered by experience or disease. These computations will be revealed by targeted analyses of the neurons that perform these calculations, defined not only by their firing properties but also by their molecular identity and how they are wired within the local and broad-scale network of the brain. New studies that take advantage of sophisticated genetic tools for cell-type-specific identification and control are revealing how learning and neurological disorders initiate and successively change the properties of defined neural circuits. Understanding the temporal sequence of adaptive or pathological synaptic changes across multiple synapses within a network will shed light into how small-scale neural circuits contribute to higher cognitive functions during learning and disease.
ER  - 

TY  - JOUR
T1  - Intricacies of mega and complex projects: a survey of AAMI Park, Australia
AU  - McIntosh, Jennifer
AU  - Harris, Sophia
AU  - Taylor, Josh Scott
AU  - Gharehbaghi, Koorosh
AU  - Hurst, Neville
AU  - Tee, Kong Fah
JO  - Infrastructure Asset Management
VL  - 11
IS  - 3
SP  - 172
EP  - 188
PY  - 2024
DA  - 2024/09/13/
SN  - 2053-0250
DO  - https://doi.org/10.1680/jinam.24.00003
UR  - https://www.sciencedirect.com/science/article/pii/S2053025024000071
KW  - design complexity
KW  - environmental considerations
KW  - infrastructure asset management
KW  - mapping complexity science
KW  - mega & complex projects
KW  - UN SDG 11: Sustainable cities and communities
KW  - UN SDG 13: Climate action
AB  - Complexity science brings together differing paradigms and thoughts. It has attracted academic interest as a means of understanding complex social and technological phenomena. The emergence of increasingly complex building design, construction and technologies is posing numerous challenges for professionals. This paper utilises complexity science, and the practical application of complexity theories, to evaluate holistically the development of a unique major sporting stadium, known as AAMI Park, in Melbourne, Australia. The authors assess the complexity of this project and rank it on a complexity scale to illustrate the level of knowledge and expertise required to deliver such projects. The most dominant and complex feature of AAMI Park, the bio-frame roof, which was innovative at the time, posed unique challenges. Therefore, the authors also evaluate the constraints and specific project delivery methods developed to manage best its complications. Since the adaptive management approach was used for this project, this paper assessed this approach to recommend enhanced delivery methodologies for similar future projects. Further, since the design of this project was the first of a kind, the authors seek to identify the level of project complexity and its success through the lens of complexity theory.
ER  - 

TY  - JOUR
T1  - Safety evaluations on unignited high-pressure methane jets impacting a spherical obstacle
AU  - Colombini, Cristian
AU  - Carminati, Edoardo
AU  - Parisi, Andrea
AU  - Rota, Renato
AU  - Busini, Valentina
JO  - Journal of Loss Prevention in the Process Industries
VL  - 74
SP  - 104631
PY  - 2022
DA  - 2022/01/01/
SN  - 0950-4230
DO  - https://doi.org/10.1016/j.jlp.2021.104631
UR  - https://www.sciencedirect.com/science/article/pii/S0950423021002400
KW  - High-pressure release
KW  - Methane
KW  - Spherical obstacle influence
KW  - Risk assessment
KW  - CFD
KW  - Analytical correlation
AB  - Nowadays methane is a fossil fuel widely used both in industries and in civil appliances. From the safety point of view, due to its flammability, its use implies hazards for people and assets. The hazardous area related to a high-pressure jet of methane arising from an accidental loss of containment requires the estimation of the distance at which the methane concentration falls below the Lower Flammability limit. Such a topic is well covered in the literature when considering free jet conditions, i.e., jets that do not interact with any equipment or surface. The same cannot be said for high pressure jets impacting an obstacle. In this context, the present work focuses on studying high pressure methane jets impacting spherical obstacles by means of Computational Fluid Dynamics with the aim of giving some insights about such a jet-obstacle interaction, possibly providing a brief by-hand procedure that, only based on known scenario information, allows to estimate the maximum extent of the unignited high-pressure jet when interacting with a spherical obstacle.
ER  - 

TY  - JOUR
T1  - Artificial intelligence as a tool for creativity
AU  - Ivcevic, Zorana
AU  - Grandinetti, Mike
JO  - Journal of Creativity
VL  - 34
IS  - 2
SP  - 100079
PY  - 2024
DA  - 2024/08/01/
SN  - 2713-3745
DO  - https://doi.org/10.1016/j.yjoc.2024.100079
UR  - https://www.sciencedirect.com/science/article/pii/S2713374524000050
KW  - Artificial intelligence
KW  - Creativity
KW  - AI as tool
KW  - 4c's model of creativity
AB  - The release of ChatGPT has sparked quite a bit of interest about creativity in the context of artificial intelligence (AI), with theorizing and empirical research asking questions about the nature of creativity (both human and artificially-produced) and the valuing of work produced by humans and artificial means. In this article, we discuss one specific scenario identified in the creativity research community – co-creation, or use of AI as a tool that could augment human creativity. We present emerging research relevant to how AI can be used on a continuum of four levels of creativity, from mini-c/creativity in learning to little-c/everyday creativity to Pro-C/professional creativity and Big-C/eminent creativity. In this discussion, AI is defined broadly, not to include only large language models (e.g., ChatGPT) which might approach general AI, but also other computer programs that perform tasks typically understood as requiring human intelligence. We conclude by considering future directions for research on AI as a tool for creativity across the four c's.
ER  - 

TY  - JOUR
T1  - Cortical thickness and formal thought disorder in schizophrenia: An ultra high-field network-based morphometry study
AU  - Palaniyappan, Lena
AU  - Al-Radaideh, Ali
AU  - Gowland, Penny A.
AU  - Liddle, Peter F.
JO  - Progress in Neuro-Psychopharmacology and Biological Psychiatry
VL  - 101
SP  - 109911
PY  - 2020
DA  - 2020/07/13/
SN  - 0278-5846
DO  - https://doi.org/10.1016/j.pnpbp.2020.109911
UR  - https://www.sciencedirect.com/science/article/pii/S0278584619310309
KW  - Disorganisation
KW  - Thought disorder
KW  - Salience network
KW  - Cognitive control
KW  - Language network
KW  - Coherence
AB  - Background
Persistent formal thought disorder (FTD) is a core feature of schizophrenia. Recent cognitive and neuroimaging studies indicate a distinct mechanistic pathway underlying the persistent positive FTD (pFTD or disorganized thinking), though its structural determinants are still elusive. Using network-based cortical thickness estimates from ultra-high field 7-Tesla Magnetic Resonance Imaging (7T MRI), we investigated the structural correlates of pFTD.
Methods
We obtained speech samples and 7T MRI anatomical scans from medicated clinically stable patients with schizophrenia (n = 19) and healthy controls (n = 20). Network-based morphometry was used to estimate the mean cortical thickness of 17 functional networks covering the entire cortical surface from each subject. We also quantified the vertexwise variability of thickness within each network to quantify the spatial coherence of the 17 networks, estimated patients vs. controls differences, and related the thickness of the affected networks to the severity of pFTD.
Results
Patients had reduced thickness of the frontoparietal and default mode networks, and reduced spatial coherence affecting the salience and the frontoparietal control network. A higher burden of positive FTD related to reduced frontoparietal thickness and reduced spatial coherence of the salience network. The presence of positive FTD, but not its severity, related to the reduced thickness of the language network comprising of the superior temporal cortex.
Conclusions
These results suggest that cortical thickness of both cognitive control and language networks underlie the positive FTD in schizophrenia. The structural integrity of cognitive control networks is a critical determinant of the expressed severity of persistent FTD in schizophrenia.
ER  - 

TY  - JOUR
T1  - A rough set, formal concept analysis and SEM-PLS integrated approach towards sustainable wearable computing in the adoption of smartwatch
AU  - Acharjya, D.P.
AU  - Kiruba B, Gladys Gnana
JO  - Sustainable Computing: Informatics and Systems
VL  - 33
SP  - 100647
PY  - 2022
DA  - 2022/01/01/
SN  - 2210-5379
DO  - https://doi.org/10.1016/j.suscom.2021.100647
UR  - https://www.sciencedirect.com/science/article/pii/S221053792100130X
KW  - Rough set
KW  - Wearable computing
KW  - Path diagram
KW  - Composite reliability
KW  - Convergence
KW  - Discriminant validity
AB  - The rapid growth of sustainable computing towards the energy, power and environment seize an immense attention from bigger organizations to an individual life. Besides the world is advancing towards the digital mode and smartwatch is gaining its popularity because of additional importance to improve lifestyle. Moreover, it is not restricted to only time viewer rather paves a way in user's daily life. Therefore, it is highly cardinal in identifying the factors among consumers influencing the adoption of smartwatch in sustainable wearable computing. Traditional data modelling tools limited to technology acceptance model is used to this end. After all the study deals with user's behaviour that includes uncertainties and thus studying such problems using computational intelligence techniques is pivotal. In this research work we hybridize rough set, partial least square, and formal concept analysis to study smartwatch users adoption in wearable computing. Initially, the reliability and validity of the proposed model is analysed using structural equation modelling along with partial least square. Further, decision rules are generated using the rough set. Finally, important factors affecting the user's behavioural adoption towards sustainable wearable computing is discovered using formal concept analysis.
ER  - 

TY  - JOUR
T1  - Students’ 2018 PISA reading self-concept: Identifying predictors and examining model generalizability for emergent bilinguals
AU  - Ramazan, Onur
AU  - Dai, Shenghai
AU  - Danielson, Robert William
AU  - Ardasheva, Yuliya
AU  - Hao, Tao
AU  - Austin, Bruce W.
JO  - Journal of School Psychology
VL  - 101
SP  - 101254
PY  - 2023
DA  - 2023/12/01/
SN  - 0022-4405
DO  - https://doi.org/10.1016/j.jsp.2023.101254
UR  - https://www.sciencedirect.com/science/article/pii/S0022440523000821
KW  - Reading self-concept
KW  - Perception of competence
KW  - PISA 2018
KW  - Machine learning
KW  - Multilevel modeling
AB  - Decades of research have indicated that reading self-concept is an important predictor of reading achievement. During this period, the population of emergent bilinguals has continued to increase within United States' schools. However, the existing literature has tended to examine native English speakers' and emergent bilinguals' reading self-concept in the aggregate, thereby potentially obfuscating the unique pathways through which reading self-concept predicts reading achievement. Furthermore, due to the overreliance of native English speakers in samples relating to theory development, researchers attempting to examine predictors of reading achievement may a priori select variables that are more aligned with native English speakers' experiences. To address this issue, we adopted Elastic Net, which is a theoretically agnostic methodology and machine learning approach to variable selection to identify the proximal and distal predictors of reading self-concept for the entire population; in our study, participants from the United States who participated in PISA 2018 served as the baseline group to determine significant predictors of reading self-concept with the intent of identifying potential new directions for future researchers. Based on Elastic Net analysis, 20 variables at the student level, three variables at the teacher level, and 12 variables at the school level were identified as the most salient predictors of reading self-concept. We then utilized a multilevel modeling approach to test model generalizability of the identified predictors of reading self-concept for emergent bilinguals and native English speakers. We disaggregated and compared findings for both emergent bilinguals and native English speakers. Our results indicate that although some predictors were important for both groups (e.g., perceived information and communications technologies competence), other predictors were not (e.g., competitiveness). Suggestions for future directions and implications of the present study are examined.
ER  - 

TY  - JOUR
T1  - WizardOfMath: A top-down puzzle game with RPG elements to hone the player's arithmetic skills
AU  - Pratama, Mulia
AU  - Yanfi, Yanfi
AU  - Nusantara, Pualam Dipa
JO  - Procedia Computer Science
VL  - 216
SP  - 338
EP  - 345
PY  - 2023
DA  - 2023/01/01/
T2  - 7th International Conference on Computer Science and Computational Intelligence 2022
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2022.12.144
UR  - https://www.sciencedirect.com/science/article/pii/S1877050922022220
KW  - Game
KW  - math
KW  - Game Development Life Cycle
KW  - Game Experience Questionnaire
AB  - As one of the important education subjects’ mathematics difficulties can lead to tension and be described as the most hated or feared subject. This study aims to create a puzzle game application with RPG elements called WizardOfMath to increase a user's interest in mathematics subject. The research method includes a method called Game Development Life Cycle (GDLC), which has a pre-production stage that is suitable for game development rather than the Waterfall method. A game application is built based on the prior requirement gathering. The evaluation was arranged using the Game Experience Questionnaire (GEQ) survey which is performed by providing an online form to the public. Reliability test of GEQ modules meets Cronbach's Alpha value above 0.7 and the validity test of the r table is greater than 0.05. The results calculation of the Game Experience Questionnaire (GEQ) from a total of 55 participants and 3 modular structures, which are the Core module, In-game Module, and Post-game Module obtained an average score of 4.06, 3.88, and 3.57 for positive aspects and 2,72, 2.67, and 2,61 for the negative aspect. The contribution of this study shows this puzzle game application with RPG elements decreased user tension and the negative effect of being involved with mathematics subjects.
ER  - 

TY  - CHAP
T1  - Chapter 17 - More Intelligent Models
AU  - Ni, Daiheng
A2  - Ni, Daiheng
BT  - Traffic Flow Theory
PB  - Butterworth-Heinemann
SP  - 239
EP  - 251
PY  - 2016
DA  - 2016/01/01/
SN  - 978-0-12-804134-5
DO  - https://doi.org/10.1016/B978-0-12-804134-5.00017-9
UR  - https://www.sciencedirect.com/science/article/pii/B9780128041345000179
KW  - Car-following models
KW  - Psycho-physical model
KW  - Carsim model
KW  - Rule-based model
KW  - Neural network model
AB  - Along the lines of car-following models, single-regime models stand at one end and use one equation to handle all driving situations. Models can become increasingly intelligent if they include more and more equations to represent different regimes, such as start-up, speedup, free-flow, approaching, following, and stopping. Even more intelligent models can mimic the way of human thinking—for example, using rules and reasoning based on neural networks.
ER  - 

TY  - JOUR
T1  - On GPU acceleration of common solvers for (quasi-) triangular generalized Lyapunov equations
AU  - Köhler, Martin
AU  - Saak, Jens
JO  - Parallel Computing
VL  - 57
SP  - 212
EP  - 221
PY  - 2016
DA  - 2016/09/01/
SN  - 0167-8191
DO  - https://doi.org/10.1016/j.parco.2016.05.010
UR  - https://www.sciencedirect.com/science/article/pii/S0167819116300436
KW  - Lyapunov equations
KW  - BLAS level-3
KW  - Accelerator device
AB  - The solutions of Lyapunov and generalized Lyapunov equations are a key player in many applications in systems and control theory. Their stable numerical computation, when the full solution is sought, is considered solved since the seminal work of Bartels and Stewart [R. H. Bartels, G. W. Stewart, Solution of the matrix equation AX+XB=C: Algorithm 432, Comm. ACM 15 (1972) 820–826.]. A number of variants of their algorithm have been proposed, but none of them goes beyond BLAS level-2 style implementation. On modern computers, however, the formulation of BLAS level-3 type implementations is crucial to enable optimal usage of cache hierarchies and modern block scheduling methods based on directed acyclic graphs describing the interdependence of single block computations. In this contribution, we present the port of our recent BLAS level-3 algorithm [M. Köhler, J. Saak, On BLAS Level-3 implementations of common solvers for (quasi-) triangular generalized Lyapunov equations, SLICOT Working Note 2014-1, NICONET e.V., available from www.slicot.org (Sep. 2014).] to a GPU accelerator device.
ER  - 

TY  - JOUR
T1  - Aggregate-aware model with bidirectional edge generation for medical image segmentation
AU  - Ma, Shiqiang
AU  - Li, Xuejian
AU  - Tang, Jijun
AU  - Guo, Fei
JO  - Applied Soft Computing
VL  - 163
SP  - 111918
PY  - 2024
DA  - 2024/09/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2024.111918
UR  - https://www.sciencedirect.com/science/article/pii/S1568494624006926
KW  - Medical image segmentation
KW  - Multi-task learning
KW  - Edge generation
KW  - Aggregate-aware
KW  - Ensemble learning
AB  - Accurate segmentation of lesion areas plays an important role in medical imaging-assisted diagnosis and treatment. Accurate boundary information can help doctors develop precise surgical plans and improve patient prognosis. However, automatic segmentation methods often struggle to accurately segment edges due to the random shape, size, and location of regions of interest (ROI). This problem is compounded in medical images, where the difference in pixel intensity between foreground and background is significantly smaller than in natural images. In this study, we propose an aggregate-aware model with bidirectional edge generation (Ambeg) for medical image segmentation. To overcome the problem of blurred edges between foreground and background in medical images, we design a deep learning model via a multi-task learning strategy and obtain richer visual features to guide segmentation. Furthermore, an Edge Feature Fusion (EFF) module is developed to combine spatial correlation information of lesion edges between adjacent images for more accurate edge segmentation. Finally, we design a new evaluation metric, the Boundary DSC segmentation consistency measure, to evaluate the edge segmentation accuracy of medical image segmentation methods. We utilize dilation and erosion operations in morphological methods to construct lesion edge labels. In addition, we use expansion and erosion rates to regulate the dimensions of the edge region to assess the requirements of different diseases for edge segmentation accuracy. The proposed approach is particularly noteworthy for achieving state-of-the-art results on medical image segmentation datasets, including BraTS 2022 (MRI), BraTS 2020 (MRI) and COVID-19–20 (CT), which have different modalities of datasets. It has an impressive Hausdorff distance of 4.62 mm and a sensitivity score of 92.45 % on BraTS 2020. Compared with existing assessment methods such as Dice score, Boundary DSC segmentation consistency measure focuses on the hard-to-segment lesion edge region rather than the easy-to-segment lesion center region, which provides a more comprehensive reference for physicians to choose automatic segmentation methods. In addition, since the boundary shapes of medical images are complex and diverse, we utilize morphological methods to obtain the boundary labels to ensure the smoothness of the boundary. Moreover, the approach is easy to implement and has a low computational cost, making it an attractive option for practical medical imaging applications.
ER  - 

TY  - JOUR
T1  - Augmented Intelligence to Identify Patients With Advanced Heart Failure in an Integrated Health System
AU  - Cheema, Baljash
AU  - Mutharasan, R. Kannan
AU  - Sharma, Aditya
AU  - Jacobs, Maia
AU  - Powers, Kaleigh
AU  - Lehrer, Susan
AU  - Wehbe, Firas H.
AU  - Ronald, Jason
AU  - Pifer, Lindsay
AU  - Rich, Jonathan D.
AU  - Ghafourian, Kambiz
AU  - Tibrewala, Anjan
AU  - McCarthy, Patrick
AU  - Luo, Yuan
AU  - Pham, Duc T.
AU  - Wilcox, Jane E.
AU  - Ahmad, Faraz S.
JO  - JACC: Advances
VL  - 1
IS  - 4
SP  - 100123
PY  - 2022
DA  - 2022/10/01/
SN  - 2772-963X
DO  - https://doi.org/10.1016/j.jacadv.2022.100123
UR  - https://www.sciencedirect.com/science/article/pii/S2772963X22001739
KW  - advanced heart failure
KW  - artificial intelligence
KW  - augmented intelligence
KW  - electronic health record
KW  - integrated healthcare system
KW  - machine learning
AB  - Background
Timely referral for specialist evaluation in patients with advanced heart failure (HF) is a Class 1 recommendation. However, the transition from stage C HF to advanced or stage D HF often goes undetected in routine care, resulting in delayed referral and higher mortality rates.
Objectives
The authors sought to develop an augmented intelligence-enabled workflow using machine learning to identify patients with stage D HF and streamline referral.
Methods
We extracted data on HF patients with encounters from January 1, 2007, to November 30, 2020, from a HF registry within a regional, integrated health system. We created an ensemble machine learning model to predict stage C or stage D HF and integrated the results within the electronic health record.
Results
In a retrospective data set of 14,846 patients, the model had a good positive predictive value (60%) and low sensitivity (25%) for identifying stage D HF in a 100-person, physician-reviewed, holdout test set. During prospective implementation of the workflow from April 1, 2021, to February 15, 2022, 416 patients were reviewed by a clinical coordinator, with agreement between the model and the coordinator in 50.3% of stage D predictions. Twenty-four patients have been scheduled for evaluation in a HF clinic, 4 patients started an evaluation for advanced therapies, and 1 patient received a left ventricular assist device.
Conclusions
An augmented intelligence-enabled workflow was integrated into clinical operations to identify patients with advanced HF. Endeavors such as this require a multidisciplinary team with experience in design thinking, informatics, quality improvement, operations, and health information technology, as well as dedicated resources to monitor and improve performance over time.
ER  - 

TY  - JOUR
T1  - Sensory connection, interest/attention and gamma synchrony in autism or autism, brain connections and preoccupation
AU  - Lawson, Wendy
JO  - Medical Hypotheses
VL  - 80
IS  - 3
SP  - 284
EP  - 288
PY  - 2013
DA  - 2013/03/01/
SN  - 0306-9877
DO  - https://doi.org/10.1016/j.mehy.2012.12.005
UR  - https://www.sciencedirect.com/science/article/pii/S0306987712005415
AB  - Does motivational interest increase gamma synchrony across neuronal networking to enable computation of related sensory inputs that might lead to greater social understanding in autism spectrum conditions (ASC)? Meaning, is it possible/likely that in autism because individuals process one aspect of sensory input at any one time (therefore missing the wider picture in general) when they are motivated/interested or attending to particular stimuli their attention window is widened due to increased gamma synchrony and they might be enabled to connect in ways that do not occur when they are not motivated? This is my current research question. If gamma synchrony is helping with the binding of information from collective sensory inputs, in ASC, when and only if the individual is motivated, then this has huge potential for how learning might be encouraged for individuals with an ASC.
ER  - 

TY  - JOUR
T1  - Surrogate-based optimisation of process systems to recover resources from wastewater
AU  - Durkin, Alex
AU  - Otte, Lennart
AU  - Guo, Miao
JO  - Computers & Chemical Engineering
VL  - 182
SP  - 108584
PY  - 2024
DA  - 2024/03/01/
SN  - 0098-1354
DO  - https://doi.org/10.1016/j.compchemeng.2024.108584
UR  - https://www.sciencedirect.com/science/article/pii/S0098135424000024
KW  - Surrogate modelling
KW  - Derivative-free optimisation
KW  - Resource recovery from wastewater
AB  - Wastewater systems are transitioning towards integrative process systems to recover multiple resources whilst simultaneously satisfying regulations on final effluent quality. This work contributes to the literature by bringing a systems-thinking approach to resource recovery from wastewater, harnessing surrogate modelling and mathematical optimisation techniques to highlight holistic process systems. A surrogate-based process synthesis methodology was presented to harness high-fidelity data from black box process simulations, embedding first principles models, within a superstructure optimisation framework. Modelling tools were developed to facilitate tailored derivative-free optimisation solutions widely applicable to black box optimisation problems. The optimisation of a process system to recover energy and nutrients from a brewery wastewater reveals significant scope to reduce the environmental impacts of food and beverage production systems. Additionally, the application demonstrates the capabilities of the modelling methodology to highlight optimal processes to recover carbon, nitrogen, and phosphorous resources whilst also accounting for uncertainties inherent to wastewater systems.
ER  - 

TY  - JOUR
T1  - A Domain-Specific Modeling approach for supporting the specification of Visual Instructional Design Languages and the building of dedicated editors
AU  - Laforcade, Pierre
JO  - Journal of Visual Languages & Computing
VL  - 21
IS  - 6
SP  - 347
EP  - 358
PY  - 2010
DA  - 2010/12/20/
T2  - Special Issue on Visual Instructional Design Languages
SN  - 1045-926X
DO  - https://doi.org/10.1016/j.jvlc.2010.08.008
UR  - https://www.sciencedirect.com/science/article/pii/S1045926X10000492
KW  - Visual Instructional Design Languages Domain Specific Modeling
KW  - Visual and executable models
AB  - This paper presents, illustrates and discusses theories and practices about the application of a domain-specific modeling (DSM) approach to facilitate the specification of Visual Instructional Design Languages (VIDLs) and the development of dedicated graphical editors. Although this approach still requires software engineering skills, it tackles the need of building VIDLs allowing both visual models for human-interpretation purposes (explicit designs, communication, thinking, etc.) and machine-readable notations for deployment or other instructional design activities. This article proposes a theoretical application and a categorization, based on a domain-oriented separation of concerns of instructional design. It also presents some practical illustrations from experiments of specific DSM tooling. Key lessons learned as well as observed obstacles and challenges to deal with are discussed in order to further develop such an approach.
ER  - 

TY  - JOUR
T1  - A neural network for learning the meaning of objects and words from a featural representation
AU  - Ursino, Mauro
AU  - Cuppini, Cristiano
AU  - Magosso, Elisa
JO  - Neural Networks
VL  - 63
SP  - 234
EP  - 253
PY  - 2015
DA  - 2015/03/01/
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2014.11.009
UR  - https://www.sciencedirect.com/science/article/pii/S0893608014002639
KW  - Semantic memory
KW  - Lexical memory
KW  - Conceptual representation
KW  - Hebb rule
KW  - Dominant features
KW  - Category formation
AB  - The present work investigates how complex semantics can be extracted from the statistics of input features, using an attractor neural network. The study is focused on how feature dominance and feature distinctiveness can be naturally coded using Hebbian training, and how similarity among objects can be managed. The model includes a lexical network (which represents word-forms) and a semantic network composed of several areas: each area is topologically organized (similarity) and codes for a different feature. Synapses in the model are created using Hebb rules with different values for pre-synaptic and post-synaptic thresholds, producing patterns of asymmetrical synapses. This work uses a simple taxonomy of schematic objects (i.e., a vector of features), with shared features (to realize categories) and distinctive features (to have individual members) with different frequency of occurrence. The trained network can solve simple object recognition tasks and object naming tasks by maintaining a distinction between categories and their members, and providing a different role for dominant features vs. marginal features. Marginal features are not evoked in memory when thinking of objects, but they facilitate the reconstruction of objects when provided as input. Finally, the topological organization of features allows the recognition of objects with some modified features.
ER  - 

TY  - JOUR
T1  - Cross-layer progressive attention bilinear fusion method for fine-grained visual classification
AU  - Wang, Chaoqing
AU  - Qian, Yurong
AU  - Gong, Weijun
AU  - Cheng, Junjong
AU  - Wang, Yongqiang
AU  - Wang, Yuefei
JO  - Journal of Visual Communication and Image Representation
VL  - 82
SP  - 103414
PY  - 2022
DA  - 2022/01/01/
SN  - 1047-3203
DO  - https://doi.org/10.1016/j.jvcir.2021.103414
UR  - https://www.sciencedirect.com/science/article/pii/S1047320321002789
KW  - Fine-grained visual classification
KW  - Feature fusion
KW  - Attention
KW  - Progressive
AB  - Fine-grained visual classification (FGVC) is a critical task in the field of computer vision. However, FGVC is full of challenges due to the large intra-class variation and small inter-class variation of the classes to be classified on an image. The key in dealing with the problem is to capture subtle visual differences from the image and effectively represent the discriminative features. Existing methods are often limited by insufficient localization accuracy and insufficient feature representation capabilities. In this paper, we propose a cross-layer progressive attention bilinear fusion (CPABF in short) method, which can efficiently express the characteristics of discriminative regions. The CPABF method involves three components: 1) Cross-Layer Attention (CLA) locates and reinforces the discriminative region with low computational costs; 2) The Cross-Layer Bilinear Fusion Module (CBFM) effectively integrates the semantic information from the low-level to the high-level 3) Progressive Training optimizes the parameters in the network to the best state in a delicate way. The CPABF shows excellent performance on the four FGVC datasets and outperforms some state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - Performance of Softcup® menstrual cup and vulvovaginal swab samples for detection and quantification of genital cytokines
AU  - Pillay, Nashlin
AU  - Mzobe, Gugulethu Favourate
AU  - Letsoalo, Marothi
AU  - Kama, Asavela Olona
AU  - Mtshali, Andile
AU  - Magini, Stanley Nzuzo
AU  - Singh, Nikkishia
AU  - Govender, Vani
AU  - Samsunder, Natasha
AU  - Naidoo, Megeshinee
AU  - Moodley, Dhayendre
AU  - Baxter, Cheryl
AU  - Archary, Derseree
AU  - Ngcapu, Sinaye
JO  - Journal of Immunological Methods
VL  - 528
SP  - 113656
PY  - 2024
DA  - 2024/05/01/
SN  - 0022-1759
DO  - https://doi.org/10.1016/j.jim.2024.113656
UR  - https://www.sciencedirect.com/science/article/pii/S0022175924000413
KW  - Cytokines
KW  - Softcup® menstrual cup
KW  - Vulvovaginal swab
KW  - Detection
KW  - Genital inflammation
AB  - Cytokines are important mediators of immunity in the female genital tract, and their levels may be associated with various reproductive health outcomes. However, the measurement of cytokines and chemokines in vaginal fluid samples may be influenced by a variety of factors, each with the potential to affect the sensitivity and accuracy of the assay, including the interpretation and comparison of data. We measured and compared cytokine milieu in samples collected via Softcup® menstrual cup versus vulvovaginal swabs. One hundred and eighty vulvovaginal swabs from CAPRISA 088 and 42 Softcup supernatants from CAPRISA 016 cohorts of pregnant women were used to measure the concentrations of 28 cytokines through multiplexing. Cytokines measured in this study were detectable in each of the methods however, SoftCup supernatants showed consistently, higher detectability, expression ratios, and mean concentration of cytokines than vulvovaginal swabs. While mean concentrations differed, the majority of cytokines correlated between SoftCup supernatants and vulvovaginal swabs. Additionally, there were no significant differences in a number of participants between the two sampling methods for the classification of genital inflammation. Our findings suggest that SoftCup supernatants and vulvovaginal swab samples are suitable for the collection of genital specimens to study biological markers of genital inflammatory response. However, the Softcup menstrual cup performs better for the detection and quantification of soluble biomarkers that are found in low concentrations in cervicovaginal fluid.
ER  - 

TY  - JOUR
T1  - Linking life cycle sustainability assessment and the sustainable development goals – Calculation of goal achievement
AU  - Barke, Alexander
AU  - Sodhi, Manbir S.
AU  - Thies, Christian
AU  - Spengler, Thomas S.
JO  - Procedia CIRP
VL  - 116
SP  - 618
EP  - 623
PY  - 2023
DA  - 2023/01/01/
T2  - 30th CIRP Life Cycle Engineering Conference
SN  - 2212-8271
DO  - https://doi.org/10.1016/j.procir.2023.02.104
UR  - https://www.sciencedirect.com/science/article/pii/S2212827123000999
KW  - Sustainable development goals (SDGs)
KW  - SDG quantification
KW  - Sustainable development
KW  - Life cycle sustainability assessment
AB  - In 2015, the United Nations General Assembly proposed seventeen Sustainable Development Goals (SDGs) intended to ensure sustainable development worldwide at the economic, environmental, and social levels. SDGs are now being used by some corporations in formulating and expressing business strategies. However, assessing the effects of corporate activities and products regarding their contribution to SDGs is difficult. In this paper, we have developed a method for linking life cycle sustainability assessment (LCSA) with the SDGs and calculating the contribution to SDG achievement. An essential part of this approach is the weighting of LCSA impact categories, which is typically done using equal weighting. This weighting method enables compensation of negative contributions by positive contributions in different impact categories but results in ambiguity in the results. This article identifies alternative weighting methods, integrates them into a computational approach, and determines their influence on the SDG contribution scores. The analysis shows that the use of alternative weights changes SDG contribution scores. However, the same product always has the highest SDG contribution score, regardless of the weighting method used. Nonetheless, the recommendations for action with regard to the total product alternatives would change depending on the weighting method.
ER  - 

TY  - JOUR
T1  - The impact of competitive FPS video games on human's decision-making skills
AU  - Oscarido, Juan
AU  - Siswanto, Zulfikar Airlangga
AU  - Maleke, Devin Akwila
AU  - Gunawan, Alexander Agung Santoso
JO  - Procedia Computer Science
VL  - 216
SP  - 539
EP  - 546
PY  - 2023
DA  - 2023/01/01/
T2  - 7th International Conference on Computer Science and Computational Intelligence 2022
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2022.12.167
UR  - https://www.sciencedirect.com/science/article/pii/S1877050922022451
KW  - decision making
KW  - comparison strategy
KW  - video games
KW  - cognitive skill
KW  - influence-of-games
KW  - game-based learning
AB  - The problem we face today is that many people think that playing games only has a negative impact on a person's brain and behavior. but the fact is that playing games has a positive impact in many ways. The aim of this document is to prove whether video games can really influence human behavior on their decision-making skills. We will test 22 respondents directly who are teenagers and adults around 17 - 25 years old, and we will score them after they have finished playing games with the genre that we decided. The results proved that competitive First-person shooter (FPS) games increase human ability to make decisions quickly and correctly. Many of our participants agree that after playing competitive FPS games, they feel a positive impact on their cognitive skills. Our participants said that they can quickly compare the impact of the decisions they make and choose exactly which is the best course of action.
ER  - 

TY  - CHAP
T1  - Chapter 11 - Cellular Automata Investigations and Emerging Complex System Principles
AU  - Yackinous, William S.
A2  - Yackinous, William S.
BT  - Understanding Complex Ecosystem Dynamics
PB  - Academic Press
CY  - Boston
SP  - 193
EP  - 212
PY  - 2015
DA  - 2015/01/01/
SN  - 978-0-12-802031-9
DO  - https://doi.org/10.1016/B978-0-12-802031-9.00011-5
UR  - https://www.sciencedirect.com/science/article/pii/B9780128020319000115
KW  - Cellular automata
KW  - Cellular automata investigations
KW  - Explicit experimentation
KW  - Cellular automata classes
KW  - Simple programs/simple rules
KW  - Complex system principles
KW  - Computational view of systems
KW  - Computational universality
KW  - Principle of Computational Equivalence
AB  - This chapter is primarily about Stephen Wolfram's innovative cellular automata investigations and his associated ideas on emerging complex system principles. The chapter begins with some cellular automata history and background, and then provides a description of Wolfram's cellular automata “explicit experimentation” work. The experimentation work shows that simple programs with simple rules, repeated over and over, can yield highly complex behavior. Wolfram has identified four classes of cellular automata. Those classes and their characteristics are discussed. The correspondence between cellular automata classes and the attractors of nonlinear dynamics theory is also discussed. Another of Wolfram's important insights is that the behavior of cellular automata is indicative of the behavior of systems in general. That idea is addressed in some detail. The latter part of the chapter addresses Wolfram's computational view of systems. The topics covered include computation as a framework for system principles, the concept of computational universality, and the identification of computationally universal cellular automata. Wolfram's Principle of Computational Equivalence is then described and discussed. The chapter concludes with a summary of my perspectives on the emerging complex system principles.
ER  - 

TY  - JOUR
T1  - A security optimization scheme for data security transmission in UAV-assisted edge networks based on federal learning
AU  - Zhang, Han
AU  - Xue, Jianbin
AU  - Wang, Qi
AU  - Li, Ye
JO  - Ad Hoc Networks
VL  - 150
SP  - 103277
PY  - 2023
DA  - 2023/11/01/
SN  - 1570-8705
DO  - https://doi.org/10.1016/j.adhoc.2023.103277
UR  - https://www.sciencedirect.com/science/article/pii/S157087052300197X
KW  - Communication security
KW  - Mobile edge computing
KW  - Data offloading
KW  - Artificial intelligence
KW  - UAV communication
AB  - To solve the problem that mobile users cannot handle all data tasks by themselves due to the huge amount of data at present, this paper proposes a four-layer model of efficient and secure multiuser multitask computing offload. Since the user needs to offload the data to the server for processing through the wireless communication link, and users have mobility, it is difficult to achieve dynamic updates of user status and data information based on traditional cloud computing data processing methods, and it is difficult to ensure security during data unloading. In this paper, we studied how to realize the efficient and safe transmission of mobile users' data tasks when deploying Mobile Edge Computing (MEC) servers with artificial intelligence to assist in data processing on Unmanned Aerial vehicles (UAVs). First of all, to ensure the efficient use of computing resources, we use compression algorithms to reduce transmission overhead. Secondly, to enhance the security of the data transmission process, we have designed a security layer in the system model, which mainly uses secure multiparty technology to encrypt sensitive data, and a data transmission algorithm based on artificial intelligence is designed to assure the efficient and secure transmission of data in the network. Finally, through the analysis of the simulation results, we can know that the proposed strategy in this study has better performance than other existing strategies.
ER  - 

TY  - JOUR
T1  - Time dependent network resource optimization in cyber–physical systems using game theory
AU  - Ravishankar, Monica
AU  - Stephan, Thompson
AU  - Perumal, Thinagaran
JO  - Computer Communications
VL  - 176
SP  - 1
EP  - 12
PY  - 2021
DA  - 2021/08/01/
SN  - 0140-3664
DO  - https://doi.org/10.1016/j.comcom.2021.04.034
UR  - https://www.sciencedirect.com/science/article/pii/S0140366421001857
KW  - Critical infrastructures
KW  - Cyber–physical systems
KW  - Game theory
KW  - Reinforcement learning technique
KW  - Linguistic fuzzy variables
AB  - The social and economic stability of a country is dependent on critical infrastructures (CIs) whose services range from financial to healthcare and power to transportation and communications. Most of these CIs are cyber–physical systems (CPSs), which integrate the network’s computational and communication capabilities to facilitate the monitoring and controlling of physical processes. Such systems are vulnerable to damage due to natural disasters, physical incidents, or cyber-attacks impacting the CPS organizations managing complex industrial control systems and data acquisition systems. When these CPSs are exposed to systemic cyber risks and cascaded network failures, network administrators need to recover from the compromise under limited resources. This is formulated as an attacker-defender game model to emulate the decision-making process in choosing an appropriate attack/defence mechanism in response to cybersecurity incidents using game theory. To further improve the assumptions made in the pure game-theoretic model, we relax the constraints on the rationality of the players, monetary payoff, and completeness of information by incorporating learning in games using reinforcement learning technique and compute the expected payoff using linguistic fuzzy variables.
ER  - 

TY  - JOUR
T1  - Systems biology, complexity, and the impact on antiepileptic drug discovery
AU  - Margineanu, Doru Georg
JO  - Epilepsy & Behavior
VL  - 38
SP  - 131
EP  - 142
PY  - 2014
DA  - 2014/09/01/
T2  - SI: NEWroscience 2013
SN  - 1525-5050
DO  - https://doi.org/10.1016/j.yebeh.2013.08.029
UR  - https://www.sciencedirect.com/science/article/pii/S1525505013004344
KW  - Systems biology
KW  - Systems/network pharmacology
KW  - Drug resistance in epilepsy
KW  - Antiepileptic drug
KW  - Polypharmacology
KW  - Multitarget drug
KW  - Phenotypic screening
KW  - Modeling
KW  - Drug discovery
AB  - The number of available anticonvulsant drugs increased in the period spanning over more than a century, amounting to the current panoply of nearly two dozen so-called antiepileptic drugs (AEDs). However, none of them actually prevents/reduces the post-brain insult development of epilepsy in man, and in no less than a third of patients with epilepsy, the seizures are not drug-controlled. Plausibly, the enduring limitation of AEDs' efficacy derives from the insufficient understanding of epileptic pathology. This review pinpoints the unbalanced reductionism of the analytic approaches that overlook the intrinsic complexity of epilepsy and of the drug resistance in epilepsy as the core conceptual flaw hampering the discovery of truly antiepileptogenic drugs. A rising awareness of the complexity of epileptic pathology is, however, brought about by the emergence of nonreductionist systems biology (SB) that considers the networks of interactions underlying the normal organismic functions and of SB-based systems (network) pharmacology that aims to restore pathological networks. By now, the systems pharmacology approaches of AED discovery are fairly meager, but their forthcoming development is both a necessity and a realistic prospect, explored in this review. This article is part of a Special Issue entitled “NEWroscience 2013”.
ER  - 

TY  - JOUR
T1  - A survey of mobility-aware Multi-access Edge Computing: Challenges, use cases and future directions
AU  - Singh, Ramesh
AU  - Sukapuram, Radhika
AU  - Chakraborty, Suchetana
JO  - Ad Hoc Networks
VL  - 140
SP  - 103044
PY  - 2023
DA  - 2023/03/01/
SN  - 1570-8705
DO  - https://doi.org/10.1016/j.adhoc.2022.103044
UR  - https://www.sciencedirect.com/science/article/pii/S1570870522002165
KW  - Mobility
KW  - Multi-access Edge Computing
KW  - Task offloading
KW  - Service migration
KW  - Content caching
KW  - Resource allocation
AB  - Many mobile and pervasive applications avail cloud services to reduce overheads in on-device computation. The performance of these services depends on the available bandwidth of the underlying network, the physical proximity of the cloud server and the end devices, the volume of data, the computational capacity of the server, and, importantly, the mobility of the devices hosting the applications. Edge computing promises to provide better performance by bringing services (e.g., a video streaming service) from the cloud to servers near the user. It also enables partial or full offloading of the computation (tasks) and storage functionalities from the User Equipment (UE) to the edge of the network. This saves power and benefits from relatively more powerful devices at the edge. Multi-access Edge Computing (MEC), which supports wireless and wired access technologies, has gained significant research interest. When UEs move, services must continue to operate, tasks may need to be offloaded again, and states related to tasks and services may need to be migrated. In this paper, we focus on four functional components (task/service offloading, resource allocation, content/task caching, and service/task migration) of MEC. We survey the challenges to these and their solutions in the context of UE mobility. Mobility creates challenges during offloading resource-intensive tasks as the user may move while the task is being offloaded. Some of the other challenges are how to jointly allocate computing and communication resources, minimize service down time during migration, and share the backhaul network if the same MEC host must continue to be used. Some key research areas include intelligent task offloading and service migration algorithms, exploiting group mobility to improve task migration time, studying the interplay of MEC parameters such as capabilities of the target MEC host, etc. In addition, predicting the mobile trajectory through intelligent methods and implementations with datasets from real-world scenarios are required. We compare this paper on 11 parameters (service migration, task offloading, resource allocation, content caching, mobility, use cases, architecture, computing paradigm, mobility model, system model, virtualization/Software Defined Networks) with 31 other survey papers from 2018 to April 2022 in MEC and related domains. We discuss the Edge Computing paradigm, the system architecture and model descriptions, and use cases. We briefly explain the relevant challenges and future directions in emerging domains, such as the Internet of drones and Digital twins. We also discuss future research directions in task/service migration, offloading, resource management, distributed computing, reliability, and Quality of Service, all related to mobility in MEC.
ER  - 

TY  - JOUR
T1  - Combining conscious and unconscious knowledge within human-machine-interfaces to foster sustainability with decision-making concerning production processes
AU  - Arnold, Marlen Gabriele
JO  - Journal of Cleaner Production
VL  - 179
SP  - 581
EP  - 592
PY  - 2018
DA  - 2018/04/01/
SN  - 0959-6526
DO  - https://doi.org/10.1016/j.jclepro.2018.01.070
UR  - https://www.sciencedirect.com/science/article/pii/S0959652618300787
KW  - Exploratory design
KW  - Structural systemic constellations
KW  - Cognitive human biases
KW  - HMI
KW  - Sustainable production contexts
AB  - At present, sustainability science is mainly based on conscious information and strongly focused on analytical tools or strategies. Neuroscience has made obvious that human decisions are prepared by the unconsciousness. Intuition plays an important role in early and late stages of learning processes and has a crucial impact on decision-making. Thus, intuitive and unconscious thinking is crucial for management processes in general and production planning processes in the main. However, unconscious knowledge and human behaviour is predominantly neglected in production research. Especially the addressing of human machine interfaces (HMI), human cognitive biases have a crucial impact on decision making processes. Constellation work is based on unconscious knowledge and intuition. Thus, systemic structural constellations are an innovative tool to integrate unconscious knowledge in a research context. In systemic structural constellations specific foci of complex systems, such as a production system, can be simulated and represented through spatial arrangements of persons or symbols. So, the method was used to reveal relevant patterns of relationships, structures, interaction, implicit knowledge, including hidden or underlying dynamics and influences that are relevant to and within a production system to understand how the raised problems in HMI can be better solved. The guiding research question is: How can the use of structural systemic constellations improve decision-making processes in HMI contexts in production environments in order to increase sustainability? Results show sustainability seems to be a matter of consciousness and is closely linked to the bias group not enough meaning. Sustainability and complexity resemble more than being linked by trade-offs. The recognition of human biases can be trained to improve human-machine-interfaces and sustainability. Constellation work contributes to decision theory by supporting effectuation.
ER  - 

TY  - JOUR
T1  - scASGC: An adaptive simplified graph convolution model for clustering single-cell RNA-seq data
AU  - Wang, Shudong
AU  - Zhang, Yu
AU  - Zhang, Yulin
AU  - Wu, Wenhao
AU  - Ye, Lan
AU  - Li, YunYin
AU  - Su, Jionglong
AU  - Pang, Shanchen
JO  - Computers in Biology and Medicine
VL  - 163
SP  - 107152
PY  - 2023
DA  - 2023/09/01/
SN  - 0010-4825
DO  - https://doi.org/10.1016/j.compbiomed.2023.107152
UR  - https://www.sciencedirect.com/science/article/pii/S0010482523006170
KW  - ScRNA-seq
KW  - Clustering
KW  - Bioinformatics
KW  - Graph convolution
KW  - Computational biology
KW  - Machine learning
AB  - Single-cell RNA sequencing (scRNA-seq) is now a successful technique for identifying cellular heterogeneity, revealing novel cell subpopulations, and forecasting developmental trajectories. A crucial component of the processing of scRNA-seq data is the precise identification of cell subpopulations. Although many unsupervised clustering methods have been developed to cluster cell subpopulations, the performance of these methods is vulnerable to dropouts and high dimensionality. In addition, most existing methods are time-consuming and fail to adequately account for potential associations between cells. In the manuscript, we present an unsupervised clustering method based on an adaptive simplified graph convolution model called scASGC. The proposed method builds plausible cell graphs, aggregates neighbor information using a simplified graph convolution model, and adaptively determines the most optimal number of convolution layers for various graphs. Experiments on 12 public datasets show that scASGC outperforms both classical and state-of-the-art clustering methods. In addition, in a study of mouse intestinal muscle containing 15,983 cells, we identified distinct marker genes based on the clustering results of scASGC. The source code of scASGC is available at https://github.com/ZzzOctopus/scASGC.
ER  - 

TY  - JOUR
T1  - FPFS: Filter-level pruning via distance weight measuring filter similarity
AU  - Zhang, Wei
AU  - Wang, Zhiming
JO  - Neurocomputing
VL  - 512
SP  - 40
EP  - 51
PY  - 2022
DA  - 2022/11/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2022.09.049
UR  - https://www.sciencedirect.com/science/article/pii/S092523122201164X
KW  - Model compression
KW  - Neural network pruning
KW  - Distance and similarity
KW  - Deep convolutional neural network (DCNN)
AB  - Deep Neural Networks (DNNs) enjoy the welfare of convolution, while also bearing huge computational pressure. Therefore, model compression techniques are used to alleviate this problem, where filter-based neural network has received extensive attention as the research object of this paper. Common approaches treat filters as independent individuals and choose retrained filters by evaluating their performance, while more complex macro methods consider relationship between filters. Therefore, we propose a facile distance-based filter selection method, called FPFS, to visualize the similarity between filters from a global perspective. We calculate and sum the distance between filters to get filters’ “Distance Weight” which is applied as a metric to assess filters. We use four common and appropriate distances for filters evaluation. To verify the performance of our algorithm, we introduce FPFS to classical DCNNs and test it on general classification datasets CIFAR-10, CIFAR-100 and mageNet. For example, FPFS reduces Parameters and FLOPs of the lightweight model DenseNet-40 to about half of the original while maintain accuracy on CIFAR-10 by 94.40% (the original model is 94.80%). To ResNet-56 on CIFAR-100, FPFS compresses FLOPs to less than half of the original, while model accuracy reaches 71.46% (the original model is 71.44%). About ResNet-50 on ImageNet, FPFS achieves 60.3% FLOPs pruning rate accompanied by 0.96% top-1 accuracy loss. We also compare the experimental results with state-of-the-art filter pruning algorithms to highlight the effectiveness of FPFS.
ER  - 

TY  - CHAP
T1  - Chapter 1 - The Neurobiology of Preferences
AU  - Symmonds, Mkael
AU  - Dolan, Raymond J.
A2  - Dolan, Raymond
A2  - Sharot, Tali
BT  - Neuroscience of Preference and Choice
PB  - Academic Press
CY  - San Diego
SP  - 3
EP  - 31
PY  - 2012
DA  - 2012/01/01/
SN  - 978-0-12-381431-9
DO  - https://doi.org/10.1016/B978-0-12-381431-9.00001-2
UR  - https://www.sciencedirect.com/science/article/pii/B9780123814319000012
KW  - Preference
KW  - choice
KW  - neuroscience
KW  - neuroeconomics
KW  - decision-making
KW  - action
KW  - value
AB  - Publisher Summary
The neuroscience of choice and preference dates back to the nineteenth century, with the emergence of the idea of functional specialization as a fundamental organizational principle of the brain. The development of neuroimaging techniques—in particular, functional magnetic resonance imaging (fMRI)—has meant that questions related to choice and preference can now be addressed non-invasively in humans. There are important examples where choices do not accord with internal wants. An addict may perform an action in the present despite expressing a desire to avoid doing this very action on a prior occasion. A major conundrum when thinking about neurobiological mechanisms in decision-making is the fact that choices are often noisy or stochastic. A different network of regions in precuneus, left prefrontal, and temproparietal cortex reflected endogenous inequity aversion across subjects, illustrating that even within the context of a specific task, preferences for the same stimulus feature can be expressed in different regions and modulated in a distinct manner.
ER  - 

TY  - JOUR
T1  - Deep learning based multi-labelled soil classification and empirical estimation toward sustainable agriculture
AU  - J., Padmapriya
AU  - T., Sasilatha
JO  - Engineering Applications of Artificial Intelligence
VL  - 119
SP  - 105690
PY  - 2023
DA  - 2023/03/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2022.105690
UR  - https://www.sciencedirect.com/science/article/pii/S0952197622006807
KW  - Soil classification
KW  - Q-HOG
KW  - SVM
KW  - Deep Neural Network
KW  - VGG16
AB  - Agriculture is the underlying occupation of the vast people in India and it is a major economic contribution. Soil is prime for the vital nutrient supply to the crops and its yield. Determination of the type of soil which comprises of the clay, sand and silt particles in the respective proportion is indeed significant for the suitable crop selection and to identify the weeds growth. The most commonly utilized soil determination methods were International Pipette method and Pressure-plate apparatus method. In this research work, multiclass soil classification using machine learning and deep learning models for the appropriate determination of the soil type as Multi-Stacking ensemble model and a novel feature selection algorithm Q-HOG is proposed; since the Artificial Intelligence has led to furtherance in the smart agriculture. Besides, the images are collected from the exploration site vriddhachalam along with the soil datasets will increase the classification accuracy. The deep learning models Recurrent Neural Network(RNN), Long Short Term Memory(LSTM), Gated Recurrent Unit(GRU) and VGG16 are considered and the comprehensive evaluation of these different deep learning architectures and also the machine learning algorithms such as Naïve-bayes, KNN, SVM are carried out and the obtained results are tabulated. Multi-stacking ensemble model for multi-classification is proposed with the Machine learning and deep learning algorithms and evaluated the performance with increased computation time. Among these models the proposed model outperformed in soil classification in-terms of accuracy as 98.96 percent, achieved precision as 96.14 percent, recall as 99.65 percent and the achieved F1-Score is 97.87 percent.
ER  - 

TY  - JOUR
T1  - Frame-based guide to situated decision-making on climate change
AU  - de Boer, Joop
AU  - Wardekker, J. Arjan
AU  - van der Sluijs, Jeroen P.
JO  - Global Environmental Change
VL  - 20
IS  - 3
SP  - 502
EP  - 510
PY  - 2010
DA  - 2010/08/01/
T2  - Governance, Complexity and Resilience
SN  - 0959-3780
DO  - https://doi.org/10.1016/j.gloenvcha.2010.03.003
UR  - https://www.sciencedirect.com/science/article/pii/S0959378010000245
KW  - Climate change
KW  - Adaptation
KW  - Decision-making
KW  - Frames
AB  - The present paper describes a frame-based approach to situated-decision-making on climate change. Building on the multidisciplinary literature on the relationship between frames and decision-making, it argues that decision-makers may gain from making frames more explicit and using them for generating different visions about the central issues. Frames act as organizing principles that shape in a “hidden” and taken-for-granted way how people conceptualize an issue. Science-related issues, such as climate change, are often linked to only a few frames, which consistently appear across different policy areas. Indeed, it appears that there are some very contrasting ways in which climate change may be framed. These frames can be characterized in terms of a simple framework that highlights specific interpretations of climate issues. A second framework clarifies the built-in frames of decision tools. Using Thompson's two basic dimensions of decision, it identifies the main uncertainties that should be considered in developing a decision strategy. The paper characterizes four types of decision strategy, focusing on (1) computation, (2) compromise, (3) judgment, or (4) inspiration, and links each strategy to the appropriate methods and tools, as well as the appropriate social structures. Our experiences show that the frame-based guide can work as an eye-opener for decision-makers, particularly where it demonstrates how to add more perspectives to the decision.
ER  - 

TY  - JOUR
T1  - Present and future approaches to lifetime prediction of superelastic nitinol
AU  - Bonsignore, Craig
JO  - Theoretical and Applied Fracture Mechanics
VL  - 92
SP  - 298
EP  - 305
PY  - 2017
DA  - 2017/12/01/
SN  - 0167-8442
DO  - https://doi.org/10.1016/j.tafmec.2017.04.001
UR  - https://www.sciencedirect.com/science/article/pii/S0167844217300587
ER  - 

TY  - JOUR
T1  - Aggregation and Solvation of Sodium Hexamethyldisilazide: Across the Solvent Spectrum
AU  - Woltornist, Ryan A.
AU  - Collum, David B.
JO  - The Journal of Organic Chemistry
VL  - 86
IS  - 3
SP  - 2406
EP  - 2422
PY  - 2021
DA  - 2021/01/01/
SN  - 0022-3263
DO  - https://doi.org/10.1021/acs.joc.0c02546
UR  - https://www.sciencedirect.com/science/article/pii/S002232632101077X
AB  - ABSTRACT
We report solution structures of sodium hexamethyldisilazide (NaHMDS) solvated by >30 standard solvents (ligands). These include: toluene, benzene, and styrene; triethylamine and related trialkylamines; pyrrolidine as a representative dialkylamine; dialkylethers including THF, tert-butylmethyl ether, and diethyl ether; dipolar ligands such as DMF, HMPA, DMSO, and DMPU; a bifunctional dipolar ligand nonamethylimidodiphosphoramide (NIPA); polyamines N,N,N′,N′-tetramethylenediamine (TMEDA), N,N,N′,N″,N″-pentamethyldiethylenetriamine (PMDTA), N,N,N′,N′-tetramethylcyclohexanediamine (TMCDA), and 2,2′-bipyridine; polyethers 12-crown-4, 15-crown-5, 18-crown-6, and diglyme; 4,7,13,16,21,24-hexaoxa-1,10-diazabicyclo[8.8.8]­hexacosane ([2.2.2] cryptand); and tris­[2-(2-methoxyethoxy)­ethyl]­amine (TDA-1). Combinations of 1H, 13C, 15N, and 29Si NMR spectroscopies, the method of continuous variations, X-ray crystallography, and density functional theory (DFT) computations reveal ligand-modulated aggregation to give mixtures of dimers, monomers, triple ions, and ion pairs. 15N–29Si coupling constants distinguish dimers and monomers. Solvation numbers are determined by a combination of solvent titrations, observed free and bound solvent in the slow exchange limit, and DFT computations. The relative abilities of solvents to compete in binary mixtures often match that predicted by conventional wisdom but with some exceptions and evidence of both competitive and cooperative (mixed) solvation. Crystal structures of a NaHMDS cryptate ion pair and a 15-crown-5-solvated monomer are included. Results are compared with those for lithium hexamethyldisilazide, lithium diisopropylamide, and sodium diisopropylamide.
ER  - 

TY  - CHAP
T1  - Chapter 5 - Mathematical modeling driven predication
AU  - Zohuri, Bahman
AU  - Mossavar-Rahmani, Farhang
AU  - Behgounia, Farahnaz
A2  - Zohuri, Bahman
A2  - Mossavar-Rahmani, Farhang
A2  - Behgounia, Farahnaz
BT  - Knowledge is Power in Four Dimensions: Models to Forecast Future Paradigm
PB  - Academic Press
SP  - 121
EP  - 163
PY  - 2022
DA  - 2022/01/01/
SN  - 978-0-323-95112-8
DO  - https://doi.org/10.1016/B978-0-323-95112-8.00005-2
UR  - https://www.sciencedirect.com/science/article/pii/B9780323951128000052
KW  - Data mining and data analytics
KW  - Forecasting and prediction
KW  - Modeling and mathematics
AB  - During the past decade, there has been a tremendous blast and progress in computation technology, and with it comes vast amounts of data in a variety of fields such as the economy, medicine, biology, banking services such as customer relation management and credit card fraud, finance, demographic population growth from a demographical point of view nationwide and worldwide, and the need for new lifestyles and growth in term of continuous renewable sources of energy and its production, as well as marketing are among the fields that can be mentioned. The challenge of understanding these data has led to the development of new tools such as predictive analytics in the field of statistics and spawned new areas such as data mining, machine learning, and bioinformatics to process these data and determine the integrity of their information for prediction analysis. Many of these tools have common underpinnings but are often expressed with different terminology. This chapter will summarize the important ideas in these areas in a common conceptual framework.
ER  - 

TY  - JOUR
T1  - Information retrieval with semantic memory model
AU  - Szymański, Julian
AU  - Duch, Włodzisław
JO  - Cognitive Systems Research
VL  - 14
IS  - 1
SP  - 84
EP  - 100
PY  - 2012
DA  - 2012/04/01/
T2  - Cognitive Systems Research: Special Issue on Modeling and Application of Cognitive Systems
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2011.02.002
UR  - https://www.sciencedirect.com/science/article/pii/S1389041711000179
AB  - Psycholinguistic theories of semantic memory form the basis of understanding of natural language concepts. These theories are used here as an inspiration for implementing a computational model of semantic memory in the form of semantic network. Combining this network with a vector-based object-relation-feature value representation of concepts that includes also weights for confidence and support, allows for recognition of concepts by referring to their features, enabling a semantic search algorithm. This algorithm has been used for word games, in particular the 20-question game in which the program tries to guess a concept that a human player thinks about. The game facilitates lexical knowledge validation and acquisition through the interaction with humans via supervised dialog templates. The elementary linguistic competencies of the proposed model have been evaluated assessing how well it can represent the meaning of linguistic concepts. To study properties of information retrieval based on this type of semantic representation in contexts derived from on-going dialogs experiments in limited domains have been performed. Several similarity measures have been used to compare the completeness of knowledge retrieved automatically and corrected through active dialogs to a “golden standard”. Comparison of semantic search with human performance has been made in a series of 20-question games. On average results achieved by human players were better than those obtained by semantic search, but not by a wide margin.
ER  - 

TY  - JOUR
T1  - The Hutong neighbourhood grammar: A procedural modelling approach to unravel the rationale of historical Beijing urban structure
AU  - Wang, Yuyang
AU  - Crompton, Andrew
AU  - Agkathidis, Asterios
JO  - Frontiers of Architectural Research
VL  - 12
IS  - 3
SP  - 458
EP  - 476
PY  - 2023
DA  - 2023/06/01/
SN  - 2095-2635
DO  - https://doi.org/10.1016/j.foar.2022.12.004
UR  - https://www.sciencedirect.com/science/article/pii/S2095263523000031
KW  - Urban morphology
KW  - Siheyuan
KW  - Hutong neighbourhood
KW  - Procedural modelling
KW  - Shape grammar
AB  - Hutong neighbourhoods, composed of Chinese courtyard dwellings (Siheyuan), are historically and socially significant urban spaces that embody the traditional Chinese way of life and philosophy. As part of the national heritage, there is an increasing research interest in Hutong neighbourhoods, many of which are facing oblivion. This study presents a formal grammar for Hutong neighbourhood generation. This research investigates traditional principles of urban planning of ancient Beijing, based on examples on the historical map Qianlong Jingcheng Quantu, to derive the lost design rules. These rules are used to build up a procedural modelling framework, which reveals the development of Beijing's urban structure from the Yuan (1271–1368) to the Qing (1644–1911) dynasty. Our findings present a grammar incorporated into the procedural modelling framework to parametrically generate Hutong neighbourhoods, which replicates the morphological characteristics of historic cases. It contributes to the understanding of the generation of Hutong neighbourhoods. In support of heritage sustainability, this grammar can be implemented in a computational environment by visual scripting that enables the generation of new instances of Hutong neighbourhoods, both real and virtual.
ER  - 

TY  - JOUR
T1  - Collaboration, cyberinfrastructure, and cognitive science: The role of databases and dataguides in 21st century structural geology
AU  - Shipley, Thomas F.
AU  - Tikoff, Basil
JO  - Journal of Structural Geology
VL  - 125
SP  - 48
EP  - 54
PY  - 2019
DA  - 2019/08/01/
T2  - Back to the future
SN  - 0191-8141
DO  - https://doi.org/10.1016/j.jsg.2018.05.007
UR  - https://www.sciencedirect.com/science/article/pii/S0191814117303164
KW  - Spatial cognition
KW  - Cyberinfrastructure
KW  - Expert training
AB  - Structural geologists support their mind with tools, and these tools are increasingly computer based. The advent of Intelligent Systems will allow creation of research teams that combine the strengths of the human mind and computer processing to produce new research results. The efficacy of these approaches will require a solid grounding in cognitive science. Critical to this approach are databases, which are potentially transformative solely in their ability to allow access to data, in a primary form. Emerging more recently, however, is the concept of a dataguide, in which computer-aided analysis informs ongoing decisions about where and what data to collect. The creation of human and computer teams can expand the types of questions that can be addressed in structural geology and tectonics research, but it will take a community-based effort to understand the value of data to experts and how computers might aid an expert in the field.
ER  - 

TY  - JOUR
T1  - Assessing the Efficacy of Tier 2 Mathematics Intervention for Spanish Primary School Students
AU  - de León, Sara C.
AU  - Jiménez, Juan E.
AU  - Gutiérrez, Nuria
AU  - Hernández-Cabrera, Juan Andrés
JO  - Early Childhood Research Quarterly
VL  - 56
SP  - 281
EP  - 293
PY  - 2021
DA  - 2021/07/01/
SN  - 0885-2006
DO  - https://doi.org/10.1016/j.ecresq.2021.04.003
UR  - https://www.sciencedirect.com/science/article/pii/S0885200621000508
KW  - RtI model
KW  - math
KW  - early grades
KW  - Tier 2
KW  - at-risk
AB  - This study explored the efficacy of a Tier 2 intervention within the context of the Response to Intervention (RtI) model implemented by Spanish first- to third-grade primary school teachers to improve at-risk students’ early math skills. Teachers were instructed in the administration of a math curriculum-based measure composed of 5 isolated measures (quantity discrimination, missing number, single-digit computation, multidigit computation, and place value) to identify at-risk students and to monitor their progress; and in the implementation of a systematic and explicit instructional program to improve basic math skills in at-risk students. Implementation fidelity was analyzed using direct observations and self-reports. The intervention was conducted with adequate fidelity and had a significant positive impact on all grades. Significant differences were found between experimental and control students at risk of math failure in the improvement rate of quantity discrimination, missing number, and place value in all grades. Experimental at-risk students showed a monthly improvement, assessed using a combination of screening and progress monitoring measures. In conclusion, Spanish first to third graders at risk of math failure benefited from a Tier 2 intervention based on basic math skills, implemented by in-service teachers.
ER  - 

TY  - JOUR
T1  - The digital frontier: Envisioning future technologies impact on the classroom
AU  - Leahy, Sean M.
AU  - Holland, Charlotte
AU  - Ward, Francis
JO  - Futures
VL  - 113
SP  - 102422
PY  - 2019
DA  - 2019/10/01/
SN  - 0016-3287
DO  - https://doi.org/10.1016/j.futures.2019.04.009
UR  - https://www.sciencedirect.com/science/article/pii/S0016328718304166
KW  - Artificial intelligence
KW  - Augmented reality
KW  - Smart materials
KW  - Educational technology
KW  - Education futures
KW  - Education
AB  - Global advances in technology and information are purportedly propelling transformations and disruptions across many sectors, including education. However, historical reviews of technology integration in education mainly reveal weak or ineffectual impacts on learning, and only minor reforms to date within the education system. This study adopted a futures studies methodological approach to explore how K-12 educational spaces and experiences might be shaped by emerging and emergent technologies. In this regard, a series of vignettes are presented which critically examine the potential of augmented reality technologies, artificial intelligence, and smart materials technologies to transform future learning experiences and learning environments across K-12 education contexts, while also challenging assumptions about, and considering influences on, these futures. The focus of the study was not to predict a single or desired future for education, but rather to critically consider a range of possible education futures informed by the articulation of these three vignettes. The paper concludes with discourse on an emergent pedagogic approach that has the potential to prepare teachers and learners to interact and flourish within radically re-configured learning spaces that lean on the aforementioned technologies to support transitions within and beyond the school and its connected communities.
ER  - 

TY  - JOUR
T1  - Modelling learning for a better safety culture within an organization using a virtual safety coach: Reducing the risk of postpartum depression via improved communication with parents
AU  - Weigl, Linn-Marie
AU  - Jabeen, Fakhra
AU  - Treur, Jan
AU  - Taal, H. Rob
AU  - Roelofsma, Peter H.M.P.
JO  - Cognitive Systems Research
VL  - 80
SP  - 1
EP  - 36
PY  - 2023
DA  - 2023/08/01/
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2023.01.009
UR  - https://www.sciencedirect.com/science/article/pii/S1389041723000153
KW  - Shared mental models
KW  - virtual AI Coach in healthcare
KW  - Fathers/psychology
KW  - Depressive disorders/complications
KW  - Postpartum depression
AB  - This paper describes an extension of a safety culture within hospital organizations providing more transparency and acknowledgement of all actors, and in particular the parents. It contributes a model architecture to support a hospital to develop such an extended safety culture. It is illustrated for prevention of postpartum depression. Postpartum depression is a commonly known consequence of childbirth for both mothers and fathers. In this research, we computationally analyze the risk factors and lack of support received by fathers. Therefore, we use shared mental models to model the effects of poor and additional communication by healthcare practitioners to mitigate the development of postpartum depression in both the mother and the father. Both individual mental models and shared mental models are considered in the design of the computational model. The paper illustrates the benefits of simple support in terms of communication during childbirth, which has lasting effects, even outside the hospital. For the impact of additional communication, a Virtual Safety Coach is designed that intervenes when necessary to provide support, i.e., when a health care practitioner doesn’t. Moreover, organizational learning is also modelled to improve the mental models of both the Safety Coach and the Health Care Practitioner.
ER  - 

TY  - JOUR
T1  - Approach for the rationalisation of product lines variety
AU  - Giovannini, A.
AU  - Aubry, A.
AU  - Panetto, H.
AU  - Haouzi, H. El
AU  - Pierrel, L.
AU  - Dassisti, M.
JO  - IFAC Proceedings Volumes
VL  - 47
IS  - 3
SP  - 3280
EP  - 3291
PY  - 2014
DA  - 2014/01/01/
T2  - 19th IFAC World Congress
SN  - 1474-6670
DO  - https://doi.org/10.3182/20140824-6-ZA-1003.02226
UR  - https://www.sciencedirect.com/science/article/pii/S1474667016421130
KW  - Mass customization
KW  - Product variety
KW  - Knowledge representation
KW  - Knowledge-based system
AB  - The product variety management is a key process to deal with the flexibility requested by the mass customisation. In this paper we show that current variety-modelling methods miss a customer representation: without a proper assessment of the customers is not possible to define the product variety that has to be developed to meet the requirements of a customer segment. Here we present an innovative approach to rationalise the product variety, i.e. to link each product variant to the customer profile who needs it. The aim is to optimise the product variety avoiding excesses (variants not related to a customer), lacks (customers not related to a variant) or redundancies (two or more variants proposed to a customer). An overview of customer modelling approaches in the classic product design (non-customisable) is presented. The innovative approach is here developed using system-thinking concepts. A knowledge-based system that uses this approach is designed. Finally the approach is explained using a real industrial case of a quasi-real coil design process.
ER  - 

TY  - JOUR
T1  - Quasi-generalized least squares regression estimation with spatial data
AU  - Lu, Cuicui
AU  - Wooldridge, Jeffrey M.
JO  - Economics Letters
VL  - 156
SP  - 138
EP  - 141
PY  - 2017
DA  - 2017/07/01/
SN  - 0165-1765
DO  - https://doi.org/10.1016/j.econlet.2017.04.004
UR  - https://www.sciencedirect.com/science/article/pii/S0165176517301441
KW  - Quasi-GLS
KW  - Spatial correlation
KW  - Covariance tapering
KW  - Spatial HAC estimator
AB  - We use a particular quasi-generalized least squares (QGLS) approach to study a linear regression model with spatially correlated error terms. The QGLS estimator is consistent, asymptotically normal, computationally easier than GLS, and it appears to not lose much efficiency. A variance–covariance estimator for QGLS, which is robust to heteroskedasticity, spatial correlation and general variance–covariance misspecification is provided.
ER  - 

TY  - JOUR
T1  - Training Pathology Residents to Practice 21st Century Medicine: A Proposal
AU  - Black-Schaffer, W. Stephen
AU  - Morrow, Jon S.
AU  - Prystowsky, Michael B.
AU  - Steinberg, Jacob J.
JO  - Academic Pathology
VL  - 3
SP  - 2374289516665393
PY  - 2016
DA  - 2016/01/01/
SN  - 2374-2895
DO  - https://doi.org/10.1177/2374289516665393
UR  - https://www.sciencedirect.com/science/article/pii/S2374289521002189
KW  - competency
KW  - progressive responsibility
KW  - residency training
AB  - Scientific advances, open information access, and evolving health-care economics are disrupting extant models of health-care delivery. Physicians increasingly practice as team members, accountable to payers and patients, with improved efficiency, value, and quality. This change along with a greater focus on population health affects how systems of care are structured and delivered. Pathologists are not immune to these disruptors and, in fact, may be one of the most affected medical specialties. In the coming decades, it is likely that the number of practicing pathologists will decline, requiring each pathologist to serve more and often sicker patients. The demand for increasingly sophisticated yet broader diagnostic skills will continue to grow. This will require pathologists to acquire appropriate professional training and interpersonal skills. Today’s pathology training programs are ill designed to prepare such practitioners. The time to practice for most pathology trainees is typically 5 to 6 years. Yet, trainees often lack sufficient experience to practice independently and effectively. Many studies have recognized these challenges suggesting that more effective training for this new century can be implemented. Building on the strengths of existing programs, we propose a redesign of pathology residency training that will meet (and encourage) a continuing evolution of American Board of Pathology and Accreditation Council for Graduate Medical Education requirements, reduce the time to readiness for practice, and produce more effective, interactive, and adaptable pathologists. The essence of this new model is clear definition and acquisition of core knowledge and practice skills that span the anatomic and clinical pathology continuum during the first 2 years, assessed by competency-based metrics with emphasis on critical thinking and skill acquisition, followed by individualized modular training with intensively progressive responsibility during the final years of training. We anticipate that implementing some or all aspects of this model will enable residents to attain a higher level of competency within the current time-based constraints of residency training.
ER  - 

TY  - JOUR
T1  - On the role of integrated computer modelling in fusion technology
AU  - Smolentsev, Sergey
AU  - Spagnuolo, Gandolfo Alessandro
AU  - Serikov, Arkady
AU  - Rasmussen, Jens Juul
AU  - Nielsen, Anders H.
AU  - Naulin, Volker
AU  - Marian, Jaime
AU  - Coleman, Matti
AU  - Malerba, Lorenzo
JO  - Fusion Engineering and Design
VL  - 157
SP  - 111671
PY  - 2020
DA  - 2020/08/01/
SN  - 0920-3796
DO  - https://doi.org/10.1016/j.fusengdes.2020.111671
UR  - https://www.sciencedirect.com/science/article/pii/S0920379620302192
KW  - Fusion technology
KW  - Computer modelling
KW  - Neutronics
KW  - Materials
KW  - Plasma
KW  - MHD thermofluids
KW  - Model integration
AB  - Computer modelling is expected to play an increasingly important role in fusion design and technology, where the complexity of the physical processes involved (plasma, materials, engineering), and the highly interconnected nature of systems and components (“system of systems” design), call for support from sophisticated and integrated computer simulation tools. In this paper, we review the contribution of coupled computer modelling to the design of the reactor, breeding blanket and integrated first wall in terms of neutronics, materials behaviour (including plasma-materials interaction, radiation effects and compatibility with fluids), magnetohydrodynamics thermofluid issues and thermo-hydraulic aspects, as well as simulations of plasma transport out of the confinement region to determine heat and particle loads on plasma facing components. The current capabilities and levels of maturity of existing simulation tools are critically analysed, having in mind the possibility of integrating several tools in a single computational suite in the future and highlighting the perspectives and difficulties of such an endeavour.
ER  - 

TY  - JOUR
T1  - Making as an opportunity for classroom assessment: Canadian maker educators’ views on assessment
AU  - Murai, Yumiko
AU  - Yulis San Juan, A.
JO  - International Journal of Child-Computer Interaction
VL  - 39
SP  - 100631
PY  - 2024
DA  - 2024/03/01/
SN  - 2212-8689
DO  - https://doi.org/10.1016/j.ijcci.2023.100631
UR  - https://www.sciencedirect.com/science/article/pii/S2212868923000685
KW  - Maker education
KW  - School-based making
KW  - Maker classrooms
KW  - Classroom assessment
KW  - Curriculum change
KW  - Case study
AB  - A growing number of studies have shown that the exploratory, collaborative, and contextualized nature of maker activities create opportunities for learners to engage with knowledge in a uniquely different way from traditional education which largely relies on de-contextualized instructions. The increased integration of making into K-12 curricula has enormous implications not only for instructional design but also for assessment practices. Maker-oriented activities have the potential to shed light on types of learning that previous assessment systems have not captured and examined. Nevertheless, little is discussed on how making can contribute to the assessment and instructional practices at large. This case study investigated educators' experiences with assessment in classrooms integrating maker activities. Through a qualitative analysis of interviews with six K-12 educators in Canada, the researchers examined: (1) in what ways does making activities create opportunities for assessment and instruction in K-12 classrooms? (2) in what ways does maker learning become a challenge for assessment and instruction in K-12 classrooms? Our analysis revealed several ways in which teachers experienced the advantages of the making approach for understanding student learning and for helping students become further aware of their own progress. The results also revealed challenges to conducting assessments for maker learning, including administrative challenges like continuing to gain support from the administration, and literacy challenges such as students’ obsession with letter grades. This study provides insights into how making may help improve assessment and instructional practices in K-12 classrooms.
ER  - 

TY  - JOUR
T1  - Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making
AU  - Jarrahi, Mohammad Hossein
JO  - Business Horizons
VL  - 61
IS  - 4
SP  - 577
EP  - 586
PY  - 2018
DA  - 2018/07/01/
SN  - 0007-6813
DO  - https://doi.org/10.1016/j.bushor.2018.03.007
UR  - https://www.sciencedirect.com/science/article/pii/S0007681318300387
KW  - Artificial intelligence
KW  - Organizational decision making
KW  - Human-machine symbiosis
KW  - Human augmentation
KW  - Analytical and intuitive decision making
AB  - Artificial intelligence (AI) has penetrated many organizational processes, resulting in a growing fear that smart machines will soon replace many humans in decision making. To provide a more proactive and pragmatic perspective, this article highlights the complementarity of humans and AI and examines how each can bring their own strength in organizational decision-making processes typically characterized by uncertainty, complexity, and equivocality. With a greater computational information processing capacity and an analytical approach, AI can extend humans’ cognition when addressing complexity, whereas humans can still offer a more holistic, intuitive approach in dealing with uncertainty and equivocality in organizational decision making. This premise mirrors the idea of intelligence augmentation, which states that AI systems should be designed with the intention of augmenting, not replacing, human contributions.
ER  - 

TY  - JOUR
T1  - An effective approach for bi-objective multi-period touristic itinerary planning
AU  - Aliano Filho, Angelo
AU  - Morabito, Reinaldo
JO  - Expert Systems with Applications
VL  - 240
SP  - 122437
PY  - 2024
DA  - 2024/04/15/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2023.122437
UR  - https://www.sciencedirect.com/science/article/pii/S0957417423029391
KW  - Touristic itinerary planning
KW  - Multi-objective optimization
KW  - Routing and scheduling problem
KW  - MIP-heuristic
KW  - Trade-off analysis
AB  - Planning effective itineraries for tourists is a major problem that has been gaining attention over the last years. This paper proposes a new bi-objective integer linear programming model for this problem. Decisions include the choice of the best itinerary to be performed considering multi-period routing, time windows for the visited attractions and the choice of restaurants and hotels. The conflicting objectives considered are: (i) maximizing the level of service offered by the itinerary, and (ii) minimizing the total distance traveled. The problem resolution, even for small instances by exact methods, is limited. This motivated the proposition of a new customized MIP-heuristic based on decomposition, fix-and-optimize and MIP-start, to produce good-quality solutions with moderate computational effort. Tchebycheff’s scalarization method was coupled to this heuristic and multiple compromise solutions were obtained. Extensive results with problem instances of different sizes and characteristics showed a good performance of this approach, capable of producing effective solutions within short runtimes. The analysis of the solutions indicated a strong conflict between the objectives, allowing the user to quantify the losses and gains when one criterion is prioritized over the other. A brief sensitivity analysis of some model parameters revealed interesting managerial insights. Some examples include quantifying the negative impacts in terms of the level of service offered by concentrating hotels and restaurants in the center of tourist attractions, increasing visit and transfer times between attractions and reducing the planning horizon for the entire itinerary. These aspects validate the potential of using this MIP model and applying this MIP-heuristic in real situations.
ER  - 

TY  - JOUR
T1  - Interpretability in neural networks towards universal consistency
AU  - Monte-Serrat, Dionéia Motta
AU  - Cattani, Carlo
JO  - International Journal of Cognitive Computing in Engineering
VL  - 2
SP  - 30
EP  - 39
PY  - 2021
DA  - 2021/06/01/
SN  - 2666-3074
DO  - https://doi.org/10.1016/j.ijcce.2021.01.002
UR  - https://www.sciencedirect.com/science/article/pii/S266630742100005X
KW  - Intelligent systems
KW  - Interpretability
KW  - Language semantics
KW  - Universal consistency
AB  - In the challenge of Artificial Intelligence in processing semantically evaluable information, the application of deep learning techniques depends not only on the algorithms, but also on the principles that explain how they work. The malfunction of a machine learning system, ML, can occur due lack of knowledge of the algorithm intended behavior. The difficulty in debugging ML can be overcome by using strategies based on the universal structure of language that overlaps in the cognitive architecture of biological and intelligent systems. The appropriate choice of an algorithm inspired by the functioning of human language offers the computational scientist methodological strategies to clarify its performance analysis to optimize the interpretative activity under the good instrumentation of the system and to reach the performance level of an application considered safe. Neurolinguistic principles that link interpretation to language and cognition; the semantic dimension that arises not only from the linguistic system, but also from the context in which the information is produced; and the theoretical bases for understanding language as a 'form' (process) and not as a substance (set of signs) provide the groundwork for the intelligent systems’ improvement so that they have universal consistency and lessen the effects of the ‘curse of dimensionality’ or of the bias in the interpretation by the system. Semantics and statistics are considered to understand universal consistency as opposed to ideal consistency when evaluating a data set, since training alone is not sufficient to avoid data manipulation. We conclude that the 'key' for a good information classifier to achieve an acceptable performance of neural networks is in the dynamic aspect of language (language as a form / process) that: Guides the apprehension of how neural networks have access to weights (values); replicates this for intelligent systems making them invariant to many input transformations and guarantees an infinite amount of finite sample information, avoiding semantic distortion.
ER  - 

TY  - JOUR
T1  - Multiple criteria decision-making methods with completely unknown weights in hesitant fuzzy linguistic term setting
AU  - Farhadinia, B.
JO  - Knowledge-Based Systems
VL  - 93
SP  - 135
EP  - 144
PY  - 2016
DA  - 2016/02/01/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2015.11.008
UR  - https://www.sciencedirect.com/science/article/pii/S0950705115004359
KW  - Multi-criteria decision making
KW  - Hesitant fuzzy linguistic term set
KW  - Entropy measure
KW  - Similarity measure
KW  - Distance measure
AB  - As for multi-criteria decision making problems with hesitant fuzzy linguistic information, it is common that the criteria involved in the problems are associated with the predetermined weights, whereas the information about criteria weights is generally incomplete. This is because of the complexity and the inherent subjective nature of human thinking. In this circumstance, the weights of criteria can be derived by means of information entropy from the evaluation values of criteria for alternatives. To the best of our knowledge, up to now, there is no work having introduced the concept of entropy measure for hesitant fuzzy linguistic term sets (HFLTSs). Hence, in this paper, we are going to fill in this gap by developing information about how entropy measures of HFLTSs can be designed.
ER  - 

TY  - JOUR
T1  - Expert knowledge recommendation systems based on conceptual similarity and space mapping
AU  - Gao, Li
AU  - Dai, Kun
AU  - Gao, Liping
AU  - Jin, Tao
JO  - Expert Systems with Applications
VL  - 136
SP  - 242
EP  - 251
PY  - 2019
DA  - 2019/12/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2019.06.013
UR  - https://www.sciencedirect.com/science/article/pii/S0957417419304130
KW  - Conceptual similarity
KW  - Space mapping
KW  - Core resource database (CRD)
KW  - Institutional repository (IR)
KW  - Expert Knowledge Recommendation System (EKRS)
AB  - The semantic analysis method of structured big data generated based on human knowledge is important in expert recommendation systems and scientific and technological information analysis. In these fields, the most important problem is the calculation of concept similarity. The study aims to explore the spatial mapping relationship between the general knowledge base and the professional knowledge base for the application of the general knowledge map in professional fields. With the core resource database (CRD) as the main body of the general knowledge and the institutional repository (IR) as the main body of the professional knowledge, the conceptual features of institutional expert knowledge were firstly abstracted from IR and inferred from small-scale datasets and the mathematical model was established based on the similarity of text concepts and related ranking results. Then, a two-set concept space mapping algorithm between CRD and IR was designed. In the algorithm, the more granular concept nodes were extracted from the information on the shortest paths among concepts to obtain a new knowledge set, the Expert Knowledge Recommendation System (EKRS). Finally, the simulation experiment was carried out with open datasets to verify the algorithm. The simulation results showed that the algorithm reduced the structural complexity in the calculation of large datasets. The proposed system model had a clear knowledge structure and the recommended accuracy of the text similarity was high. For small-scale knowledge base datasets with different sparsity, the system showed the stable performance, indicating the better convergence and robustness of the algorithm.
ER  - 

TY  - JOUR
T1  - Educational Robotics as a boundary object: Towards a research agenda
AU  - Malinverni, Laura
AU  - Valero, Cristina
AU  - Schaper, Marie Monique
AU  - de la Cruz, Isabel Garcia
JO  - International Journal of Child-Computer Interaction
VL  - 29
SP  - 100305
PY  - 2021
DA  - 2021/09/01/
SN  - 2212-8689
DO  - https://doi.org/10.1016/j.ijcci.2021.100305
UR  - https://www.sciencedirect.com/science/article/pii/S2212868921000349
KW  - Educational robotics
KW  - Children
KW  - Robots
KW  - Boundary object
KW  - Intelligent technologies
AB  - Educational robotics has become each time more present in the educational experiences of children and young people. Nonetheless, often, the way in which robotics is introduced in educational settings has been considered as unnecessarily narrow. The paper aims at widening the scope of Educational Robotics and expanding the pedagogical possibilities of this field. To this end, the paper draws on the outcomes of two case studies carried out with primary and secondary school children aimed at investigating their views about robots. These studies allow framing and identifying five themes we believe are particularly relevant to rethink the pedagogy of Educational Robotics. Using these themes as cornerstones for reflection, we delineate a set of dimensions and paths to move Educational Robotics beyond the focus on technical skills but instead explore its potential as a boundary object to involve children in reflective processes around the ethical, social and cultural implications of emerging intelligent technologies.
ER  - 

TY  - JOUR
T1  - BERT-based transfer learning in tacit knowledge externalization: A study case of history teachers
AU  - Li, Guang
AU  - Zhu, Linkai
AU  - Liu, Fangfang
AU  - Cai, Zhiming
AU  - Wang, Yiyun
AU  - Gao, Ruichen
JO  - Learning and Motivation
VL  - 87
SP  - 102009
PY  - 2024
DA  - 2024/08/01/
SN  - 0023-9690
DO  - https://doi.org/10.1016/j.lmot.2024.102009
UR  - https://www.sciencedirect.com/science/article/pii/S0023969024000511
KW  - Transfer Learning
KW  - Classification
KW  - Tacit Knowledge Externalization
AB  - There has been significant progress in the field of transfer learning. However, there are still issues with inconsistent results in professional domain applications, with low-resource learning being a considerable problem. This paper proposes a language processing model for historical education built using BERT's pre-training techniques. Two experiments were conducted to obtain comparative results and choose the appropriate model method for explicating implicit expertise in secondary school history teaching. It compares traditional methods, represented by naive Bayes, to popular continuation pre-processing techniques such as domain adaptive learning and task adaptive learning to improve the effectiveness of transfer learning. Finally, this study builds targeted models based on real application needs and selects professional rules consistent with the scene application. The use of continued pre-training helps to enhance the accuracy of the professional domain model.
ER  - 

TY  - JOUR
T1  - A comparative study of optimization models for the gas detector placement in process facilities
AU  - Liu, Yue
AU  - Zhang, Bo
AU  - Mu, Chao
JO  - Computers & Chemical Engineering
VL  - 143
SP  - 107095
PY  - 2020
DA  - 2020/12/05/
SN  - 0098-1354
DO  - https://doi.org/10.1016/j.compchemeng.2020.107095
UR  - https://www.sciencedirect.com/science/article/pii/S0098135420306189
KW  - Optimization
KW  - Gas detector
KW  - Stochastic programming
KW  - Computational fluid dynamics
AB  - Gas detector network is an important layer of protection in process facilities for prevention gas leakage accidents. But traditional standards just provide basic principles for the installation of detectors. In this study, three stochastic programming (SP) models are developed and contrasted, namely minimal detection time P-Median model (MDTP), minimal leakage concentration P-Median model (MLCP), and minimal individual risk P-median model (MIRP). Meanwhile all possible leak scenarios are identified based on the combination of wind field set and leakage sources. And clustering analysis is used to filter similar scenarios and select representative leak scenarios. The leak consequences are predicted by computational fluid dynamics (CFD) method and the results are served as the input data of these SP models. A case study is carried out in a diesel hydrogenation unit.
ER  - 

TY  - JOUR
T1  - Kuhn vs. Popper on criticism and dogmatism in science, part II: How to strike the balance
AU  - Rowbottom, Darrell P.
JO  - Studies in History and Philosophy of Science Part A
VL  - 44
IS  - 2
SP  - 161
EP  - 168
PY  - 2013
DA  - 2013/06/01/
SN  - 0039-3681
DO  - https://doi.org/10.1016/j.shpsa.2012.11.011
UR  - https://www.sciencedirect.com/science/article/pii/S0039368112001161
AB  - This paper is a supplement to, and provides a proof of principle of, Kuhn vs. Popper on Criticism and Dogmatism in Science: A Resolution at the Group Level. It illustrates how calculations may be performed in order to determine how the balance between different functions in science—such as imaginative, critical, and dogmatic—should be struck, with respect to confirmation (or corroboration) functions and rules of scientific method.
ER  - 

TY  - JOUR
T1  - On low for speed oracles
AU  - Bienvenu, Laurent
AU  - Downey, Rod
JO  - Journal of Computer and System Sciences
VL  - 108
SP  - 49
EP  - 63
PY  - 2020
DA  - 2020/03/01/
SN  - 0022-0000
DO  - https://doi.org/10.1016/j.jcss.2019.08.007
UR  - https://www.sciencedirect.com/science/article/pii/S0022000018305828
KW  - Oracle computations
KW  - Lowness for speed
AB  - Relativizing computations of Turing machines to an oracle is a central concept in the theory of computation, both in complexity theory and in computability theory(!). Inspired by lowness notions from computability theory, Allender introduced the concept of “low for speed” oracles. An oracle A is low for speed if relativizing to A has essentially no effect on computational complexity, meaning that if a decidable language can be decided in time f(n) with access to oracle A, then it can be decided in time poly(f(n)) without any oracle. The existence of non-computable such A's was later proven by Bayer and Slaman, who even constructed a computably enumerable one, and exhibited a number of properties of these oracles. In this paper, we pursue this line of research, answering the questions left by Bayer and Slaman and give further evidence that the class of low for speed oracles is a very rich one.
ER  - 

TY  - JOUR
T1  - Replay in minds and machines
AU  - Wittkuhn, Lennart
AU  - Chien, Samson
AU  - Hall-McMaster, Sam
AU  - Schuck, Nicolas W.
JO  - Neuroscience & Biobehavioral Reviews
VL  - 129
SP  - 367
EP  - 388
PY  - 2021
DA  - 2021/10/01/
SN  - 0149-7634
DO  - https://doi.org/10.1016/j.neubiorev.2021.08.002
UR  - https://www.sciencedirect.com/science/article/pii/S0149763421003444
KW  - Replay
KW  - Reinforcement learning
KW  - Machine learning
KW  - Representation learning
KW  - Decision-making
AB  - Experience-related brain activity patterns reactivate during sleep, wakeful rest, and brief pauses from active behavior. In parallel, machine learning research has found that experience replay can lead to substantial performance improvements in artificial agents. Together, these lines of research suggest that replay has a variety of computational benefits for decision-making and learning. Here, we provide an overview of putative computational functions of replay as suggested by machine learning and neuroscientific research. We show that replay can lead to faster learning, less forgetting, reorganization or augmentation of experiences, and support planning and generalization. In addition, we highlight the benefits of reactivating abstracted internal representations rather than veridical memories, and discuss how replay could provide a mechanism to build internal representations that improve learning and decision-making.
ER  - 
